{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/cyberseihis/bnnprint/blob/main/notebooks/skqktnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","source":["!wget -O gasId.csv \"https://drive.google.com/file/d/123kc11q3BL9VD3GyvM7aUVR6Z2_gK42-/view?usp=share_link\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9lWE-tGm8LcN","executionInfo":{"status":"ok","timestamp":1681931744669,"user_tz":-180,"elapsed":477,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}},"outputId":"f195631a-f9f5-4ee1-92a4-637602f2cff9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-04-19 19:15:43--  https://drive.google.com/file/d/123kc11q3BL9VD3GyvM7aUVR6Z2_gK42-/view?usp=share_link\n","Resolving drive.google.com (drive.google.com)... 172.253.118.100, 172.253.118.101, 172.253.118.139, ...\n","Connecting to drive.google.com (drive.google.com)|172.253.118.100|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/html]\n","Saving to: ‘gasId.csv’\n","\n","gasId.csv               [ <=>                ]  74.64K  --.-KB/s    in 0.03s   \n","\n","2023-04-19 19:15:44 (2.73 MB/s) - ‘gasId.csv’ saved [76434]\n","\n"]}]},{"cell_type":"code","source":["%pip install keras-tuner QKeras"],"metadata":{"id":"inCvvA6Y12bn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681931872430,"user_tz":-180,"elapsed":3474,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}},"outputId":"01af2035-2d32-4534-a711-304aaa10d29f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras-tuner in /usr/local/lib/python3.9/dist-packages (1.3.5)\n","Requirement already satisfied: QKeras in /usr/local/lib/python3.9/dist-packages (0.9.0)\n","Requirement already satisfied: kt-legacy in /usr/local/lib/python3.9/dist-packages (from keras-tuner) (1.0.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from keras-tuner) (2.27.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from keras-tuner) (23.1)\n","Requirement already satisfied: tensorflow-model-optimization>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from QKeras) (0.7.4)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.9/dist-packages (from QKeras) (3.1)\n","Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.9/dist-packages (from QKeras) (4.65.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from QKeras) (67.6.1)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from QKeras) (1.24.2)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from QKeras) (1.10.1)\n","Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from QKeras) (1.2.2)\n","Requirement already satisfied: pyparser in /usr/local/lib/python3.9/dist-packages (from QKeras) (1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.23.1->QKeras) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.23.1->QKeras) (3.1.0)\n","Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization>=0.2.1->QKeras) (1.4.0)\n","Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization>=0.2.1->QKeras) (1.16.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization>=0.2.1->QKeras) (0.1.8)\n","Requirement already satisfied: parse==1.6.5 in /usr/local/lib/python3.9/dist-packages (from pyparser->QKeras) (1.6.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (1.26.15)\n"]}]},{"cell_type":"code","source":["%pip install --no-deps scikeras"],"metadata":{"id":"Y8D5wcfE07Cy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681931876967,"user_tz":-180,"elapsed":767,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}},"outputId":"e704f3bc-d59e-4c11-8691-b2457fea363c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikeras in /usr/local/lib/python3.9/dist-packages (0.10.0)\n"]}]},{"cell_type":"code","source":["def get_csv_filenames():\n","    filenames = os.listdir()\n","    csv_filenames = [os.path.splitext(filename)[0] for filename in filenames if filename.endswith(\".csv\")]\n","    return csv_filenames"],"metadata":{"id":"oHc51wQaItjx","executionInfo":{"status":"ok","timestamp":1681933892898,"user_tz":-180,"elapsed":1155,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["os.chdir('drive/MyDrive/dataset')"],"metadata":{"id":"S4a0bOUTQXLm","executionInfo":{"status":"error","timestamp":1681929458984,"user_tz":-180,"elapsed":1169,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}},"colab":{"base_uri":"https://localhost:8080/","height":222},"outputId":"cd78bb2e-78ed-41b3-e81d-5d8ef470e702"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-fbba9c364403>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/dataset'"]}]},{"cell_type":"code","source":["for fn in get_csv_filenames():\n","  quick_csv(fn)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3V4z51ayEohf","executionInfo":{"status":"error","timestamp":1681935275359,"user_tz":-180,"elapsed":1336988,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}},"outputId":"249e4062-6229-4fc4-8145-c0e5178b82c3"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["28/33 [========================>.....] - ETA: 0s - loss: 1.1519 - accuracy: 0.7132\n","Epoch 1: val_accuracy improved from -inf to 0.75168, saving model to cardio_tnn2.h5\n","33/33 [==============================] - 2s 20ms/step - loss: 1.1439 - accuracy: 0.7147 - val_loss: 0.9084 - val_accuracy: 0.7517\n","Epoch 2/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.6359 - accuracy: 0.7942\n","Epoch 2: val_accuracy improved from 0.75168 to 0.76286, saving model to cardio_tnn2.h5\n","33/33 [==============================] - 0s 7ms/step - loss: 0.6605 - accuracy: 0.7867 - val_loss: 0.6273 - val_accuracy: 0.7629\n","Epoch 3/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.5129 - accuracy: 0.8000\n","Epoch 3: val_accuracy improved from 0.76286 to 0.82550, saving model to cardio_tnn2.h5\n","33/33 [==============================] - 0s 7ms/step - loss: 0.5013 - accuracy: 0.8012 - val_loss: 0.4796 - val_accuracy: 0.8255\n","Epoch 4/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.5824 - accuracy: 0.8190\n","Epoch 4: val_accuracy did not improve from 0.82550\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5910 - accuracy: 0.8165 - val_loss: 0.5753 - val_accuracy: 0.7987\n","Epoch 5/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.5234 - accuracy: 0.8287\n","Epoch 5: val_accuracy did not improve from 0.82550\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5122 - accuracy: 0.8300 - val_loss: 0.6100 - val_accuracy: 0.7897\n","Epoch 6/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.5395 - accuracy: 0.8157\n","Epoch 6: val_accuracy did not improve from 0.82550\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5378 - accuracy: 0.8175 - val_loss: 0.5862 - val_accuracy: 0.7987\n","Epoch 7/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.4557 - accuracy: 0.8242\n","Epoch 7: val_accuracy did not improve from 0.82550\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4600 - accuracy: 0.8280 - val_loss: 0.6117 - val_accuracy: 0.7897\n","Epoch 8/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4834 - accuracy: 0.8337\n","Epoch 8: val_accuracy improved from 0.82550 to 0.82774, saving model to cardio_tnn2.h5\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4776 - accuracy: 0.8367 - val_loss: 0.5347 - val_accuracy: 0.8277\n","Epoch 9/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4249 - accuracy: 0.8330\n","Epoch 9: val_accuracy did not improve from 0.82774\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8386 - val_loss: 0.5052 - val_accuracy: 0.8098\n","Epoch 10/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4507 - accuracy: 0.8491\n","Epoch 10: val_accuracy did not improve from 0.82774\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4573 - accuracy: 0.8453 - val_loss: 0.5104 - val_accuracy: 0.8210\n","Epoch 11/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4453 - accuracy: 0.8397\n","Epoch 11: val_accuracy improved from 0.82774 to 0.83893, saving model to cardio_tnn2.h5\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.8415 - val_loss: 0.5394 - val_accuracy: 0.8389\n","Epoch 12/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3844 - accuracy: 0.8417\n","Epoch 12: val_accuracy did not improve from 0.83893\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3832 - accuracy: 0.8444 - val_loss: 0.5151 - val_accuracy: 0.8076\n","Epoch 13/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4175 - accuracy: 0.8414\n","Epoch 13: val_accuracy did not improve from 0.83893\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.8501 - val_loss: 0.4485 - val_accuracy: 0.8277\n","Epoch 14/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3837 - accuracy: 0.8427\n","Epoch 14: val_accuracy improved from 0.83893 to 0.84116, saving model to cardio_tnn2.h5\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8473 - val_loss: 0.4334 - val_accuracy: 0.8412\n","Epoch 15/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4234 - accuracy: 0.8502\n","Epoch 15: val_accuracy did not improve from 0.84116\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.8482 - val_loss: 0.4982 - val_accuracy: 0.8322\n","Epoch 16/100\n","22/33 [===================>..........] - ETA: 0s - loss: 0.3839 - accuracy: 0.8523\n","Epoch 16: val_accuracy did not improve from 0.84116\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8549 - val_loss: 0.4655 - val_accuracy: 0.8076\n","Epoch 17/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4181 - accuracy: 0.8481\n","Epoch 17: val_accuracy improved from 0.84116 to 0.84564, saving model to cardio_tnn2.h5\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8482 - val_loss: 0.4109 - val_accuracy: 0.8456\n","Epoch 18/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4315 - accuracy: 0.8500\n","Epoch 18: val_accuracy did not improve from 0.84564\n","33/33 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.8444 - val_loss: 0.5972 - val_accuracy: 0.7830\n","Epoch 19/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4115 - accuracy: 0.8416\n","Epoch 19: val_accuracy did not improve from 0.84564\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8357 - val_loss: 0.4511 - val_accuracy: 0.8434\n","Epoch 20/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3803 - accuracy: 0.8588\n","Epoch 20: val_accuracy did not improve from 0.84564\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8549 - val_loss: 0.4125 - val_accuracy: 0.8345\n","Epoch 21/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4716 - accuracy: 0.8438\n","Epoch 21: val_accuracy improved from 0.84564 to 0.86130, saving model to cardio_tnn2.h5\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.8540 - val_loss: 0.3767 - val_accuracy: 0.8613\n","Epoch 22/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3908 - accuracy: 0.8571\n","Epoch 22: val_accuracy did not improve from 0.86130\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8511 - val_loss: 0.4205 - val_accuracy: 0.8568\n","Epoch 23/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4813 - accuracy: 0.8490\n","Epoch 23: val_accuracy did not improve from 0.86130\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4808 - accuracy: 0.8501 - val_loss: 0.3853 - val_accuracy: 0.8434\n","Epoch 24/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3881 - accuracy: 0.8513\n","Epoch 24: val_accuracy did not improve from 0.86130\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8501 - val_loss: 0.4476 - val_accuracy: 0.8389\n","Epoch 25/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4423 - accuracy: 0.8610\n","Epoch 25: val_accuracy did not improve from 0.86130\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4391 - accuracy: 0.8588 - val_loss: 0.4336 - val_accuracy: 0.8412\n","Epoch 26/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4150 - accuracy: 0.8380\n","Epoch 26: val_accuracy did not improve from 0.86130\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.8425 - val_loss: 0.4512 - val_accuracy: 0.8389\n","Epoch 27/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4422 - accuracy: 0.8296\n","Epoch 27: val_accuracy improved from 0.86130 to 0.86577, saving model to cardio_tnn2.h5\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4334 - accuracy: 0.8357 - val_loss: 0.3900 - val_accuracy: 0.8658\n","Epoch 28/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4250 - accuracy: 0.8448\n","Epoch 28: val_accuracy did not improve from 0.86577\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.8473 - val_loss: 0.5124 - val_accuracy: 0.8210\n","Epoch 29/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4070 - accuracy: 0.8471\n","Epoch 29: val_accuracy did not improve from 0.86577\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8415 - val_loss: 0.6005 - val_accuracy: 0.8300\n","Epoch 30/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4159 - accuracy: 0.8599\n","Epoch 30: val_accuracy did not improve from 0.86577\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.8598 - val_loss: 0.4827 - val_accuracy: 0.7964\n","Epoch 31/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3379 - accuracy: 0.8738\n","Epoch 31: val_accuracy did not improve from 0.86577\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3460 - accuracy: 0.8674 - val_loss: 0.4933 - val_accuracy: 0.8322\n","Epoch 32/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4007 - accuracy: 0.8615\n","Epoch 32: val_accuracy did not improve from 0.86577\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4037 - accuracy: 0.8598 - val_loss: 0.5788 - val_accuracy: 0.8098\n","Epoch 33/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3813 - accuracy: 0.8634\n","Epoch 33: val_accuracy did not improve from 0.86577\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8636 - val_loss: 0.4217 - val_accuracy: 0.8501\n","Epoch 34/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3111 - accuracy: 0.8750\n","Epoch 34: val_accuracy improved from 0.86577 to 0.87919, saving model to cardio_tnn2.h5\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3356 - accuracy: 0.8646 - val_loss: 0.3859 - val_accuracy: 0.8792\n","Epoch 35/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.3538 - accuracy: 0.8548\n","Epoch 35: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3594 - accuracy: 0.8540 - val_loss: 0.4068 - val_accuracy: 0.8479\n","Epoch 36/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4136 - accuracy: 0.8519\n","Epoch 36: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4035 - accuracy: 0.8521 - val_loss: 0.3807 - val_accuracy: 0.8479\n","Epoch 37/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3583 - accuracy: 0.8642\n","Epoch 37: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3556 - accuracy: 0.8665 - val_loss: 0.4587 - val_accuracy: 0.8367\n","Epoch 38/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3805 - accuracy: 0.8604\n","Epoch 38: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8549 - val_loss: 0.3820 - val_accuracy: 0.8523\n","Epoch 39/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3810 - accuracy: 0.8479\n","Epoch 39: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8463 - val_loss: 0.6717 - val_accuracy: 0.8054\n","Epoch 40/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4331 - accuracy: 0.8472\n","Epoch 40: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.8482 - val_loss: 0.3928 - val_accuracy: 0.8479\n","Epoch 41/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3345 - accuracy: 0.8621\n","Epoch 41: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3231 - accuracy: 0.8626 - val_loss: 0.3685 - val_accuracy: 0.8546\n","Epoch 42/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.3452 - accuracy: 0.8518\n","Epoch 42: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3524 - accuracy: 0.8473 - val_loss: 0.4225 - val_accuracy: 0.8456\n","Epoch 43/100\n","33/33 [==============================] - ETA: 0s - loss: 0.4092 - accuracy: 0.8521\n","Epoch 43: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4092 - accuracy: 0.8521 - val_loss: 0.4268 - val_accuracy: 0.8277\n","Epoch 44/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4956 - accuracy: 0.8498\n","Epoch 44: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4900 - accuracy: 0.8492 - val_loss: 0.4458 - val_accuracy: 0.8412\n","Epoch 45/100\n","32/33 [============================>.] - ETA: 0s - loss: 0.3566 - accuracy: 0.8594\n","Epoch 45: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3571 - accuracy: 0.8588 - val_loss: 0.3790 - val_accuracy: 0.8345\n","Epoch 46/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.3657 - accuracy: 0.8649\n","Epoch 46: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3673 - accuracy: 0.8655 - val_loss: 0.3723 - val_accuracy: 0.8658\n","Epoch 47/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3645 - accuracy: 0.8635\n","Epoch 47: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.3737 - accuracy: 0.8578 - val_loss: 0.3802 - val_accuracy: 0.8501\n","Epoch 48/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4043 - accuracy: 0.8478\n","Epoch 48: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4010 - accuracy: 0.8482 - val_loss: 0.4952 - val_accuracy: 0.7875\n","Epoch 49/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4196 - accuracy: 0.8470\n","Epoch 49: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4136 - accuracy: 0.8501 - val_loss: 0.3893 - val_accuracy: 0.8389\n","Epoch 50/100\n","32/33 [============================>.] - ETA: 0s - loss: 0.3751 - accuracy: 0.8535\n","Epoch 50: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3714 - accuracy: 0.8540 - val_loss: 0.4164 - val_accuracy: 0.8367\n","Epoch 51/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4156 - accuracy: 0.8468\n","Epoch 51: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4115 - accuracy: 0.8482 - val_loss: 0.6862 - val_accuracy: 0.8255\n","Epoch 52/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4911 - accuracy: 0.8460\n","Epoch 52: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4913 - accuracy: 0.8463 - val_loss: 0.3975 - val_accuracy: 0.8501\n","Epoch 53/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3709 - accuracy: 0.8552\n","Epoch 53: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3572 - accuracy: 0.8617 - val_loss: 0.5056 - val_accuracy: 0.8277\n","Epoch 54/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3882 - accuracy: 0.8594\n","Epoch 54: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8559 - val_loss: 0.4066 - val_accuracy: 0.8523\n","20/20 [==============================] - 0s 3ms/step\n","0.8605015673981191\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["28/33 [========================>.....] - ETA: 0s - loss: 1.7890 - accuracy: 0.5636\n","Epoch 1: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 1s 16ms/step - loss: 1.6472 - accuracy: 0.5994 - val_loss: 1.0884 - val_accuracy: 0.7830\n","Epoch 2/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.8987 - accuracy: 0.7594\n","Epoch 2: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.9027 - accuracy: 0.7627 - val_loss: 0.8375 - val_accuracy: 0.7830\n","Epoch 3/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.7136 - accuracy: 0.7857\n","Epoch 3: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.7896 - val_loss: 0.7553 - val_accuracy: 0.7450\n","Epoch 4/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.5281 - accuracy: 0.8233\n","Epoch 4: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.8175 - val_loss: 0.6275 - val_accuracy: 0.7740\n","Epoch 5/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.5356 - accuracy: 0.8135\n","Epoch 5: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.8117 - val_loss: 0.5652 - val_accuracy: 0.7875\n","Epoch 6/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4483 - accuracy: 0.8425\n","Epoch 6: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.8309 - val_loss: 0.5574 - val_accuracy: 0.7919\n","Epoch 7/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4642 - accuracy: 0.8271\n","Epoch 7: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4766 - accuracy: 0.8232 - val_loss: 0.5135 - val_accuracy: 0.8188\n","Epoch 8/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4830 - accuracy: 0.8185\n","Epoch 8: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4948 - accuracy: 0.8213 - val_loss: 0.6451 - val_accuracy: 0.8210\n","Epoch 9/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4652 - accuracy: 0.8330\n","Epoch 9: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4804 - accuracy: 0.8309 - val_loss: 0.5197 - val_accuracy: 0.8322\n","Epoch 10/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4668 - accuracy: 0.8351\n","Epoch 10: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.8367 - val_loss: 0.4061 - val_accuracy: 0.8210\n","Epoch 11/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4184 - accuracy: 0.8448\n","Epoch 11: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8434 - val_loss: 0.4658 - val_accuracy: 0.8188\n","Epoch 12/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4046 - accuracy: 0.8380\n","Epoch 12: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8329 - val_loss: 0.4552 - val_accuracy: 0.8143\n","Epoch 13/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4439 - accuracy: 0.8373\n","Epoch 13: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4579 - accuracy: 0.8357 - val_loss: 0.4936 - val_accuracy: 0.8322\n","Epoch 14/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4619 - accuracy: 0.8373\n","Epoch 14: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.8396 - val_loss: 0.4122 - val_accuracy: 0.8591\n","Epoch 15/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3973 - accuracy: 0.8502\n","Epoch 15: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8530 - val_loss: 0.4398 - val_accuracy: 0.8367\n","Epoch 16/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4005 - accuracy: 0.8469\n","Epoch 16: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8492 - val_loss: 0.4553 - val_accuracy: 0.8322\n","Epoch 17/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4588 - accuracy: 0.8493\n","Epoch 17: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.8521 - val_loss: 0.5381 - val_accuracy: 0.8210\n","Epoch 18/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4481 - accuracy: 0.8531\n","Epoch 18: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.8473 - val_loss: 0.4565 - val_accuracy: 0.8434\n","Epoch 19/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4578 - accuracy: 0.8396\n","Epoch 19: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.8367 - val_loss: 0.6599 - val_accuracy: 0.8188\n","Epoch 20/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4608 - accuracy: 0.8333\n","Epoch 20: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.8338 - val_loss: 0.4977 - val_accuracy: 0.8188\n","Epoch 21/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4158 - accuracy: 0.8513\n","Epoch 21: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.8492 - val_loss: 0.6195 - val_accuracy: 0.8210\n","Epoch 22/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4646 - accuracy: 0.8365\n","Epoch 22: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.8329 - val_loss: 0.4382 - val_accuracy: 0.8568\n","Epoch 23/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3492 - accuracy: 0.8702\n","Epoch 23: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3735 - accuracy: 0.8617 - val_loss: 0.5079 - val_accuracy: 0.8322\n","Epoch 24/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4159 - accuracy: 0.8510\n","Epoch 24: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8530 - val_loss: 0.4558 - val_accuracy: 0.8523\n","Epoch 25/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.3967 - accuracy: 0.8558\n","Epoch 25: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8569 - val_loss: 0.4944 - val_accuracy: 0.8143\n","Epoch 26/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3682 - accuracy: 0.8513\n","Epoch 26: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8492 - val_loss: 0.3795 - val_accuracy: 0.8523\n","Epoch 27/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3981 - accuracy: 0.8560\n","Epoch 27: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8569 - val_loss: 0.5864 - val_accuracy: 0.8076\n","Epoch 28/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4934 - accuracy: 0.8371\n","Epoch 28: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.8405 - val_loss: 0.5096 - val_accuracy: 0.8121\n","Epoch 29/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.3955 - accuracy: 0.8508\n","Epoch 29: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8530 - val_loss: 0.4964 - val_accuracy: 0.8210\n","Epoch 30/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4236 - accuracy: 0.8438\n","Epoch 30: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.8501 - val_loss: 0.4764 - val_accuracy: 0.8300\n","Epoch 31/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4224 - accuracy: 0.8531\n","Epoch 31: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8511 - val_loss: 0.6554 - val_accuracy: 0.7964\n","Epoch 32/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4219 - accuracy: 0.8500\n","Epoch 32: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4261 - accuracy: 0.8530 - val_loss: 0.5752 - val_accuracy: 0.8009\n","Epoch 33/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4698 - accuracy: 0.8403\n","Epoch 33: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.8501 - val_loss: 0.4162 - val_accuracy: 0.8635\n","Epoch 34/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4183 - accuracy: 0.8573\n","Epoch 34: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8607 - val_loss: 0.6231 - val_accuracy: 0.8277\n","Epoch 35/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4014 - accuracy: 0.8761\n","Epoch 35: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4233 - accuracy: 0.8703 - val_loss: 0.4498 - val_accuracy: 0.8635\n","Epoch 36/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4315 - accuracy: 0.8384\n","Epoch 36: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.8463 - val_loss: 0.4419 - val_accuracy: 0.8322\n","Epoch 37/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4098 - accuracy: 0.8382\n","Epoch 37: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8463 - val_loss: 0.4524 - val_accuracy: 0.8412\n","Epoch 38/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3710 - accuracy: 0.8534\n","Epoch 38: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3814 - accuracy: 0.8501 - val_loss: 0.4119 - val_accuracy: 0.8591\n","Epoch 39/100\n","32/33 [============================>.] - ETA: 0s - loss: 0.4345 - accuracy: 0.8545\n","Epoch 39: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4347 - accuracy: 0.8549 - val_loss: 0.4876 - val_accuracy: 0.8277\n","Epoch 40/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3609 - accuracy: 0.8646\n","Epoch 40: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3638 - accuracy: 0.8646 - val_loss: 0.5411 - val_accuracy: 0.8233\n","Epoch 41/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4316 - accuracy: 0.8507\n","Epoch 41: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 10ms/step - loss: 0.4441 - accuracy: 0.8492 - val_loss: 0.5441 - val_accuracy: 0.8054\n","Epoch 42/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.5144 - accuracy: 0.8426\n","Epoch 42: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.5430 - accuracy: 0.8357 - val_loss: 0.6040 - val_accuracy: 0.8233\n","Epoch 43/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4325 - accuracy: 0.8600\n","Epoch 43: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4556 - accuracy: 0.8540 - val_loss: 0.4887 - val_accuracy: 0.8367\n","Epoch 44/100\n","33/33 [==============================] - ETA: 0s - loss: 0.4296 - accuracy: 0.8511\n","Epoch 44: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4296 - accuracy: 0.8511 - val_loss: 0.5243 - val_accuracy: 0.8255\n","Epoch 45/100\n","32/33 [============================>.] - ETA: 0s - loss: 0.4266 - accuracy: 0.8447\n","Epoch 45: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.8473 - val_loss: 0.8235 - val_accuracy: 0.7718\n","Epoch 46/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4489 - accuracy: 0.8371\n","Epoch 46: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4331 - accuracy: 0.8415 - val_loss: 0.9097 - val_accuracy: 0.7271\n","Epoch 47/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4476 - accuracy: 0.8354\n","Epoch 47: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4408 - accuracy: 0.8386 - val_loss: 0.5096 - val_accuracy: 0.8367\n","Epoch 48/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4435 - accuracy: 0.8468\n","Epoch 48: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4587 - accuracy: 0.8415 - val_loss: 0.6104 - val_accuracy: 0.8054\n","Epoch 49/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3913 - accuracy: 0.8521\n","Epoch 49: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.3948 - accuracy: 0.8511 - val_loss: 0.3811 - val_accuracy: 0.8345\n","Epoch 50/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.5204 - accuracy: 0.8319\n","Epoch 50: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.5150 - accuracy: 0.8309 - val_loss: 0.4943 - val_accuracy: 0.8367\n","Epoch 51/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4422 - accuracy: 0.8542\n","Epoch 51: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.8569 - val_loss: 0.6177 - val_accuracy: 0.8434\n","Epoch 52/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4245 - accuracy: 0.8534\n","Epoch 52: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.8444 - val_loss: 0.6158 - val_accuracy: 0.8277\n","Epoch 53/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.5487 - accuracy: 0.8337\n","Epoch 53: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5165 - accuracy: 0.8405 - val_loss: 0.4840 - val_accuracy: 0.8188\n","20/20 [==============================] - 0s 3ms/step\n","0.8605015673981191\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["28/33 [========================>.....] - ETA: 0s - loss: 2.6117 - accuracy: 0.5078\n","Epoch 1: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 2s 24ms/step - loss: 2.4198 - accuracy: 0.5456 - val_loss: 1.1019 - val_accuracy: 0.7562\n","Epoch 2/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.9198 - accuracy: 0.7985\n","Epoch 2: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.8930 - accuracy: 0.8002 - val_loss: 0.7675 - val_accuracy: 0.7808\n","Epoch 3/100\n","32/33 [============================>.] - ETA: 0s - loss: 0.7511 - accuracy: 0.7988\n","Epoch 3: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.7547 - accuracy: 0.7963 - val_loss: 0.8221 - val_accuracy: 0.7696\n","Epoch 4/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.7425 - accuracy: 0.7792\n","Epoch 4: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.7095 - accuracy: 0.7887 - val_loss: 0.7381 - val_accuracy: 0.7651\n","Epoch 5/100\n","33/33 [==============================] - ETA: 0s - loss: 0.7398 - accuracy: 0.7858\n","Epoch 5: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 1s 22ms/step - loss: 0.7398 - accuracy: 0.7858 - val_loss: 0.8362 - val_accuracy: 0.7718\n","Epoch 6/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.6557 - accuracy: 0.8065\n","Epoch 6: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 14ms/step - loss: 0.6283 - accuracy: 0.8060 - val_loss: 0.5447 - val_accuracy: 0.8031\n","Epoch 7/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4723 - accuracy: 0.8160\n","Epoch 7: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 10ms/step - loss: 0.4909 - accuracy: 0.8184 - val_loss: 0.5202 - val_accuracy: 0.8300\n","Epoch 8/100\n","22/33 [===================>..........] - ETA: 0s - loss: 0.4760 - accuracy: 0.8381\n","Epoch 8: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4690 - accuracy: 0.8386 - val_loss: 0.5013 - val_accuracy: 0.8322\n","Epoch 9/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.5165 - accuracy: 0.8233\n","Epoch 9: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.8252 - val_loss: 0.5357 - val_accuracy: 0.8210\n","Epoch 10/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4762 - accuracy: 0.8396\n","Epoch 10: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 15ms/step - loss: 0.4699 - accuracy: 0.8405 - val_loss: 0.4838 - val_accuracy: 0.8188\n","Epoch 11/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4640 - accuracy: 0.8206\n","Epoch 11: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 13ms/step - loss: 0.4447 - accuracy: 0.8338 - val_loss: 0.4458 - val_accuracy: 0.8277\n","Epoch 12/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3913 - accuracy: 0.8462\n","Epoch 12: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 12ms/step - loss: 0.3878 - accuracy: 0.8463 - val_loss: 0.4650 - val_accuracy: 0.8434\n","Epoch 13/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4787 - accuracy: 0.8292\n","Epoch 13: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.8309 - val_loss: 0.4552 - val_accuracy: 0.8322\n","Epoch 14/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3817 - accuracy: 0.8530\n","Epoch 14: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3828 - accuracy: 0.8549 - val_loss: 0.5688 - val_accuracy: 0.8389\n","Epoch 15/100\n","32/33 [============================>.] - ETA: 0s - loss: 0.4210 - accuracy: 0.8467\n","Epoch 15: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 15ms/step - loss: 0.4187 - accuracy: 0.8463 - val_loss: 0.4524 - val_accuracy: 0.8210\n","Epoch 16/100\n","33/33 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.8386\n","Epoch 16: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 13ms/step - loss: 0.4115 - accuracy: 0.8386 - val_loss: 0.4580 - val_accuracy: 0.8412\n","Epoch 17/100\n","33/33 [==============================] - ETA: 0s - loss: 0.5028 - accuracy: 0.8319\n","Epoch 17: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 10ms/step - loss: 0.5028 - accuracy: 0.8319 - val_loss: 0.4938 - val_accuracy: 0.8367\n","Epoch 18/100\n","22/33 [===================>..........] - ETA: 0s - loss: 0.4711 - accuracy: 0.8423\n","Epoch 18: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4505 - accuracy: 0.8405 - val_loss: 0.4480 - val_accuracy: 0.8210\n","Epoch 19/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4064 - accuracy: 0.8504\n","Epoch 19: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8501 - val_loss: 0.4771 - val_accuracy: 0.8345\n","Epoch 20/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4616 - accuracy: 0.8297\n","Epoch 20: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.8357 - val_loss: 0.5895 - val_accuracy: 0.8322\n","Epoch 21/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4152 - accuracy: 0.8482\n","Epoch 21: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8482 - val_loss: 0.4541 - val_accuracy: 0.8143\n","Epoch 22/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4397 - accuracy: 0.8375\n","Epoch 22: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.8434 - val_loss: 0.5075 - val_accuracy: 0.8188\n","Epoch 23/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4245 - accuracy: 0.8337\n","Epoch 23: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8348 - val_loss: 0.5198 - val_accuracy: 0.8501\n","Epoch 24/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3671 - accuracy: 0.8542\n","Epoch 24: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8540 - val_loss: 0.4788 - val_accuracy: 0.8277\n","Epoch 25/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4561 - accuracy: 0.8449\n","Epoch 25: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.8453 - val_loss: 0.5296 - val_accuracy: 0.8277\n","Epoch 26/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4118 - accuracy: 0.8438\n","Epoch 26: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4244 - accuracy: 0.8396 - val_loss: 0.6137 - val_accuracy: 0.7875\n","Epoch 27/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4114 - accuracy: 0.8600\n","Epoch 27: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8588 - val_loss: 0.4758 - val_accuracy: 0.8434\n","Epoch 28/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4036 - accuracy: 0.8546\n","Epoch 28: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4100 - accuracy: 0.8559 - val_loss: 0.5324 - val_accuracy: 0.8255\n","Epoch 29/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4107 - accuracy: 0.8594\n","Epoch 29: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4056 - accuracy: 0.8636 - val_loss: 0.5720 - val_accuracy: 0.8166\n","Epoch 30/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4233 - accuracy: 0.8638\n","Epoch 30: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8626 - val_loss: 0.4746 - val_accuracy: 0.8277\n","Epoch 31/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3861 - accuracy: 0.8500\n","Epoch 31: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8569 - val_loss: 0.4810 - val_accuracy: 0.8412\n","Epoch 32/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4444 - accuracy: 0.8502\n","Epoch 32: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.8492 - val_loss: 0.4587 - val_accuracy: 0.8300\n","Epoch 33/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4149 - accuracy: 0.8519\n","Epoch 33: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8501 - val_loss: 0.6128 - val_accuracy: 0.8210\n","Epoch 34/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4219 - accuracy: 0.8594\n","Epoch 34: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.8549 - val_loss: 0.4609 - val_accuracy: 0.8479\n","Epoch 35/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4180 - accuracy: 0.8578\n","Epoch 35: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8655 - val_loss: 0.5041 - val_accuracy: 0.8479\n","Epoch 36/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4408 - accuracy: 0.8449\n","Epoch 36: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.8425 - val_loss: 0.4994 - val_accuracy: 0.8591\n","Epoch 37/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4357 - accuracy: 0.8538\n","Epoch 37: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.8549 - val_loss: 0.5465 - val_accuracy: 0.8345\n","Epoch 38/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4581 - accuracy: 0.8404\n","Epoch 38: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.8396 - val_loss: 0.4260 - val_accuracy: 0.8456\n","Epoch 39/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3893 - accuracy: 0.8739\n","Epoch 39: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8655 - val_loss: 0.4461 - val_accuracy: 0.8456\n","Epoch 40/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4313 - accuracy: 0.8482\n","Epoch 40: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8559 - val_loss: 0.6261 - val_accuracy: 0.8367\n","Epoch 41/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4331 - accuracy: 0.8438\n","Epoch 41: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4253 - accuracy: 0.8434 - val_loss: 0.5621 - val_accuracy: 0.8345\n","Epoch 42/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4335 - accuracy: 0.8605\n","Epoch 42: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.8549 - val_loss: 0.4244 - val_accuracy: 0.8523\n","Epoch 43/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.3537 - accuracy: 0.8685\n","Epoch 43: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8617 - val_loss: 0.4526 - val_accuracy: 0.8434\n","Epoch 44/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4237 - accuracy: 0.8582\n","Epoch 44: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4334 - accuracy: 0.8521 - val_loss: 0.3746 - val_accuracy: 0.8658\n","Epoch 45/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.3959 - accuracy: 0.8518\n","Epoch 45: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4007 - accuracy: 0.8521 - val_loss: 0.4492 - val_accuracy: 0.8568\n","Epoch 46/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4728 - accuracy: 0.8406\n","Epoch 46: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4693 - accuracy: 0.8425 - val_loss: 0.4179 - val_accuracy: 0.8322\n","Epoch 47/100\n","33/33 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.8607\n","Epoch 47: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3786 - accuracy: 0.8607 - val_loss: 0.4071 - val_accuracy: 0.8568\n","Epoch 48/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4062 - accuracy: 0.8604\n","Epoch 48: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4157 - accuracy: 0.8588 - val_loss: 0.6746 - val_accuracy: 0.7584\n","Epoch 49/100\n","33/33 [==============================] - ETA: 0s - loss: 0.4075 - accuracy: 0.8463\n","Epoch 49: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4075 - accuracy: 0.8463 - val_loss: 0.4428 - val_accuracy: 0.8434\n","Epoch 50/100\n","33/33 [==============================] - ETA: 0s - loss: 0.3627 - accuracy: 0.8694\n","Epoch 50: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3627 - accuracy: 0.8694 - val_loss: 0.4332 - val_accuracy: 0.8635\n","Epoch 51/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4143 - accuracy: 0.8569\n","Epoch 51: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4201 - accuracy: 0.8569 - val_loss: 0.4420 - val_accuracy: 0.8523\n","Epoch 52/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3821 - accuracy: 0.8610\n","Epoch 52: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.3743 - accuracy: 0.8674 - val_loss: 0.4634 - val_accuracy: 0.8322\n","Epoch 53/100\n","33/33 [==============================] - ETA: 0s - loss: 0.4198 - accuracy: 0.8444\n","Epoch 53: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.8444 - val_loss: 0.4520 - val_accuracy: 0.8501\n","Epoch 54/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3913 - accuracy: 0.8616\n","Epoch 54: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 12ms/step - loss: 0.4064 - accuracy: 0.8607 - val_loss: 0.4296 - val_accuracy: 0.8591\n","Epoch 55/100\n","32/33 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8613\n","Epoch 55: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3823 - accuracy: 0.8626 - val_loss: 0.4574 - val_accuracy: 0.8255\n","Epoch 56/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4243 - accuracy: 0.8438\n","Epoch 56: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.8425 - val_loss: 0.5712 - val_accuracy: 0.8277\n","Epoch 57/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.5554 - accuracy: 0.8348\n","Epoch 57: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5376 - accuracy: 0.8357 - val_loss: 0.4433 - val_accuracy: 0.8613\n","Epoch 58/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3814 - accuracy: 0.8549\n","Epoch 58: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8559 - val_loss: 0.4309 - val_accuracy: 0.8434\n","Epoch 59/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4037 - accuracy: 0.8565\n","Epoch 59: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8598 - val_loss: 0.4123 - val_accuracy: 0.8568\n","Epoch 60/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4091 - accuracy: 0.8491\n","Epoch 60: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8559 - val_loss: 0.4902 - val_accuracy: 0.8479\n","Epoch 61/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3737 - accuracy: 0.8650\n","Epoch 61: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8578 - val_loss: 0.5520 - val_accuracy: 0.7942\n","Epoch 62/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4413 - accuracy: 0.8438\n","Epoch 62: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4272 - accuracy: 0.8492 - val_loss: 0.5928 - val_accuracy: 0.8322\n","Epoch 63/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4441 - accuracy: 0.8459\n","Epoch 63: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.8425 - val_loss: 0.4184 - val_accuracy: 0.8322\n","Epoch 64/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4046 - accuracy: 0.8448\n","Epoch 64: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4038 - accuracy: 0.8453 - val_loss: 0.4557 - val_accuracy: 0.8412\n","20/20 [==============================] - 0s 2ms/step\n","0.8699059561128527\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["28/33 [========================>.....] - ETA: 0s - loss: 1.3971 - accuracy: 0.7221\n","Epoch 1: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 1s 16ms/step - loss: 1.2920 - accuracy: 0.7358 - val_loss: 0.9539 - val_accuracy: 0.7025\n","Epoch 2/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.7619 - accuracy: 0.7616\n","Epoch 2: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.7405 - accuracy: 0.7627 - val_loss: 0.7742 - val_accuracy: 0.7651\n","Epoch 3/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.6884 - accuracy: 0.8024\n","Epoch 3: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.6703 - accuracy: 0.8069 - val_loss: 0.6475 - val_accuracy: 0.8031\n","Epoch 4/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.6587 - accuracy: 0.8093\n","Epoch 4: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.6250 - accuracy: 0.8175 - val_loss: 0.5481 - val_accuracy: 0.8322\n","Epoch 5/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.6109 - accuracy: 0.8156\n","Epoch 5: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5898 - accuracy: 0.8232 - val_loss: 0.5474 - val_accuracy: 0.8031\n","Epoch 6/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4739 - accuracy: 0.8394\n","Epoch 6: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.8415 - val_loss: 0.5257 - val_accuracy: 0.8210\n","Epoch 7/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4777 - accuracy: 0.8173\n","Epoch 7: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5348 - accuracy: 0.8204 - val_loss: 0.5160 - val_accuracy: 0.8389\n","Epoch 8/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.5433 - accuracy: 0.8237\n","Epoch 8: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5261 - accuracy: 0.8309 - val_loss: 0.5085 - val_accuracy: 0.8121\n","Epoch 9/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4950 - accuracy: 0.8254\n","Epoch 9: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.8261 - val_loss: 0.5189 - val_accuracy: 0.8233\n","Epoch 10/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4745 - accuracy: 0.8317\n","Epoch 10: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.8338 - val_loss: 0.5391 - val_accuracy: 0.8098\n","Epoch 11/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.5110 - accuracy: 0.8219\n","Epoch 11: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.8232 - val_loss: 0.5271 - val_accuracy: 0.8277\n","Epoch 12/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.5001 - accuracy: 0.8299\n","Epoch 12: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5267 - accuracy: 0.8232 - val_loss: 0.5473 - val_accuracy: 0.8098\n","Epoch 13/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4604 - accuracy: 0.8415\n","Epoch 13: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.8377 - val_loss: 0.4115 - val_accuracy: 0.8479\n","Epoch 14/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4188 - accuracy: 0.8416\n","Epoch 14: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8434 - val_loss: 0.3611 - val_accuracy: 0.8747\n","Epoch 15/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3614 - accuracy: 0.8675\n","Epoch 15: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8607 - val_loss: 0.4437 - val_accuracy: 0.8412\n","Epoch 16/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4007 - accuracy: 0.8400\n","Epoch 16: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8367 - val_loss: 0.6713 - val_accuracy: 0.7875\n","Epoch 17/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3945 - accuracy: 0.8610\n","Epoch 17: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8626 - val_loss: 0.4729 - val_accuracy: 0.8479\n","Epoch 18/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4305 - accuracy: 0.8385\n","Epoch 18: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.8405 - val_loss: 0.4271 - val_accuracy: 0.8613\n","Epoch 19/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3846 - accuracy: 0.8656\n","Epoch 19: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8636 - val_loss: 0.4649 - val_accuracy: 0.8300\n","Epoch 20/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4528 - accuracy: 0.8384\n","Epoch 20: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.8473 - val_loss: 0.4597 - val_accuracy: 0.8345\n","Epoch 21/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4534 - accuracy: 0.8380\n","Epoch 21: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.8357 - val_loss: 0.4478 - val_accuracy: 0.8568\n","Epoch 22/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4053 - accuracy: 0.8583\n","Epoch 22: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8588 - val_loss: 0.4534 - val_accuracy: 0.8233\n","Epoch 23/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3685 - accuracy: 0.8616\n","Epoch 23: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3780 - accuracy: 0.8540 - val_loss: 0.3378 - val_accuracy: 0.8613\n","Epoch 24/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3939 - accuracy: 0.8438\n","Epoch 24: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3904 - accuracy: 0.8386 - val_loss: 0.4156 - val_accuracy: 0.8233\n","Epoch 25/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3688 - accuracy: 0.8583\n","Epoch 25: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.8540 - val_loss: 0.6423 - val_accuracy: 0.8166\n","Epoch 26/100\n","22/33 [===================>..........] - ETA: 0s - loss: 0.6197 - accuracy: 0.8026\n","Epoch 26: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.5882 - accuracy: 0.8069 - val_loss: 0.4247 - val_accuracy: 0.8277\n","Epoch 27/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4093 - accuracy: 0.8426\n","Epoch 27: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8377 - val_loss: 0.4301 - val_accuracy: 0.8479\n","Epoch 28/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4471 - accuracy: 0.8438\n","Epoch 28: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.8463 - val_loss: 0.4253 - val_accuracy: 0.8479\n","Epoch 29/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4408 - accuracy: 0.8471\n","Epoch 29: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.8473 - val_loss: 0.7180 - val_accuracy: 0.7942\n","Epoch 30/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4552 - accuracy: 0.8438\n","Epoch 30: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.8405 - val_loss: 0.4857 - val_accuracy: 0.8434\n","Epoch 31/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4396 - accuracy: 0.8459\n","Epoch 31: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 11ms/step - loss: 0.4398 - accuracy: 0.8415 - val_loss: 0.4139 - val_accuracy: 0.8658\n","Epoch 32/100\n","32/33 [============================>.] - ETA: 0s - loss: 0.4478 - accuracy: 0.8457\n","Epoch 32: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4513 - accuracy: 0.8453 - val_loss: 0.5088 - val_accuracy: 0.8210\n","Epoch 33/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4427 - accuracy: 0.8281\n","Epoch 33: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4374 - accuracy: 0.8309 - val_loss: 0.5067 - val_accuracy: 0.8210\n","Epoch 34/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4317 - accuracy: 0.8416\n","Epoch 34: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4314 - accuracy: 0.8396 - val_loss: 0.4032 - val_accuracy: 0.8591\n","20/20 [==============================] - 0s 4ms/step\n","0.8855799373040752\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["28/33 [========================>.....] - ETA: 0s - loss: 1.9802 - accuracy: 0.4676\n","Epoch 1: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 2s 17ms/step - loss: 1.8005 - accuracy: 0.5120 - val_loss: 0.9177 - val_accuracy: 0.7271\n","Epoch 2/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.7700 - accuracy: 0.7823\n","Epoch 2: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.7808 - accuracy: 0.7781 - val_loss: 0.8522 - val_accuracy: 0.7629\n","Epoch 3/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.7631 - accuracy: 0.7719\n","Epoch 3: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.7372 - accuracy: 0.7800 - val_loss: 0.7820 - val_accuracy: 0.7651\n","Epoch 4/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.7860 - accuracy: 0.7540\n","Epoch 4: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.7727 - accuracy: 0.7598 - val_loss: 0.6785 - val_accuracy: 0.7718\n","Epoch 5/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.5661 - accuracy: 0.8073\n","Epoch 5: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 5ms/step - loss: 0.5640 - accuracy: 0.8069 - val_loss: 0.5617 - val_accuracy: 0.7718\n","Epoch 6/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.5019 - accuracy: 0.8145\n","Epoch 6: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4958 - accuracy: 0.8165 - val_loss: 0.5198 - val_accuracy: 0.7808\n","Epoch 7/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4453 - accuracy: 0.8326\n","Epoch 7: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.8242 - val_loss: 0.5895 - val_accuracy: 0.7360\n","Epoch 8/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.4792 - accuracy: 0.8047\n","Epoch 8: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.8136 - val_loss: 0.4330 - val_accuracy: 0.8143\n","Epoch 9/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4625 - accuracy: 0.8090\n","Epoch 9: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4448 - accuracy: 0.8213 - val_loss: 0.5118 - val_accuracy: 0.7919\n","Epoch 10/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4191 - accuracy: 0.8534\n","Epoch 10: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.8511 - val_loss: 0.4076 - val_accuracy: 0.8277\n","Epoch 11/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4675 - accuracy: 0.8270\n","Epoch 11: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.8367 - val_loss: 0.5471 - val_accuracy: 0.8412\n","Epoch 12/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4741 - accuracy: 0.8347\n","Epoch 12: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.8377 - val_loss: 0.5380 - val_accuracy: 0.8076\n","Epoch 13/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4545 - accuracy: 0.8513\n","Epoch 13: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.8501 - val_loss: 0.4125 - val_accuracy: 0.8255\n","Epoch 14/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4484 - accuracy: 0.8470\n","Epoch 14: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.8405 - val_loss: 0.5865 - val_accuracy: 0.7897\n","Epoch 15/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4106 - accuracy: 0.8362\n","Epoch 15: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4258 - accuracy: 0.8319 - val_loss: 0.5328 - val_accuracy: 0.8233\n","Epoch 16/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4276 - accuracy: 0.8394\n","Epoch 16: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4334 - accuracy: 0.8367 - val_loss: 0.4824 - val_accuracy: 0.8300\n","Epoch 17/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.5008 - accuracy: 0.8287\n","Epoch 17: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4929 - accuracy: 0.8348 - val_loss: 0.4859 - val_accuracy: 0.8613\n","Epoch 18/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4249 - accuracy: 0.8416\n","Epoch 18: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8463 - val_loss: 0.3887 - val_accuracy: 0.8479\n","Epoch 19/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4096 - accuracy: 0.8495\n","Epoch 19: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.8444 - val_loss: 0.7938 - val_accuracy: 0.7606\n","Epoch 20/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4399 - accuracy: 0.8365\n","Epoch 20: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.8386 - val_loss: 0.5079 - val_accuracy: 0.8412\n","Epoch 21/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4400 - accuracy: 0.8333\n","Epoch 21: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.8329 - val_loss: 0.4861 - val_accuracy: 0.8188\n","Epoch 22/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4124 - accuracy: 0.8481\n","Epoch 22: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.8463 - val_loss: 0.4027 - val_accuracy: 0.8277\n","Epoch 23/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3758 - accuracy: 0.8562\n","Epoch 23: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8598 - val_loss: 0.4266 - val_accuracy: 0.8143\n","Epoch 24/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3868 - accuracy: 0.8615\n","Epoch 24: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8626 - val_loss: 0.5043 - val_accuracy: 0.8255\n","Epoch 25/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4208 - accuracy: 0.8405\n","Epoch 25: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8473 - val_loss: 0.4063 - val_accuracy: 0.8367\n","Epoch 26/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3769 - accuracy: 0.8534\n","Epoch 26: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8530 - val_loss: 0.5351 - val_accuracy: 0.8389\n","Epoch 27/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3627 - accuracy: 0.8605\n","Epoch 27: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3533 - accuracy: 0.8674 - val_loss: 0.4542 - val_accuracy: 0.8456\n","Epoch 28/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3863 - accuracy: 0.8500\n","Epoch 28: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8569 - val_loss: 0.4877 - val_accuracy: 0.8434\n","Epoch 29/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4622 - accuracy: 0.8375\n","Epoch 29: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.8396 - val_loss: 0.4456 - val_accuracy: 0.8479\n","Epoch 30/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4154 - accuracy: 0.8362\n","Epoch 30: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8386 - val_loss: 0.5067 - val_accuracy: 0.8277\n","Epoch 31/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.3889 - accuracy: 0.8327\n","Epoch 31: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3854 - accuracy: 0.8348 - val_loss: 0.4707 - val_accuracy: 0.8434\n","Epoch 32/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4084 - accuracy: 0.8470\n","Epoch 32: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.8444 - val_loss: 0.4378 - val_accuracy: 0.8389\n","Epoch 33/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4152 - accuracy: 0.8459\n","Epoch 33: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8482 - val_loss: 0.5301 - val_accuracy: 0.8277\n","Epoch 34/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4253 - accuracy: 0.8565\n","Epoch 34: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.8569 - val_loss: 0.4320 - val_accuracy: 0.8300\n","Epoch 35/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4591 - accuracy: 0.8513\n","Epoch 35: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4614 - accuracy: 0.8473 - val_loss: 0.5005 - val_accuracy: 0.8322\n","Epoch 36/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4194 - accuracy: 0.8683\n","Epoch 36: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8703 - val_loss: 0.4359 - val_accuracy: 0.8568\n","Epoch 37/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4127 - accuracy: 0.8637\n","Epoch 37: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.8703 - val_loss: 0.4152 - val_accuracy: 0.8725\n","Epoch 38/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3620 - accuracy: 0.8810\n","Epoch 38: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3720 - accuracy: 0.8742 - val_loss: 0.3879 - val_accuracy: 0.8479\n","Epoch 39/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4237 - accuracy: 0.8502\n","Epoch 39: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8521 - val_loss: 0.4044 - val_accuracy: 0.8546\n","Epoch 40/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4222 - accuracy: 0.8583\n","Epoch 40: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.8444 - val_loss: 0.5273 - val_accuracy: 0.8434\n","Epoch 41/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3909 - accuracy: 0.8661\n","Epoch 41: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8665 - val_loss: 0.3810 - val_accuracy: 0.8345\n","Epoch 42/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4065 - accuracy: 0.8482\n","Epoch 42: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4070 - accuracy: 0.8482 - val_loss: 0.4740 - val_accuracy: 0.8367\n","Epoch 43/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4110 - accuracy: 0.8562\n","Epoch 43: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8540 - val_loss: 0.3871 - val_accuracy: 0.8591\n","Epoch 44/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3903 - accuracy: 0.8530\n","Epoch 44: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8549 - val_loss: 0.4519 - val_accuracy: 0.8523\n","Epoch 45/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3943 - accuracy: 0.8556\n","Epoch 45: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3832 - accuracy: 0.8607 - val_loss: 0.4933 - val_accuracy: 0.7987\n","Epoch 46/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3995 - accuracy: 0.8594\n","Epoch 46: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4027 - accuracy: 0.8559 - val_loss: 0.4585 - val_accuracy: 0.8345\n","Epoch 47/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4295 - accuracy: 0.8333\n","Epoch 47: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4483 - accuracy: 0.8280 - val_loss: 0.4267 - val_accuracy: 0.8456\n","Epoch 48/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4827 - accuracy: 0.8459\n","Epoch 48: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4698 - accuracy: 0.8492 - val_loss: 0.4782 - val_accuracy: 0.8479\n","Epoch 49/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3714 - accuracy: 0.8642\n","Epoch 49: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3683 - accuracy: 0.8607 - val_loss: 0.4422 - val_accuracy: 0.8412\n","Epoch 50/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4020 - accuracy: 0.8500\n","Epoch 50: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8511 - val_loss: 0.3791 - val_accuracy: 0.8635\n","Epoch 51/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4020 - accuracy: 0.8528\n","Epoch 51: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3979 - accuracy: 0.8521 - val_loss: 0.5029 - val_accuracy: 0.8322\n","Epoch 52/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4399 - accuracy: 0.8415\n","Epoch 52: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 11ms/step - loss: 0.4194 - accuracy: 0.8482 - val_loss: 0.3511 - val_accuracy: 0.8635\n","Epoch 53/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.3860 - accuracy: 0.8478\n","Epoch 53: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 11ms/step - loss: 0.3833 - accuracy: 0.8473 - val_loss: 0.5074 - val_accuracy: 0.8479\n","Epoch 54/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4444 - accuracy: 0.8502\n","Epoch 54: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4264 - accuracy: 0.8569 - val_loss: 0.4091 - val_accuracy: 0.8523\n","Epoch 55/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.3813 - accuracy: 0.8569\n","Epoch 55: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3827 - accuracy: 0.8540 - val_loss: 0.3804 - val_accuracy: 0.8568\n","Epoch 56/100\n","23/33 [===================>..........] - ETA: 0s - loss: 0.4095 - accuracy: 0.8587\n","Epoch 56: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8549 - val_loss: 0.4100 - val_accuracy: 0.8501\n","Epoch 57/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4292 - accuracy: 0.8578\n","Epoch 57: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.8549 - val_loss: 0.4747 - val_accuracy: 0.8367\n","20/20 [==============================] - 0s 2ms/step\n","0.8730407523510971\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["26/33 [======================>.......] - ETA: 0s - loss: 0.9965 - accuracy: 0.7368\n","Epoch 1: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 1s 16ms/step - loss: 0.9611 - accuracy: 0.7445 - val_loss: 0.7559 - val_accuracy: 0.7517\n","Epoch 2/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.6184 - accuracy: 0.7944\n","Epoch 2: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.6153 - accuracy: 0.7954 - val_loss: 0.6048 - val_accuracy: 0.7919\n","Epoch 3/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.5666 - accuracy: 0.8135\n","Epoch 3: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 5ms/step - loss: 0.5758 - accuracy: 0.8136 - val_loss: 0.5723 - val_accuracy: 0.8121\n","Epoch 4/100\n","33/33 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.8367\n","Epoch 4: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 1s 17ms/step - loss: 0.4951 - accuracy: 0.8367 - val_loss: 0.5640 - val_accuracy: 0.8277\n","Epoch 5/100\n","32/33 [============================>.] - ETA: 0s - loss: 0.4761 - accuracy: 0.8350\n","Epoch 5: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 1s 22ms/step - loss: 0.4748 - accuracy: 0.8367 - val_loss: 0.5071 - val_accuracy: 0.8389\n","Epoch 6/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4609 - accuracy: 0.8365\n","Epoch 6: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4601 - accuracy: 0.8367 - val_loss: 0.4682 - val_accuracy: 0.8389\n","Epoch 7/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4338 - accuracy: 0.8354\n","Epoch 7: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4193 - accuracy: 0.8415 - val_loss: 0.4733 - val_accuracy: 0.8412\n","Epoch 8/100\n","23/33 [===================>..........] - ETA: 0s - loss: 0.3794 - accuracy: 0.8641\n","Epoch 8: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4014 - accuracy: 0.8578 - val_loss: 0.4560 - val_accuracy: 0.8434\n","Epoch 9/100\n","33/33 [==============================] - ETA: 0s - loss: 0.3690 - accuracy: 0.8607\n","Epoch 9: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3690 - accuracy: 0.8607 - val_loss: 0.5298 - val_accuracy: 0.8479\n","Epoch 10/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3749 - accuracy: 0.8562\n","Epoch 10: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3956 - accuracy: 0.8492 - val_loss: 0.4523 - val_accuracy: 0.8613\n","Epoch 11/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4029 - accuracy: 0.8638\n","Epoch 11: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.3917 - accuracy: 0.8636 - val_loss: 0.6381 - val_accuracy: 0.7852\n","Epoch 12/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4384 - accuracy: 0.8405\n","Epoch 12: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 11ms/step - loss: 0.4464 - accuracy: 0.8405 - val_loss: 0.4880 - val_accuracy: 0.8389\n","Epoch 13/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4323 - accuracy: 0.8417\n","Epoch 13: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4294 - accuracy: 0.8415 - val_loss: 0.3969 - val_accuracy: 0.8434\n","Epoch 14/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.5085 - accuracy: 0.8373\n","Epoch 14: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.8463 - val_loss: 0.6213 - val_accuracy: 0.8456\n","Epoch 15/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4072 - accuracy: 0.8646\n","Epoch 15: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8617 - val_loss: 0.4765 - val_accuracy: 0.8367\n","Epoch 16/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3552 - accuracy: 0.8583\n","Epoch 16: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8598 - val_loss: 0.4053 - val_accuracy: 0.8680\n","Epoch 17/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4073 - accuracy: 0.8460\n","Epoch 17: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8530 - val_loss: 0.4360 - val_accuracy: 0.8434\n","Epoch 18/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4494 - accuracy: 0.8638\n","Epoch 18: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4626 - accuracy: 0.8569 - val_loss: 0.3981 - val_accuracy: 0.8747\n","Epoch 19/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4191 - accuracy: 0.8461\n","Epoch 19: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.8511 - val_loss: 0.7242 - val_accuracy: 0.7740\n","Epoch 20/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4100 - accuracy: 0.8621\n","Epoch 20: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8646 - val_loss: 0.4592 - val_accuracy: 0.8367\n","Epoch 21/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3958 - accuracy: 0.8621\n","Epoch 21: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8655 - val_loss: 0.4538 - val_accuracy: 0.8143\n","Epoch 22/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4123 - accuracy: 0.8516\n","Epoch 22: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.8511 - val_loss: 0.5156 - val_accuracy: 0.8434\n","Epoch 23/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4553 - accuracy: 0.8448\n","Epoch 23: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.8492 - val_loss: 0.4902 - val_accuracy: 0.8434\n","Epoch 24/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4070 - accuracy: 0.8610\n","Epoch 24: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3997 - accuracy: 0.8598 - val_loss: 0.4561 - val_accuracy: 0.8345\n","Epoch 25/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4131 - accuracy: 0.8502\n","Epoch 25: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8521 - val_loss: 0.5518 - val_accuracy: 0.8121\n","Epoch 26/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4437 - accuracy: 0.8304\n","Epoch 26: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.8357 - val_loss: 0.4004 - val_accuracy: 0.8434\n","Epoch 27/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3643 - accuracy: 0.8502\n","Epoch 27: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3562 - accuracy: 0.8530 - val_loss: 0.4097 - val_accuracy: 0.8434\n","Epoch 28/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3738 - accuracy: 0.8692\n","Epoch 28: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8626 - val_loss: 0.4604 - val_accuracy: 0.8277\n","Epoch 29/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.3803 - accuracy: 0.8575\n","Epoch 29: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3714 - accuracy: 0.8607 - val_loss: 0.5368 - val_accuracy: 0.8322\n","Epoch 30/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4093 - accuracy: 0.8600\n","Epoch 30: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8569 - val_loss: 0.4089 - val_accuracy: 0.8345\n","Epoch 31/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3742 - accuracy: 0.8567\n","Epoch 31: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8588 - val_loss: 0.4915 - val_accuracy: 0.8456\n","Epoch 32/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4039 - accuracy: 0.8471\n","Epoch 32: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8482 - val_loss: 0.4705 - val_accuracy: 0.8255\n","Epoch 33/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4018 - accuracy: 0.8575\n","Epoch 33: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8598 - val_loss: 0.5167 - val_accuracy: 0.8479\n","Epoch 34/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3682 - accuracy: 0.8615\n","Epoch 34: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8617 - val_loss: 0.4273 - val_accuracy: 0.8501\n","Epoch 35/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3809 - accuracy: 0.8556\n","Epoch 35: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8530 - val_loss: 0.4335 - val_accuracy: 0.8479\n","Epoch 36/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3946 - accuracy: 0.8594\n","Epoch 36: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8598 - val_loss: 0.4803 - val_accuracy: 0.8479\n","Epoch 37/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3633 - accuracy: 0.8621\n","Epoch 37: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8540 - val_loss: 0.3902 - val_accuracy: 0.8680\n","Epoch 38/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4041 - accuracy: 0.8450\n","Epoch 38: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8559 - val_loss: 0.4299 - val_accuracy: 0.8456\n","20/20 [==============================] - 0s 2ms/step\n","0.8746081504702194\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["30/33 [==========================>...] - ETA: 0s - loss: 1.0252 - accuracy: 0.7479\n","Epoch 1: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 1s 17ms/step - loss: 1.0046 - accuracy: 0.7483 - val_loss: 0.6880 - val_accuracy: 0.7852\n","Epoch 2/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.6492 - accuracy: 0.8067\n","Epoch 2: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.6417 - accuracy: 0.8079 - val_loss: 0.6445 - val_accuracy: 0.8009\n","Epoch 3/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.5891 - accuracy: 0.8192\n","Epoch 3: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5818 - accuracy: 0.8184 - val_loss: 0.6698 - val_accuracy: 0.8031\n","Epoch 4/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.5133 - accuracy: 0.8213\n","Epoch 4: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.5177 - accuracy: 0.8184 - val_loss: 0.5910 - val_accuracy: 0.7919\n","Epoch 5/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.5784 - accuracy: 0.8041\n","Epoch 5: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5655 - accuracy: 0.8088 - val_loss: 0.5242 - val_accuracy: 0.8345\n","Epoch 6/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4975 - accuracy: 0.8351\n","Epoch 6: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4957 - accuracy: 0.8319 - val_loss: 0.5287 - val_accuracy: 0.8009\n","Epoch 7/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4571 - accuracy: 0.8401\n","Epoch 7: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.8396 - val_loss: 0.6007 - val_accuracy: 0.8210\n","Epoch 8/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4705 - accuracy: 0.8270\n","Epoch 8: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4809 - accuracy: 0.8271 - val_loss: 0.4834 - val_accuracy: 0.8255\n","Epoch 9/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4569 - accuracy: 0.8450\n","Epoch 9: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.8463 - val_loss: 0.4301 - val_accuracy: 0.8255\n","Epoch 10/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4043 - accuracy: 0.8338\n","Epoch 10: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8300 - val_loss: 0.5756 - val_accuracy: 0.8098\n","Epoch 11/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4302 - accuracy: 0.8416\n","Epoch 11: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4532 - accuracy: 0.8367 - val_loss: 0.5006 - val_accuracy: 0.7987\n","Epoch 12/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4340 - accuracy: 0.8341\n","Epoch 12: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.8309 - val_loss: 0.5464 - val_accuracy: 0.8098\n","Epoch 13/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4559 - accuracy: 0.8200\n","Epoch 13: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.8194 - val_loss: 0.4814 - val_accuracy: 0.8166\n","Epoch 14/100\n","33/33 [==============================] - ETA: 0s - loss: 0.4375 - accuracy: 0.8329\n","Epoch 14: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4375 - accuracy: 0.8329 - val_loss: 0.5150 - val_accuracy: 0.8322\n","Epoch 15/100\n","32/33 [============================>.] - ETA: 0s - loss: 0.4236 - accuracy: 0.8389\n","Epoch 15: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4246 - accuracy: 0.8396 - val_loss: 0.5488 - val_accuracy: 0.7964\n","Epoch 16/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4256 - accuracy: 0.8365\n","Epoch 16: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 11ms/step - loss: 0.4258 - accuracy: 0.8386 - val_loss: 0.5060 - val_accuracy: 0.8501\n","Epoch 17/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4351 - accuracy: 0.8286\n","Epoch 17: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4445 - accuracy: 0.8280 - val_loss: 0.6196 - val_accuracy: 0.7919\n","Epoch 18/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4183 - accuracy: 0.8362\n","Epoch 18: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4156 - accuracy: 0.8367 - val_loss: 0.6205 - val_accuracy: 0.8031\n","Epoch 19/100\n","32/33 [============================>.] - ETA: 0s - loss: 0.4423 - accuracy: 0.8271\n","Epoch 19: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4385 - accuracy: 0.8290 - val_loss: 0.4470 - val_accuracy: 0.8188\n","Epoch 20/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4196 - accuracy: 0.8385\n","Epoch 20: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4071 - accuracy: 0.8434 - val_loss: 0.4951 - val_accuracy: 0.7964\n","Epoch 21/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4602 - accuracy: 0.8347\n","Epoch 21: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4533 - accuracy: 0.8367 - val_loss: 0.5117 - val_accuracy: 0.8166\n","Epoch 22/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4189 - accuracy: 0.8500\n","Epoch 22: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8521 - val_loss: 0.4373 - val_accuracy: 0.8456\n","Epoch 23/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3803 - accuracy: 0.8588\n","Epoch 23: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.3885 - accuracy: 0.8501 - val_loss: 0.4811 - val_accuracy: 0.8322\n","Epoch 24/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4187 - accuracy: 0.8367\n","Epoch 24: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.8377 - val_loss: 0.5671 - val_accuracy: 0.8166\n","Epoch 25/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4461 - accuracy: 0.8498\n","Epoch 25: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.8453 - val_loss: 0.4719 - val_accuracy: 0.8345\n","Epoch 26/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4314 - accuracy: 0.8403\n","Epoch 26: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.8434 - val_loss: 0.5147 - val_accuracy: 0.8098\n","Epoch 27/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4148 - accuracy: 0.8281\n","Epoch 27: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.8348 - val_loss: 0.5350 - val_accuracy: 0.8143\n","Epoch 28/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4098 - accuracy: 0.8531\n","Epoch 28: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4365 - accuracy: 0.8434 - val_loss: 0.4573 - val_accuracy: 0.8389\n","Epoch 29/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4192 - accuracy: 0.8351\n","Epoch 29: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.8377 - val_loss: 0.5267 - val_accuracy: 0.8479\n","Epoch 30/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.3942 - accuracy: 0.8646\n","Epoch 30: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.8492 - val_loss: 0.5349 - val_accuracy: 0.8479\n","Epoch 31/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4238 - accuracy: 0.8391\n","Epoch 31: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8425 - val_loss: 0.4490 - val_accuracy: 0.8479\n","Epoch 32/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4087 - accuracy: 0.8583\n","Epoch 32: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8607 - val_loss: 0.4398 - val_accuracy: 0.8434\n","Epoch 33/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4110 - accuracy: 0.8562\n","Epoch 33: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3867 - accuracy: 0.8636 - val_loss: 0.4783 - val_accuracy: 0.8255\n","Epoch 34/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3704 - accuracy: 0.8683\n","Epoch 34: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3601 - accuracy: 0.8636 - val_loss: 0.3447 - val_accuracy: 0.8523\n","Epoch 35/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4214 - accuracy: 0.8313\n","Epoch 35: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8377 - val_loss: 0.5273 - val_accuracy: 0.8210\n","Epoch 36/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4004 - accuracy: 0.8426\n","Epoch 36: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4102 - accuracy: 0.8396 - val_loss: 0.4755 - val_accuracy: 0.8412\n","Epoch 37/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4228 - accuracy: 0.8448\n","Epoch 37: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8549 - val_loss: 0.4962 - val_accuracy: 0.8456\n","Epoch 38/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4114 - accuracy: 0.8571\n","Epoch 38: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.8549 - val_loss: 0.4604 - val_accuracy: 0.8479\n","Epoch 39/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.3989 - accuracy: 0.8568\n","Epoch 39: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8578 - val_loss: 0.4376 - val_accuracy: 0.8277\n","Epoch 40/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3966 - accuracy: 0.8493\n","Epoch 40: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4025 - accuracy: 0.8501 - val_loss: 0.6770 - val_accuracy: 0.8345\n","Epoch 41/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3922 - accuracy: 0.8426\n","Epoch 41: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8463 - val_loss: 0.5040 - val_accuracy: 0.8098\n","Epoch 42/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4370 - accuracy: 0.8471\n","Epoch 42: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4445 - accuracy: 0.8453 - val_loss: 0.3875 - val_accuracy: 0.8501\n","Epoch 43/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3718 - accuracy: 0.8493\n","Epoch 43: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.8511 - val_loss: 0.4665 - val_accuracy: 0.8322\n","Epoch 44/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3788 - accuracy: 0.8413\n","Epoch 44: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8425 - val_loss: 0.4445 - val_accuracy: 0.8345\n","Epoch 45/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3943 - accuracy: 0.8527\n","Epoch 45: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3926 - accuracy: 0.8559 - val_loss: 0.4622 - val_accuracy: 0.8591\n","Epoch 46/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4074 - accuracy: 0.8611\n","Epoch 46: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8646 - val_loss: 0.4196 - val_accuracy: 0.8479\n","Epoch 47/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4290 - accuracy: 0.8426\n","Epoch 47: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.8453 - val_loss: 0.5538 - val_accuracy: 0.8188\n","Epoch 48/100\n","23/33 [===================>..........] - ETA: 0s - loss: 0.4767 - accuracy: 0.8302\n","Epoch 48: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.8473 - val_loss: 0.4746 - val_accuracy: 0.8277\n","Epoch 49/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3817 - accuracy: 0.8571\n","Epoch 49: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.8569 - val_loss: 0.3794 - val_accuracy: 0.8591\n","Epoch 50/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3403 - accuracy: 0.8545\n","Epoch 50: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3376 - accuracy: 0.8530 - val_loss: 0.5115 - val_accuracy: 0.8501\n","Epoch 51/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3949 - accuracy: 0.8471\n","Epoch 51: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3877 - accuracy: 0.8492 - val_loss: 0.4943 - val_accuracy: 0.8389\n","Epoch 52/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4470 - accuracy: 0.8560\n","Epoch 52: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4435 - accuracy: 0.8511 - val_loss: 0.4861 - val_accuracy: 0.8479\n","Epoch 53/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4240 - accuracy: 0.8462\n","Epoch 53: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.8578 - val_loss: 0.4908 - val_accuracy: 0.8613\n","Epoch 54/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4511 - accuracy: 0.8438\n","Epoch 54: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4390 - accuracy: 0.8473 - val_loss: 0.4431 - val_accuracy: 0.8680\n","Epoch 55/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4667 - accuracy: 0.8350\n","Epoch 55: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.8396 - val_loss: 0.4645 - val_accuracy: 0.8680\n","Epoch 56/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4488 - accuracy: 0.8438\n","Epoch 56: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.8540 - val_loss: 0.5784 - val_accuracy: 0.8143\n","Epoch 57/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3741 - accuracy: 0.8623\n","Epoch 57: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8607 - val_loss: 0.4816 - val_accuracy: 0.8434\n","Epoch 58/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4332 - accuracy: 0.8588\n","Epoch 58: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.8559 - val_loss: 0.4522 - val_accuracy: 0.8322\n","Epoch 59/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4065 - accuracy: 0.8504\n","Epoch 59: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8434 - val_loss: 0.4340 - val_accuracy: 0.8658\n","Epoch 60/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4400 - accuracy: 0.8471\n","Epoch 60: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.8501 - val_loss: 0.3726 - val_accuracy: 0.8725\n","Epoch 61/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3677 - accuracy: 0.8717\n","Epoch 61: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8674 - val_loss: 0.3587 - val_accuracy: 0.8658\n","Epoch 62/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4198 - accuracy: 0.8438\n","Epoch 62: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.8511 - val_loss: 0.4136 - val_accuracy: 0.8389\n","Epoch 63/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4086 - accuracy: 0.8546\n","Epoch 63: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8549 - val_loss: 0.3882 - val_accuracy: 0.8591\n","Epoch 64/100\n","23/33 [===================>..........] - ETA: 0s - loss: 0.3954 - accuracy: 0.8587\n","Epoch 64: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8549 - val_loss: 0.4921 - val_accuracy: 0.8456\n","Epoch 65/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4038 - accuracy: 0.8534\n","Epoch 65: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.8607 - val_loss: 0.4771 - val_accuracy: 0.8389\n","Epoch 66/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3895 - accuracy: 0.8519\n","Epoch 66: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8549 - val_loss: 0.5892 - val_accuracy: 0.8389\n","Epoch 67/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4421 - accuracy: 0.8621\n","Epoch 67: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.8588 - val_loss: 0.4205 - val_accuracy: 0.8613\n","Epoch 68/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4307 - accuracy: 0.8471\n","Epoch 68: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.8434 - val_loss: 0.6192 - val_accuracy: 0.8233\n","Epoch 69/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4201 - accuracy: 0.8438\n","Epoch 69: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8425 - val_loss: 0.4514 - val_accuracy: 0.8412\n","Epoch 70/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4198 - accuracy: 0.8377\n","Epoch 70: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4303 - accuracy: 0.8348 - val_loss: 0.4875 - val_accuracy: 0.8322\n","Epoch 71/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4594 - accuracy: 0.8415\n","Epoch 71: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4471 - accuracy: 0.8453 - val_loss: 0.3524 - val_accuracy: 0.8501\n","Epoch 72/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4301 - accuracy: 0.8448\n","Epoch 72: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.8453 - val_loss: 0.3916 - val_accuracy: 0.8501\n","Epoch 73/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.3935 - accuracy: 0.8407\n","Epoch 73: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3913 - accuracy: 0.8425 - val_loss: 0.5394 - val_accuracy: 0.8300\n","Epoch 74/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4311 - accuracy: 0.8458\n","Epoch 74: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4386 - accuracy: 0.8425 - val_loss: 0.6486 - val_accuracy: 0.7830\n","Epoch 75/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4463 - accuracy: 0.8427\n","Epoch 75: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4500 - accuracy: 0.8425 - val_loss: 0.4476 - val_accuracy: 0.8434\n","Epoch 76/100\n","33/33 [==============================] - ETA: 0s - loss: 0.4542 - accuracy: 0.8540\n","Epoch 76: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 10ms/step - loss: 0.4542 - accuracy: 0.8540 - val_loss: 0.5436 - val_accuracy: 0.8277\n","Epoch 77/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.5164 - accuracy: 0.8341\n","Epoch 77: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4912 - accuracy: 0.8386 - val_loss: 0.4695 - val_accuracy: 0.8255\n","Epoch 78/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4027 - accuracy: 0.8527\n","Epoch 78: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 11ms/step - loss: 0.4297 - accuracy: 0.8444 - val_loss: 0.4852 - val_accuracy: 0.8054\n","Epoch 79/100\n","33/33 [==============================] - ETA: 0s - loss: 0.3926 - accuracy: 0.8530\n","Epoch 79: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3926 - accuracy: 0.8530 - val_loss: 0.5114 - val_accuracy: 0.8434\n","Epoch 80/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4398 - accuracy: 0.8394\n","Epoch 80: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4392 - accuracy: 0.8415 - val_loss: 0.3938 - val_accuracy: 0.8367\n","20/20 [==============================] - 0s 3ms/step\n","0.8824451410658307\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["24/33 [====================>.........] - ETA: 0s - loss: 2.4576 - accuracy: 0.3919\n","Epoch 1: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 2s 18ms/step - loss: 2.1508 - accuracy: 0.4890 - val_loss: 1.1189 - val_accuracy: 0.7293\n","Epoch 2/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.9076 - accuracy: 0.7933\n","Epoch 2: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.9324 - accuracy: 0.7829 - val_loss: 0.9889 - val_accuracy: 0.7651\n","Epoch 3/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.7951 - accuracy: 0.7995\n","Epoch 3: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.7673 - accuracy: 0.7973 - val_loss: 0.9191 - val_accuracy: 0.6980\n","Epoch 4/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.6216 - accuracy: 0.8160\n","Epoch 4: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.6033 - accuracy: 0.8213 - val_loss: 0.7323 - val_accuracy: 0.8054\n","Epoch 5/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.5753 - accuracy: 0.8322\n","Epoch 5: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5613 - accuracy: 0.8386 - val_loss: 0.6894 - val_accuracy: 0.7785\n","Epoch 6/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.5062 - accuracy: 0.8292\n","Epoch 6: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5326 - accuracy: 0.8232 - val_loss: 0.7347 - val_accuracy: 0.7427\n","Epoch 7/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.5443 - accuracy: 0.8093\n","Epoch 7: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.5410 - accuracy: 0.8098 - val_loss: 0.6706 - val_accuracy: 0.8031\n","Epoch 8/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4973 - accuracy: 0.8353\n","Epoch 8: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5114 - accuracy: 0.8271 - val_loss: 0.5383 - val_accuracy: 0.8188\n","Epoch 9/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.5156 - accuracy: 0.8200\n","Epoch 9: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5095 - accuracy: 0.8213 - val_loss: 0.6134 - val_accuracy: 0.7987\n","Epoch 10/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4829 - accuracy: 0.8377\n","Epoch 10: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.5215 - accuracy: 0.8329 - val_loss: 0.5703 - val_accuracy: 0.8188\n","Epoch 11/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4598 - accuracy: 0.8427\n","Epoch 11: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.5156 - accuracy: 0.8357 - val_loss: 0.5477 - val_accuracy: 0.8300\n","Epoch 12/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.5041 - accuracy: 0.8380\n","Epoch 12: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5023 - accuracy: 0.8348 - val_loss: 0.5553 - val_accuracy: 0.7830\n","Epoch 13/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.5390 - accuracy: 0.8351\n","Epoch 13: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5197 - accuracy: 0.8415 - val_loss: 0.4954 - val_accuracy: 0.8300\n","Epoch 14/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4351 - accuracy: 0.8427\n","Epoch 14: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.8463 - val_loss: 0.5635 - val_accuracy: 0.8367\n","Epoch 15/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4444 - accuracy: 0.8415\n","Epoch 15: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.8453 - val_loss: 0.5087 - val_accuracy: 0.8277\n","Epoch 16/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4034 - accuracy: 0.8623\n","Epoch 16: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8655 - val_loss: 0.4674 - val_accuracy: 0.8523\n","Epoch 17/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3783 - accuracy: 0.8672\n","Epoch 17: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8588 - val_loss: 0.4724 - val_accuracy: 0.8434\n","Epoch 18/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3945 - accuracy: 0.8599\n","Epoch 18: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8559 - val_loss: 0.6300 - val_accuracy: 0.7696\n","Epoch 19/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4403 - accuracy: 0.8377\n","Epoch 19: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.8434 - val_loss: 0.5392 - val_accuracy: 0.8389\n","Epoch 20/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4141 - accuracy: 0.8570\n","Epoch 20: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8434 - val_loss: 0.4766 - val_accuracy: 0.7897\n","Epoch 21/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3908 - accuracy: 0.8565\n","Epoch 21: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3898 - accuracy: 0.8559 - val_loss: 0.3893 - val_accuracy: 0.8546\n","Epoch 22/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.4237 - accuracy: 0.8333\n","Epoch 22: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8444 - val_loss: 0.4681 - val_accuracy: 0.8188\n","Epoch 23/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3750 - accuracy: 0.8594\n","Epoch 23: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8501 - val_loss: 0.4105 - val_accuracy: 0.8523\n","Epoch 24/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4414 - accuracy: 0.8461\n","Epoch 24: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4596 - accuracy: 0.8348 - val_loss: 0.4280 - val_accuracy: 0.8456\n","Epoch 25/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4208 - accuracy: 0.8449\n","Epoch 25: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4291 - accuracy: 0.8425 - val_loss: 0.4077 - val_accuracy: 0.8501\n","Epoch 26/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3846 - accuracy: 0.8416\n","Epoch 26: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3925 - accuracy: 0.8434 - val_loss: 0.5199 - val_accuracy: 0.8479\n","Epoch 27/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3887 - accuracy: 0.8623\n","Epoch 27: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8655 - val_loss: 0.4184 - val_accuracy: 0.8479\n","Epoch 28/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4261 - accuracy: 0.8482\n","Epoch 28: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4150 - accuracy: 0.8501 - val_loss: 0.7673 - val_accuracy: 0.8166\n","Epoch 29/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4543 - accuracy: 0.8375\n","Epoch 29: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.8405 - val_loss: 0.4167 - val_accuracy: 0.8479\n","Epoch 30/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4234 - accuracy: 0.8630\n","Epoch 30: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4259 - accuracy: 0.8617 - val_loss: 0.5217 - val_accuracy: 0.8166\n","Epoch 31/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4784 - accuracy: 0.8351\n","Epoch 31: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.8386 - val_loss: 0.4833 - val_accuracy: 0.8345\n","Epoch 32/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4148 - accuracy: 0.8524\n","Epoch 32: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8492 - val_loss: 0.4036 - val_accuracy: 0.8255\n","Epoch 33/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4489 - accuracy: 0.8484\n","Epoch 33: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.8453 - val_loss: 0.4278 - val_accuracy: 0.8479\n","Epoch 34/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4258 - accuracy: 0.8405\n","Epoch 34: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4293 - accuracy: 0.8357 - val_loss: 0.3911 - val_accuracy: 0.8456\n","Epoch 35/100\n","33/33 [==============================] - ETA: 0s - loss: 0.4114 - accuracy: 0.8521\n","Epoch 35: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.8521 - val_loss: 0.3924 - val_accuracy: 0.8479\n","Epoch 36/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4626 - accuracy: 0.8448\n","Epoch 36: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4561 - accuracy: 0.8453 - val_loss: 0.4640 - val_accuracy: 0.8591\n","Epoch 37/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3859 - accuracy: 0.8594\n","Epoch 37: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4013 - accuracy: 0.8530 - val_loss: 0.3998 - val_accuracy: 0.8523\n","Epoch 38/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3720 - accuracy: 0.8694\n","Epoch 38: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.3814 - accuracy: 0.8626 - val_loss: 0.4437 - val_accuracy: 0.8456\n","Epoch 39/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4215 - accuracy: 0.8417\n","Epoch 39: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 11ms/step - loss: 0.4149 - accuracy: 0.8444 - val_loss: 0.3716 - val_accuracy: 0.8501\n","Epoch 40/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3778 - accuracy: 0.8588\n","Epoch 40: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 11ms/step - loss: 0.3730 - accuracy: 0.8617 - val_loss: 0.3782 - val_accuracy: 0.8546\n","Epoch 41/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4066 - accuracy: 0.8475\n","Epoch 41: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.3887 - accuracy: 0.8530 - val_loss: 0.3547 - val_accuracy: 0.8702\n","Epoch 42/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.3873 - accuracy: 0.8488\n","Epoch 42: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3977 - accuracy: 0.8453 - val_loss: 0.5307 - val_accuracy: 0.8501\n","Epoch 43/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4620 - accuracy: 0.8396\n","Epoch 43: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4638 - accuracy: 0.8396 - val_loss: 0.4238 - val_accuracy: 0.8367\n","Epoch 44/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4311 - accuracy: 0.8365\n","Epoch 44: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.8405 - val_loss: 0.5058 - val_accuracy: 0.8568\n","Epoch 45/100\n","20/33 [=================>............] - ETA: 0s - loss: 0.4047 - accuracy: 0.8500\n","Epoch 45: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8578 - val_loss: 0.3373 - val_accuracy: 0.8680\n","Epoch 46/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4044 - accuracy: 0.8594\n","Epoch 46: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8559 - val_loss: 0.4323 - val_accuracy: 0.8702\n","Epoch 47/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4153 - accuracy: 0.8571\n","Epoch 47: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8598 - val_loss: 0.4750 - val_accuracy: 0.8479\n","Epoch 48/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3527 - accuracy: 0.8762\n","Epoch 48: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3548 - accuracy: 0.8722 - val_loss: 0.4349 - val_accuracy: 0.8680\n","Epoch 49/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4330 - accuracy: 0.8611\n","Epoch 49: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4572 - accuracy: 0.8492 - val_loss: 0.3631 - val_accuracy: 0.8680\n","Epoch 50/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3604 - accuracy: 0.8556\n","Epoch 50: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8521 - val_loss: 0.4415 - val_accuracy: 0.8546\n","Epoch 51/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3947 - accuracy: 0.8304\n","Epoch 51: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8386 - val_loss: 0.4906 - val_accuracy: 0.8389\n","Epoch 52/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4224 - accuracy: 0.8542\n","Epoch 52: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4223 - accuracy: 0.8559 - val_loss: 0.4573 - val_accuracy: 0.8523\n","Epoch 53/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3904 - accuracy: 0.8538\n","Epoch 53: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4035 - accuracy: 0.8521 - val_loss: 0.3785 - val_accuracy: 0.8389\n","Epoch 54/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4005 - accuracy: 0.8534\n","Epoch 54: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8588 - val_loss: 0.4914 - val_accuracy: 0.8300\n","Epoch 55/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4026 - accuracy: 0.8448\n","Epoch 55: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8473 - val_loss: 0.4519 - val_accuracy: 0.8389\n","Epoch 56/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4189 - accuracy: 0.8426\n","Epoch 56: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8453 - val_loss: 0.4862 - val_accuracy: 0.8546\n","Epoch 57/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4139 - accuracy: 0.8560\n","Epoch 57: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8540 - val_loss: 0.4237 - val_accuracy: 0.8501\n","Epoch 58/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3974 - accuracy: 0.8516\n","Epoch 58: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8559 - val_loss: 0.4324 - val_accuracy: 0.8546\n","Epoch 59/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3556 - accuracy: 0.8611\n","Epoch 59: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3815 - accuracy: 0.8549 - val_loss: 0.3535 - val_accuracy: 0.8591\n","Epoch 60/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4213 - accuracy: 0.8623\n","Epoch 60: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8684 - val_loss: 0.4432 - val_accuracy: 0.8345\n","Epoch 61/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4350 - accuracy: 0.8493\n","Epoch 61: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8540 - val_loss: 0.4284 - val_accuracy: 0.8434\n","20/20 [==============================] - 0s 2ms/step\n","0.8526645768025078\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["32/33 [============================>.] - ETA: 0s - loss: 2.0773 - accuracy: 0.4541\n","Epoch 1: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 2s 24ms/step - loss: 2.0551 - accuracy: 0.4601 - val_loss: 1.2580 - val_accuracy: 0.7629\n","Epoch 2/100\n","30/33 [==========================>...] - ETA: 0s - loss: 1.0180 - accuracy: 0.7833\n","Epoch 2: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 1.0204 - accuracy: 0.7781 - val_loss: 0.8917 - val_accuracy: 0.7606\n","Epoch 3/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.6996 - accuracy: 0.7913\n","Epoch 3: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.6996 - accuracy: 0.7915 - val_loss: 0.6498 - val_accuracy: 0.7539\n","Epoch 4/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.5898 - accuracy: 0.8039\n","Epoch 4: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.5867 - accuracy: 0.8040 - val_loss: 0.6107 - val_accuracy: 0.7852\n","Epoch 5/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.5495 - accuracy: 0.8002\n","Epoch 5: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5501 - accuracy: 0.8050 - val_loss: 0.6546 - val_accuracy: 0.7517\n","Epoch 6/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.5609 - accuracy: 0.8087\n","Epoch 6: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.5541 - accuracy: 0.8079 - val_loss: 0.8102 - val_accuracy: 0.6555\n","Epoch 7/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.5838 - accuracy: 0.8103\n","Epoch 7: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5594 - accuracy: 0.8204 - val_loss: 0.5426 - val_accuracy: 0.7852\n","Epoch 8/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4836 - accuracy: 0.8190\n","Epoch 8: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.8184 - val_loss: 0.5616 - val_accuracy: 0.7919\n","Epoch 9/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4846 - accuracy: 0.8292\n","Epoch 9: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.8175 - val_loss: 0.5378 - val_accuracy: 0.7785\n","Epoch 10/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.5576 - accuracy: 0.8137\n","Epoch 10: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.5538 - accuracy: 0.8146 - val_loss: 0.6101 - val_accuracy: 0.7987\n","Epoch 11/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.5200 - accuracy: 0.8221\n","Epoch 11: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.5169 - accuracy: 0.8204 - val_loss: 0.4804 - val_accuracy: 0.8277\n","Epoch 12/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4487 - accuracy: 0.8326\n","Epoch 12: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.8329 - val_loss: 0.4214 - val_accuracy: 0.8166\n","Epoch 13/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4609 - accuracy: 0.8345\n","Epoch 13: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4715 - accuracy: 0.8280 - val_loss: 0.4982 - val_accuracy: 0.8210\n","Epoch 14/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4187 - accuracy: 0.8449\n","Epoch 14: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.8415 - val_loss: 0.4968 - val_accuracy: 0.8166\n","Epoch 15/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3990 - accuracy: 0.8578\n","Epoch 15: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8598 - val_loss: 0.4868 - val_accuracy: 0.8210\n","Epoch 16/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4190 - accuracy: 0.8448\n","Epoch 16: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8482 - val_loss: 0.4955 - val_accuracy: 0.8322\n","Epoch 17/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3870 - accuracy: 0.8588\n","Epoch 17: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8569 - val_loss: 0.4965 - val_accuracy: 0.8456\n","Epoch 18/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4064 - accuracy: 0.8549\n","Epoch 18: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.8492 - val_loss: 0.5187 - val_accuracy: 0.7897\n","Epoch 19/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4037 - accuracy: 0.8461\n","Epoch 19: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.8453 - val_loss: 0.4449 - val_accuracy: 0.8300\n","Epoch 20/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3753 - accuracy: 0.8750\n","Epoch 20: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8646 - val_loss: 0.4220 - val_accuracy: 0.8277\n","Epoch 21/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4516 - accuracy: 0.8415\n","Epoch 21: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4543 - accuracy: 0.8405 - val_loss: 0.4600 - val_accuracy: 0.8210\n","Epoch 22/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3668 - accuracy: 0.8588\n","Epoch 22: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8569 - val_loss: 0.4005 - val_accuracy: 0.8345\n","Epoch 23/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3625 - accuracy: 0.8638\n","Epoch 23: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3602 - accuracy: 0.8655 - val_loss: 0.4684 - val_accuracy: 0.8300\n","Epoch 24/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3376 - accuracy: 0.8522\n","Epoch 24: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8501 - val_loss: 0.4856 - val_accuracy: 0.8345\n","Epoch 25/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4075 - accuracy: 0.8425\n","Epoch 25: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8521 - val_loss: 0.4106 - val_accuracy: 0.8255\n","Epoch 26/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4066 - accuracy: 0.8449\n","Epoch 26: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4012 - accuracy: 0.8473 - val_loss: 0.4125 - val_accuracy: 0.8389\n","Epoch 27/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4020 - accuracy: 0.8470\n","Epoch 27: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8521 - val_loss: 0.4262 - val_accuracy: 0.8300\n","Epoch 28/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3759 - accuracy: 0.8739\n","Epoch 28: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.8607 - val_loss: 0.5030 - val_accuracy: 0.8389\n","Epoch 29/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4178 - accuracy: 0.8472\n","Epoch 29: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4069 - accuracy: 0.8453 - val_loss: 0.5576 - val_accuracy: 0.7987\n","Epoch 30/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4745 - accuracy: 0.8341\n","Epoch 30: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4313 - accuracy: 0.8501 - val_loss: 0.4899 - val_accuracy: 0.8479\n","Epoch 31/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.5152 - accuracy: 0.8264\n","Epoch 31: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4907 - accuracy: 0.8367 - val_loss: 0.5464 - val_accuracy: 0.8210\n","Epoch 32/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4279 - accuracy: 0.8470\n","Epoch 32: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8453 - val_loss: 0.4576 - val_accuracy: 0.8412\n","Epoch 33/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4273 - accuracy: 0.8534\n","Epoch 33: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4311 - accuracy: 0.8511 - val_loss: 0.4220 - val_accuracy: 0.8098\n","Epoch 34/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4206 - accuracy: 0.8449\n","Epoch 34: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8492 - val_loss: 0.4821 - val_accuracy: 0.8210\n","Epoch 35/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3823 - accuracy: 0.8570\n","Epoch 35: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3783 - accuracy: 0.8559 - val_loss: 0.4664 - val_accuracy: 0.8210\n","Epoch 36/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4587 - accuracy: 0.8341\n","Epoch 36: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.8453 - val_loss: 0.4288 - val_accuracy: 0.8434\n","Epoch 37/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4188 - accuracy: 0.8560\n","Epoch 37: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8569 - val_loss: 0.4268 - val_accuracy: 0.8300\n","Epoch 38/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3762 - accuracy: 0.8534\n","Epoch 38: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8501 - val_loss: 0.5452 - val_accuracy: 0.8322\n","Epoch 39/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4784 - accuracy: 0.8353\n","Epoch 39: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4604 - accuracy: 0.8338 - val_loss: 0.4762 - val_accuracy: 0.8233\n","Epoch 40/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4025 - accuracy: 0.8571\n","Epoch 40: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3875 - accuracy: 0.8636 - val_loss: 0.4991 - val_accuracy: 0.8188\n","Epoch 41/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3750 - accuracy: 0.8504\n","Epoch 41: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3998 - accuracy: 0.8434 - val_loss: 0.4572 - val_accuracy: 0.8345\n","Epoch 42/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4140 - accuracy: 0.8594\n","Epoch 42: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4100 - accuracy: 0.8626 - val_loss: 0.3986 - val_accuracy: 0.8210\n","Epoch 43/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4019 - accuracy: 0.8471\n","Epoch 43: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.8453 - val_loss: 0.3902 - val_accuracy: 0.8501\n","Epoch 44/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3802 - accuracy: 0.8600\n","Epoch 44: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3756 - accuracy: 0.8607 - val_loss: 0.3650 - val_accuracy: 0.8456\n","Epoch 45/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3708 - accuracy: 0.8553\n","Epoch 45: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8559 - val_loss: 0.4046 - val_accuracy: 0.8322\n","Epoch 46/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3709 - accuracy: 0.8582\n","Epoch 46: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8578 - val_loss: 0.4271 - val_accuracy: 0.8300\n","Epoch 47/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3956 - accuracy: 0.8471\n","Epoch 47: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8501 - val_loss: 0.4808 - val_accuracy: 0.8345\n","Epoch 48/100\n","22/33 [===================>..........] - ETA: 0s - loss: 0.4179 - accuracy: 0.8523\n","Epoch 48: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8492 - val_loss: 0.5063 - val_accuracy: 0.8121\n","Epoch 49/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4089 - accuracy: 0.8491\n","Epoch 49: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8521 - val_loss: 0.4192 - val_accuracy: 0.8613\n","Epoch 50/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4111 - accuracy: 0.8546\n","Epoch 50: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4256 - accuracy: 0.8530 - val_loss: 0.4452 - val_accuracy: 0.8501\n","Epoch 51/100\n","33/33 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.8646\n","Epoch 51: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 10ms/step - loss: 0.3689 - accuracy: 0.8646 - val_loss: 0.4709 - val_accuracy: 0.8613\n","Epoch 52/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4005 - accuracy: 0.8522\n","Epoch 52: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4072 - accuracy: 0.8473 - val_loss: 0.4925 - val_accuracy: 0.8121\n","Epoch 53/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3754 - accuracy: 0.8664\n","Epoch 53: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.3885 - accuracy: 0.8607 - val_loss: 0.4708 - val_accuracy: 0.8456\n","Epoch 54/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4312 - accuracy: 0.8527\n","Epoch 54: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4244 - accuracy: 0.8501 - val_loss: 0.4150 - val_accuracy: 0.8680\n","Epoch 55/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3548 - accuracy: 0.8727\n","Epoch 55: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 10ms/step - loss: 0.3836 - accuracy: 0.8655 - val_loss: 0.5312 - val_accuracy: 0.8277\n","Epoch 56/100\n","32/33 [============================>.] - ETA: 0s - loss: 0.4384 - accuracy: 0.8516\n","Epoch 56: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 11ms/step - loss: 0.4379 - accuracy: 0.8521 - val_loss: 0.6621 - val_accuracy: 0.8546\n","Epoch 57/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4285 - accuracy: 0.8482\n","Epoch 57: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4121 - accuracy: 0.8463 - val_loss: 0.4591 - val_accuracy: 0.8591\n","Epoch 58/100\n","32/33 [============================>.] - ETA: 0s - loss: 0.3577 - accuracy: 0.8750\n","Epoch 58: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.3570 - accuracy: 0.8751 - val_loss: 0.5556 - val_accuracy: 0.8233\n","Epoch 59/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4001 - accuracy: 0.8491\n","Epoch 59: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4064 - accuracy: 0.8463 - val_loss: 0.4386 - val_accuracy: 0.8233\n","Epoch 60/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3843 - accuracy: 0.8556\n","Epoch 60: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.3825 - accuracy: 0.8569 - val_loss: 0.6058 - val_accuracy: 0.7942\n","Epoch 61/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.4058 - accuracy: 0.8619\n","Epoch 61: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4166 - accuracy: 0.8598 - val_loss: 0.4298 - val_accuracy: 0.8412\n","Epoch 62/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3857 - accuracy: 0.8482\n","Epoch 62: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8521 - val_loss: 0.4518 - val_accuracy: 0.8523\n","Epoch 63/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4099 - accuracy: 0.8669\n","Epoch 63: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8742 - val_loss: 0.5217 - val_accuracy: 0.8367\n","Epoch 64/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.4284 - accuracy: 0.8698\n","Epoch 64: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.8646 - val_loss: 0.4337 - val_accuracy: 0.8389\n","Epoch 65/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.3878 - accuracy: 0.8607\n","Epoch 65: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3649 - accuracy: 0.8722 - val_loss: 0.5413 - val_accuracy: 0.8389\n","Epoch 66/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3780 - accuracy: 0.8715\n","Epoch 66: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8722 - val_loss: 0.6045 - val_accuracy: 0.8658\n","Epoch 67/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4115 - accuracy: 0.8650\n","Epoch 67: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8617 - val_loss: 0.4525 - val_accuracy: 0.8613\n","Epoch 68/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4184 - accuracy: 0.8600\n","Epoch 68: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.8511 - val_loss: 0.4210 - val_accuracy: 0.8523\n","Epoch 69/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4124 - accuracy: 0.8542\n","Epoch 69: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8559 - val_loss: 0.5013 - val_accuracy: 0.8568\n","Epoch 70/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3635 - accuracy: 0.8678\n","Epoch 70: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8703 - val_loss: 0.3941 - val_accuracy: 0.8255\n","Epoch 71/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3427 - accuracy: 0.8796\n","Epoch 71: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3354 - accuracy: 0.8818 - val_loss: 0.3788 - val_accuracy: 0.8568\n","Epoch 72/100\n","23/33 [===================>..........] - ETA: 0s - loss: 0.3350 - accuracy: 0.8668\n","Epoch 72: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3690 - accuracy: 0.8655 - val_loss: 0.4099 - val_accuracy: 0.8658\n","Epoch 73/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.3678 - accuracy: 0.8600\n","Epoch 73: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3425 - accuracy: 0.8636 - val_loss: 0.3817 - val_accuracy: 0.8725\n","Epoch 74/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.3708 - accuracy: 0.8500\n","Epoch 74: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.8530 - val_loss: 0.4279 - val_accuracy: 0.8635\n","Epoch 75/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4092 - accuracy: 0.8571\n","Epoch 75: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.8559 - val_loss: 0.4056 - val_accuracy: 0.8546\n","Epoch 76/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3699 - accuracy: 0.8582\n","Epoch 76: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3741 - accuracy: 0.8578 - val_loss: 0.4843 - val_accuracy: 0.8479\n","Epoch 77/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3787 - accuracy: 0.8510\n","Epoch 77: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8588 - val_loss: 0.5252 - val_accuracy: 0.8210\n","Epoch 78/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4157 - accuracy: 0.8583\n","Epoch 78: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8646 - val_loss: 0.4184 - val_accuracy: 0.8725\n","Epoch 79/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.3833 - accuracy: 0.8581\n","Epoch 79: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3621 - accuracy: 0.8665 - val_loss: 0.3857 - val_accuracy: 0.8725\n","Epoch 80/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.3915 - accuracy: 0.8475\n","Epoch 80: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8540 - val_loss: 0.4637 - val_accuracy: 0.8389\n","Epoch 81/100\n","23/33 [===================>..........] - ETA: 0s - loss: 0.4208 - accuracy: 0.8587\n","Epoch 81: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8665 - val_loss: 0.4845 - val_accuracy: 0.8031\n","Epoch 82/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3885 - accuracy: 0.8534\n","Epoch 82: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8549 - val_loss: 0.4160 - val_accuracy: 0.8300\n","Epoch 83/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3785 - accuracy: 0.8482\n","Epoch 83: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8521 - val_loss: 0.7282 - val_accuracy: 0.7651\n","Epoch 84/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4058 - accuracy: 0.8377\n","Epoch 84: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3877 - accuracy: 0.8405 - val_loss: 0.4830 - val_accuracy: 0.8389\n","Epoch 85/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4219 - accuracy: 0.8714\n","Epoch 85: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8713 - val_loss: 0.4559 - val_accuracy: 0.8501\n","Epoch 86/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.3614 - accuracy: 0.8537\n","Epoch 86: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.8540 - val_loss: 0.4131 - val_accuracy: 0.8345\n","Epoch 87/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3613 - accuracy: 0.8472\n","Epoch 87: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8405 - val_loss: 0.5964 - val_accuracy: 0.8367\n","Epoch 88/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4183 - accuracy: 0.8570\n","Epoch 88: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4507 - accuracy: 0.8434 - val_loss: 0.4624 - val_accuracy: 0.8456\n","Epoch 89/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.3984 - accuracy: 0.8550\n","Epoch 89: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8636 - val_loss: 0.4909 - val_accuracy: 0.8389\n","Epoch 90/100\n","22/33 [===================>..........] - ETA: 0s - loss: 0.4791 - accuracy: 0.8537\n","Epoch 90: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4512 - accuracy: 0.8559 - val_loss: 0.4913 - val_accuracy: 0.8188\n","Epoch 91/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.3782 - accuracy: 0.8637\n","Epoch 91: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3529 - accuracy: 0.8684 - val_loss: 0.4263 - val_accuracy: 0.8523\n","Epoch 92/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.3264 - accuracy: 0.8712\n","Epoch 92: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3391 - accuracy: 0.8646 - val_loss: 0.5865 - val_accuracy: 0.8143\n","Epoch 93/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4090 - accuracy: 0.8403\n","Epoch 93: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.8357 - val_loss: 0.3803 - val_accuracy: 0.8747\n","Epoch 94/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4006 - accuracy: 0.8472\n","Epoch 94: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8444 - val_loss: 0.3725 - val_accuracy: 0.8523\n","Epoch 95/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3460 - accuracy: 0.8750\n","Epoch 95: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3629 - accuracy: 0.8722 - val_loss: 0.6081 - val_accuracy: 0.7875\n","Epoch 96/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4266 - accuracy: 0.8449\n","Epoch 96: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.8559 - val_loss: 0.4465 - val_accuracy: 0.8568\n","Epoch 97/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3353 - accuracy: 0.8583\n","Epoch 97: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3546 - accuracy: 0.8540 - val_loss: 0.4233 - val_accuracy: 0.8747\n","Epoch 98/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3526 - accuracy: 0.8472\n","Epoch 98: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.8463 - val_loss: 0.5225 - val_accuracy: 0.7852\n","Epoch 99/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.3215 - accuracy: 0.8950\n","Epoch 99: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3466 - accuracy: 0.8780 - val_loss: 0.4116 - val_accuracy: 0.8635\n","Epoch 100/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3788 - accuracy: 0.8606\n","Epoch 100: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3598 - accuracy: 0.8665 - val_loss: 0.3435 - val_accuracy: 0.8568\n","20/20 [==============================] - 0s 3ms/step\n","0.8855799373040752\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["28/33 [========================>.....] - ETA: 0s - loss: 2.1752 - accuracy: 0.5100\n","Epoch 1: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 2s 24ms/step - loss: 1.9879 - accuracy: 0.5476 - val_loss: 0.8246 - val_accuracy: 0.7315\n","Epoch 2/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.6761 - accuracy: 0.7958\n","Epoch 2: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.6816 - accuracy: 0.7925 - val_loss: 0.7410 - val_accuracy: 0.7271\n","Epoch 3/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.6084 - accuracy: 0.7823\n","Epoch 3: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.6100 - accuracy: 0.7800 - val_loss: 0.6181 - val_accuracy: 0.7539\n","Epoch 4/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.5662 - accuracy: 0.7969\n","Epoch 4: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.5688 - accuracy: 0.7954 - val_loss: 0.6202 - val_accuracy: 0.7606\n","Epoch 5/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.5356 - accuracy: 0.8065\n","Epoch 5: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 12ms/step - loss: 0.5672 - accuracy: 0.8031 - val_loss: 0.6230 - val_accuracy: 0.7987\n","Epoch 6/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.5547 - accuracy: 0.8161\n","Epoch 6: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.5566 - accuracy: 0.8127 - val_loss: 0.5755 - val_accuracy: 0.7852\n","Epoch 7/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4950 - accuracy: 0.8326\n","Epoch 7: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.5171 - accuracy: 0.8242 - val_loss: 0.6745 - val_accuracy: 0.7763\n","Epoch 8/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.5067 - accuracy: 0.8203\n","Epoch 8: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5162 - accuracy: 0.8223 - val_loss: 0.5946 - val_accuracy: 0.8009\n","Epoch 9/100\n","23/33 [===================>..........] - ETA: 0s - loss: 0.5716 - accuracy: 0.8125\n","Epoch 9: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.5363 - accuracy: 0.8223 - val_loss: 0.5204 - val_accuracy: 0.8277\n","Epoch 10/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.5663 - accuracy: 0.7982\n","Epoch 10: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.5291 - accuracy: 0.8136 - val_loss: 0.5910 - val_accuracy: 0.7651\n","Epoch 11/100\n","23/33 [===================>..........] - ETA: 0s - loss: 0.4750 - accuracy: 0.8410\n","Epoch 11: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4486 - accuracy: 0.8415 - val_loss: 0.5387 - val_accuracy: 0.8367\n","Epoch 12/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4562 - accuracy: 0.8462\n","Epoch 12: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8521 - val_loss: 0.4282 - val_accuracy: 0.8367\n","Epoch 13/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.5785 - accuracy: 0.8092\n","Epoch 13: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.5616 - accuracy: 0.8127 - val_loss: 0.4615 - val_accuracy: 0.8031\n","Epoch 14/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4904 - accuracy: 0.8012\n","Epoch 14: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4616 - accuracy: 0.8165 - val_loss: 0.5256 - val_accuracy: 0.8143\n","Epoch 15/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.4357 - accuracy: 0.8268\n","Epoch 15: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.8357 - val_loss: 0.4688 - val_accuracy: 0.8277\n","Epoch 16/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4537 - accuracy: 0.8576\n","Epoch 16: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.8482 - val_loss: 0.4559 - val_accuracy: 0.8210\n","Epoch 17/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.4545 - accuracy: 0.8534\n","Epoch 17: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.8540 - val_loss: 0.4938 - val_accuracy: 0.8188\n","Epoch 18/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4498 - accuracy: 0.8337\n","Epoch 18: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4498 - accuracy: 0.8348 - val_loss: 0.4196 - val_accuracy: 0.8434\n","Epoch 19/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4754 - accuracy: 0.8449\n","Epoch 19: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4636 - accuracy: 0.8463 - val_loss: 0.6387 - val_accuracy: 0.8345\n","Epoch 20/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4822 - accuracy: 0.8504\n","Epoch 20: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4880 - accuracy: 0.8492 - val_loss: 0.6030 - val_accuracy: 0.8345\n","Epoch 21/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.4605 - accuracy: 0.8385\n","Epoch 21: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.8338 - val_loss: 0.3709 - val_accuracy: 0.8479\n","Epoch 22/100\n","29/33 [=========================>....] - ETA: 0s - loss: 0.3827 - accuracy: 0.8394\n","Epoch 22: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8386 - val_loss: 0.4175 - val_accuracy: 0.8322\n","Epoch 23/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4133 - accuracy: 0.8365\n","Epoch 23: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3998 - accuracy: 0.8453 - val_loss: 0.4055 - val_accuracy: 0.8412\n","Epoch 24/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4029 - accuracy: 0.8287\n","Epoch 24: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8261 - val_loss: 0.4124 - val_accuracy: 0.8412\n","Epoch 25/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4681 - accuracy: 0.8382\n","Epoch 25: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4585 - accuracy: 0.8386 - val_loss: 0.5332 - val_accuracy: 0.8546\n","Epoch 26/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4580 - accuracy: 0.8371\n","Epoch 26: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.8415 - val_loss: 0.4267 - val_accuracy: 0.8479\n","Epoch 27/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3975 - accuracy: 0.8471\n","Epoch 27: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8473 - val_loss: 0.4507 - val_accuracy: 0.8143\n","Epoch 28/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4351 - accuracy: 0.8188\n","Epoch 28: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8357 - val_loss: 0.7320 - val_accuracy: 0.8233\n","Epoch 29/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4677 - accuracy: 0.8225\n","Epoch 29: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.8280 - val_loss: 0.4177 - val_accuracy: 0.8456\n","Epoch 30/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4020 - accuracy: 0.8527\n","Epoch 30: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8492 - val_loss: 0.4907 - val_accuracy: 0.8479\n","Epoch 31/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4362 - accuracy: 0.8404\n","Epoch 31: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4223 - accuracy: 0.8463 - val_loss: 0.3893 - val_accuracy: 0.8546\n","Epoch 32/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.3691 - accuracy: 0.8555\n","Epoch 32: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3703 - accuracy: 0.8521 - val_loss: 0.4228 - val_accuracy: 0.8412\n","Epoch 33/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.3658 - accuracy: 0.8537\n","Epoch 33: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3649 - accuracy: 0.8588 - val_loss: 0.4475 - val_accuracy: 0.8479\n","Epoch 34/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3905 - accuracy: 0.8413\n","Epoch 34: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8415 - val_loss: 0.4124 - val_accuracy: 0.8367\n","Epoch 35/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3700 - accuracy: 0.8474\n","Epoch 35: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8463 - val_loss: 0.5906 - val_accuracy: 0.8300\n","Epoch 36/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4037 - accuracy: 0.8538\n","Epoch 36: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8559 - val_loss: 0.4039 - val_accuracy: 0.8456\n","Epoch 37/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3151 - accuracy: 0.8785\n","Epoch 37: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3201 - accuracy: 0.8780 - val_loss: 0.4343 - val_accuracy: 0.8479\n","Epoch 38/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.3463 - accuracy: 0.8620\n","Epoch 38: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3704 - accuracy: 0.8521 - val_loss: 0.4214 - val_accuracy: 0.8591\n","Epoch 39/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3394 - accuracy: 0.8486\n","Epoch 39: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3635 - accuracy: 0.8405 - val_loss: 0.4136 - val_accuracy: 0.8322\n","Epoch 40/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3716 - accuracy: 0.8516\n","Epoch 40: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.8444 - val_loss: 0.5060 - val_accuracy: 0.8367\n","Epoch 41/100\n","23/33 [===================>..........] - ETA: 0s - loss: 0.3752 - accuracy: 0.8601\n","Epoch 41: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8521 - val_loss: 0.3939 - val_accuracy: 0.8233\n","Epoch 42/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.3442 - accuracy: 0.8587\n","Epoch 42: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3375 - accuracy: 0.8598 - val_loss: 0.3897 - val_accuracy: 0.8322\n","Epoch 43/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3559 - accuracy: 0.8576\n","Epoch 43: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3646 - accuracy: 0.8511 - val_loss: 0.4320 - val_accuracy: 0.8277\n","Epoch 44/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3878 - accuracy: 0.8498\n","Epoch 44: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3920 - accuracy: 0.8492 - val_loss: 0.3887 - val_accuracy: 0.8277\n","Epoch 45/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3938 - accuracy: 0.8449\n","Epoch 45: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8453 - val_loss: 0.3778 - val_accuracy: 0.8367\n","Epoch 46/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.3191 - accuracy: 0.8700\n","Epoch 46: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3352 - accuracy: 0.8665 - val_loss: 0.3951 - val_accuracy: 0.8591\n","Epoch 47/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3891 - accuracy: 0.8627\n","Epoch 47: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4035 - accuracy: 0.8569 - val_loss: 0.4540 - val_accuracy: 0.8188\n","Epoch 48/100\n","23/33 [===================>..........] - ETA: 0s - loss: 0.3562 - accuracy: 0.8736\n","Epoch 48: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3637 - accuracy: 0.8626 - val_loss: 0.4661 - val_accuracy: 0.8188\n","Epoch 49/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4003 - accuracy: 0.8661\n","Epoch 49: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4074 - accuracy: 0.8665 - val_loss: 0.3899 - val_accuracy: 0.8456\n","Epoch 50/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3412 - accuracy: 0.8683\n","Epoch 50: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3612 - accuracy: 0.8617 - val_loss: 0.4245 - val_accuracy: 0.8456\n","Epoch 51/100\n","24/33 [====================>.........] - ETA: 0s - loss: 0.3871 - accuracy: 0.8451\n","Epoch 51: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8482 - val_loss: 0.5049 - val_accuracy: 0.8233\n","Epoch 52/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4211 - accuracy: 0.8498\n","Epoch 52: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.8473 - val_loss: 0.4322 - val_accuracy: 0.8591\n","Epoch 53/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3570 - accuracy: 0.8661\n","Epoch 53: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.3692 - accuracy: 0.8588 - val_loss: 0.4147 - val_accuracy: 0.8434\n","Epoch 54/100\n","33/33 [==============================] - ETA: 0s - loss: 0.4063 - accuracy: 0.8549\n","Epoch 54: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4063 - accuracy: 0.8549 - val_loss: 0.5582 - val_accuracy: 0.8300\n","Epoch 55/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4401 - accuracy: 0.8448\n","Epoch 55: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4252 - accuracy: 0.8482 - val_loss: 0.4718 - val_accuracy: 0.8591\n","Epoch 56/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.4325 - accuracy: 0.8406\n","Epoch 56: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4214 - accuracy: 0.8425 - val_loss: 0.4252 - val_accuracy: 0.8210\n","Epoch 57/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3547 - accuracy: 0.8687\n","Epoch 57: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 11ms/step - loss: 0.3638 - accuracy: 0.8655 - val_loss: 0.4162 - val_accuracy: 0.8635\n","Epoch 58/100\n","31/33 [===========================>..] - ETA: 0s - loss: 0.3604 - accuracy: 0.8538\n","Epoch 58: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3636 - accuracy: 0.8521 - val_loss: 0.5754 - val_accuracy: 0.8345\n","Epoch 59/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4034 - accuracy: 0.8504\n","Epoch 59: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.3937 - accuracy: 0.8530 - val_loss: 0.4928 - val_accuracy: 0.8367\n","Epoch 60/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3704 - accuracy: 0.8719\n","Epoch 60: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3742 - accuracy: 0.8703 - val_loss: 0.4058 - val_accuracy: 0.8613\n","Epoch 61/100\n","30/33 [==========================>...] - ETA: 0s - loss: 0.3770 - accuracy: 0.8510\n","Epoch 61: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3844 - accuracy: 0.8492 - val_loss: 0.5165 - val_accuracy: 0.8098\n","Epoch 62/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4421 - accuracy: 0.8438\n","Epoch 62: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 9ms/step - loss: 0.4234 - accuracy: 0.8521 - val_loss: 0.4379 - val_accuracy: 0.8389\n","Epoch 63/100\n","23/33 [===================>..........] - ETA: 0s - loss: 0.3899 - accuracy: 0.8587\n","Epoch 63: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.3937 - accuracy: 0.8588 - val_loss: 0.5419 - val_accuracy: 0.8277\n","Epoch 64/100\n","33/33 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.8530\n","Epoch 64: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 8ms/step - loss: 0.4267 - accuracy: 0.8530 - val_loss: 0.4519 - val_accuracy: 0.8546\n","Epoch 65/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3897 - accuracy: 0.8519\n","Epoch 65: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8501 - val_loss: 0.5257 - val_accuracy: 0.8456\n","Epoch 66/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4373 - accuracy: 0.8248\n","Epoch 66: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8329 - val_loss: 0.4143 - val_accuracy: 0.8367\n","Epoch 67/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4133 - accuracy: 0.8305\n","Epoch 67: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8338 - val_loss: 0.5523 - val_accuracy: 0.8143\n","Epoch 68/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4037 - accuracy: 0.8527\n","Epoch 68: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4069 - accuracy: 0.8501 - val_loss: 0.4416 - val_accuracy: 0.8434\n","Epoch 69/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.5240 - accuracy: 0.8288\n","Epoch 69: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4913 - accuracy: 0.8357 - val_loss: 0.3947 - val_accuracy: 0.8345\n","Epoch 70/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3538 - accuracy: 0.8681\n","Epoch 70: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8655 - val_loss: 0.4178 - val_accuracy: 0.8098\n","Epoch 71/100\n","33/33 [==============================] - ETA: 0s - loss: 0.3749 - accuracy: 0.8530\n","Epoch 71: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3749 - accuracy: 0.8530 - val_loss: 0.4901 - val_accuracy: 0.8456\n","Epoch 72/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4642 - accuracy: 0.8353\n","Epoch 72: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.8425 - val_loss: 0.4022 - val_accuracy: 0.8635\n","Epoch 73/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.4577 - accuracy: 0.8500\n","Epoch 73: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.8405 - val_loss: 0.4321 - val_accuracy: 0.8501\n","Epoch 74/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4321 - accuracy: 0.8582\n","Epoch 74: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.8578 - val_loss: 0.4271 - val_accuracy: 0.8479\n","Epoch 75/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4272 - accuracy: 0.8666\n","Epoch 75: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8694 - val_loss: 0.3519 - val_accuracy: 0.8702\n","Epoch 76/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3649 - accuracy: 0.8634\n","Epoch 76: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3714 - accuracy: 0.8646 - val_loss: 0.5360 - val_accuracy: 0.8367\n","Epoch 77/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3737 - accuracy: 0.8666\n","Epoch 77: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8655 - val_loss: 0.5681 - val_accuracy: 0.8076\n","Epoch 78/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3764 - accuracy: 0.8627\n","Epoch 78: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8559 - val_loss: 0.4085 - val_accuracy: 0.8702\n","Epoch 79/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3594 - accuracy: 0.8738\n","Epoch 79: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3733 - accuracy: 0.8636 - val_loss: 0.4273 - val_accuracy: 0.8658\n","Epoch 80/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3732 - accuracy: 0.8669\n","Epoch 80: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8617 - val_loss: 0.3647 - val_accuracy: 0.8613\n","Epoch 81/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4131 - accuracy: 0.8345\n","Epoch 81: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8444 - val_loss: 0.4264 - val_accuracy: 0.8434\n","Epoch 82/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4258 - accuracy: 0.8461\n","Epoch 82: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.8444 - val_loss: 0.6895 - val_accuracy: 0.8523\n","Epoch 83/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.4305 - accuracy: 0.8534\n","Epoch 83: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.8569 - val_loss: 0.3736 - val_accuracy: 0.8613\n","Epoch 84/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.3703 - accuracy: 0.8575\n","Epoch 84: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3779 - accuracy: 0.8588 - val_loss: 0.4128 - val_accuracy: 0.8412\n","Epoch 85/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4151 - accuracy: 0.8391\n","Epoch 85: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8386 - val_loss: 0.5077 - val_accuracy: 0.8389\n","Epoch 86/100\n","26/33 [======================>.......] - ETA: 0s - loss: 0.3579 - accuracy: 0.8738\n","Epoch 86: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3663 - accuracy: 0.8722 - val_loss: 0.3746 - val_accuracy: 0.8635\n","Epoch 87/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.4025 - accuracy: 0.8472\n","Epoch 87: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.8588 - val_loss: 0.3885 - val_accuracy: 0.8613\n","Epoch 88/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3576 - accuracy: 0.8484\n","Epoch 88: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3539 - accuracy: 0.8578 - val_loss: 0.3978 - val_accuracy: 0.8613\n","Epoch 89/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3779 - accuracy: 0.8414\n","Epoch 89: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8453 - val_loss: 0.3935 - val_accuracy: 0.8591\n","Epoch 90/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3204 - accuracy: 0.8638\n","Epoch 90: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.8617 - val_loss: 0.5942 - val_accuracy: 0.8188\n","Epoch 91/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.4311 - accuracy: 0.8415\n","Epoch 91: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.8511 - val_loss: 0.4179 - val_accuracy: 0.8501\n","Epoch 92/100\n","25/33 [=====================>........] - ETA: 0s - loss: 0.3172 - accuracy: 0.8750\n","Epoch 92: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3385 - accuracy: 0.8607 - val_loss: 0.3549 - val_accuracy: 0.8389\n","Epoch 93/100\n","28/33 [========================>.....] - ETA: 0s - loss: 0.3392 - accuracy: 0.8493\n","Epoch 93: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3309 - accuracy: 0.8549 - val_loss: 0.4917 - val_accuracy: 0.8054\n","Epoch 94/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3527 - accuracy: 0.8634\n","Epoch 94: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 6ms/step - loss: 0.3442 - accuracy: 0.8694 - val_loss: 0.3545 - val_accuracy: 0.8658\n","Epoch 95/100\n","27/33 [=======================>......] - ETA: 0s - loss: 0.3628 - accuracy: 0.8530\n","Epoch 95: val_accuracy did not improve from 0.87919\n","33/33 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.8511 - val_loss: 0.4616 - val_accuracy: 0.8479\n","20/20 [==============================] - 0s 2ms/step\n","0.8746081504702194\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["20/20 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.8605\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["109/115 [===========================>..] - ETA: 0s - loss: 2.6011 - accuracy: 0.3555\n","Epoch 1: val_accuracy improved from -inf to 0.51080, saving model to pendigits_tnn2.h5\n","115/115 [==============================] - 2s 8ms/step - loss: 2.5457 - accuracy: 0.3648 - val_loss: 1.6631 - val_accuracy: 0.5108\n","Epoch 2/100\n","110/115 [===========================>..] - ETA: 0s - loss: 1.2603 - accuracy: 0.6006\n","Epoch 2: val_accuracy improved from 0.51080 to 0.64549, saving model to pendigits_tnn2.h5\n","115/115 [==============================] - 1s 10ms/step - loss: 1.2609 - accuracy: 0.5979 - val_loss: 1.0241 - val_accuracy: 0.6455\n","Epoch 3/100\n","106/115 [==========================>...] - ETA: 0s - loss: 1.0937 - accuracy: 0.6445\n","Epoch 3: val_accuracy improved from 0.64549 to 0.64676, saving model to pendigits_tnn2.h5\n","115/115 [==============================] - 1s 5ms/step - loss: 1.0832 - accuracy: 0.6486 - val_loss: 0.9748 - val_accuracy: 0.6468\n","Epoch 4/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.9363 - accuracy: 0.6770\n","Epoch 4: val_accuracy improved from 0.64676 to 0.66963, saving model to pendigits_tnn2.h5\n","115/115 [==============================] - 1s 6ms/step - loss: 0.9244 - accuracy: 0.6846 - val_loss: 0.9594 - val_accuracy: 0.6696\n","Epoch 5/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.8801 - accuracy: 0.7159\n","Epoch 5: val_accuracy improved from 0.66963 to 0.74396, saving model to pendigits_tnn2.h5\n","115/115 [==============================] - 1s 6ms/step - loss: 0.8732 - accuracy: 0.7192 - val_loss: 0.7600 - val_accuracy: 0.7440\n","Epoch 6/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.7265 - accuracy: 0.7557\n","Epoch 6: val_accuracy did not improve from 0.74396\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7243 - accuracy: 0.7543 - val_loss: 0.7201 - val_accuracy: 0.7376\n","Epoch 7/100\n","115/115 [==============================] - ETA: 0s - loss: 0.7023 - accuracy: 0.7589\n","Epoch 7: val_accuracy improved from 0.74396 to 0.76557, saving model to pendigits_tnn2.h5\n","115/115 [==============================] - 1s 6ms/step - loss: 0.7023 - accuracy: 0.7589 - val_loss: 0.6326 - val_accuracy: 0.7656\n","Epoch 8/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.7071 - accuracy: 0.7709\n","Epoch 8: val_accuracy did not improve from 0.76557\n","115/115 [==============================] - 1s 6ms/step - loss: 0.7075 - accuracy: 0.7715 - val_loss: 0.7558 - val_accuracy: 0.7306\n","Epoch 9/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6978 - accuracy: 0.7642\n","Epoch 9: val_accuracy improved from 0.76557 to 0.82592, saving model to pendigits_tnn2.h5\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7646 - val_loss: 0.6097 - val_accuracy: 0.8259\n","Epoch 10/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6276 - accuracy: 0.7930\n","Epoch 10: val_accuracy did not improve from 0.82592\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6213 - accuracy: 0.7949 - val_loss: 0.5557 - val_accuracy: 0.7840\n","Epoch 11/100\n","115/115 [==============================] - ETA: 0s - loss: 0.6875 - accuracy: 0.7813\n","Epoch 11: val_accuracy did not improve from 0.82592\n","115/115 [==============================] - 1s 9ms/step - loss: 0.6875 - accuracy: 0.7813 - val_loss: 0.5838 - val_accuracy: 0.7884\n","Epoch 12/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.6691 - accuracy: 0.7824\n","Epoch 12: val_accuracy did not improve from 0.82592\n","115/115 [==============================] - 1s 8ms/step - loss: 0.6718 - accuracy: 0.7821 - val_loss: 0.6365 - val_accuracy: 0.8030\n","Epoch 13/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.6433 - accuracy: 0.7976\n","Epoch 13: val_accuracy did not improve from 0.82592\n","115/115 [==============================] - 1s 8ms/step - loss: 0.6393 - accuracy: 0.7968 - val_loss: 0.6081 - val_accuracy: 0.7706\n","Epoch 14/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.6039 - accuracy: 0.8018\n","Epoch 14: val_accuracy improved from 0.82592 to 0.85133, saving model to pendigits_tnn2.h5\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6051 - accuracy: 0.8009 - val_loss: 0.5085 - val_accuracy: 0.8513\n","Epoch 15/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5981 - accuracy: 0.8053\n","Epoch 15: val_accuracy did not improve from 0.85133\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5948 - accuracy: 0.8066 - val_loss: 0.6080 - val_accuracy: 0.8056\n","Epoch 16/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.5841 - accuracy: 0.8091\n","Epoch 16: val_accuracy did not improve from 0.85133\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5840 - accuracy: 0.8099 - val_loss: 0.7713 - val_accuracy: 0.7452\n","Epoch 17/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.6017 - accuracy: 0.8158\n","Epoch 17: val_accuracy did not improve from 0.85133\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6141 - accuracy: 0.8131 - val_loss: 0.5762 - val_accuracy: 0.8113\n","Epoch 18/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5888 - accuracy: 0.8143\n","Epoch 18: val_accuracy did not improve from 0.85133\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5900 - accuracy: 0.8134 - val_loss: 0.6200 - val_accuracy: 0.8259\n","Epoch 19/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.5413 - accuracy: 0.8335\n","Epoch 19: val_accuracy did not improve from 0.85133\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5415 - accuracy: 0.8344 - val_loss: 0.5910 - val_accuracy: 0.7853\n","Epoch 20/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4961 - accuracy: 0.8465\n","Epoch 20: val_accuracy did not improve from 0.85133\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4935 - accuracy: 0.8453 - val_loss: 0.6132 - val_accuracy: 0.8202\n","Epoch 21/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.5233 - accuracy: 0.8331\n","Epoch 21: val_accuracy did not improve from 0.85133\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5202 - accuracy: 0.8336 - val_loss: 0.4748 - val_accuracy: 0.8469\n","Epoch 22/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.5250 - accuracy: 0.8321\n","Epoch 22: val_accuracy did not improve from 0.85133\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5217 - accuracy: 0.8338 - val_loss: 0.5109 - val_accuracy: 0.8475\n","Epoch 23/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5438 - accuracy: 0.8259\n","Epoch 23: val_accuracy improved from 0.85133 to 0.85197, saving model to pendigits_tnn2.h5\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5318 - accuracy: 0.8284 - val_loss: 0.4854 - val_accuracy: 0.8520\n","Epoch 24/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5280 - accuracy: 0.8289\n","Epoch 24: val_accuracy did not improve from 0.85197\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5280 - accuracy: 0.8289 - val_loss: 0.6789 - val_accuracy: 0.8069\n","Epoch 25/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.5481 - accuracy: 0.8210\n","Epoch 25: val_accuracy did not improve from 0.85197\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5427 - accuracy: 0.8221 - val_loss: 0.5945 - val_accuracy: 0.8234\n","Epoch 26/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4710 - accuracy: 0.8508\n","Epoch 26: val_accuracy did not improve from 0.85197\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4708 - accuracy: 0.8502 - val_loss: 0.5388 - val_accuracy: 0.8323\n","Epoch 27/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4756 - accuracy: 0.8423\n","Epoch 27: val_accuracy improved from 0.85197 to 0.87611, saving model to pendigits_tnn2.h5\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4756 - accuracy: 0.8423 - val_loss: 0.4376 - val_accuracy: 0.8761\n","Epoch 28/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.5313 - accuracy: 0.8182\n","Epoch 28: val_accuracy did not improve from 0.87611\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5265 - accuracy: 0.8194 - val_loss: 0.5281 - val_accuracy: 0.8431\n","Epoch 29/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.5523 - accuracy: 0.8294\n","Epoch 29: val_accuracy did not improve from 0.87611\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5507 - accuracy: 0.8300 - val_loss: 0.5076 - val_accuracy: 0.8424\n","Epoch 30/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4711 - accuracy: 0.8407\n","Epoch 30: val_accuracy improved from 0.87611 to 0.87802, saving model to pendigits_tnn2.h5\n","115/115 [==============================] - 1s 9ms/step - loss: 0.4703 - accuracy: 0.8412 - val_loss: 0.4147 - val_accuracy: 0.8780\n","Epoch 31/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4315 - accuracy: 0.8573\n","Epoch 31: val_accuracy did not improve from 0.87802\n","115/115 [==============================] - 1s 9ms/step - loss: 0.4288 - accuracy: 0.8578 - val_loss: 0.3933 - val_accuracy: 0.8736\n","Epoch 32/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.4990 - accuracy: 0.8358\n","Epoch 32: val_accuracy did not improve from 0.87802\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4928 - accuracy: 0.8357 - val_loss: 0.4571 - val_accuracy: 0.8431\n","Epoch 33/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5167 - accuracy: 0.8255\n","Epoch 33: val_accuracy did not improve from 0.87802\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5246 - accuracy: 0.8232 - val_loss: 0.5275 - val_accuracy: 0.8412\n","Epoch 34/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.5734 - accuracy: 0.8140\n","Epoch 34: val_accuracy did not improve from 0.87802\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5826 - accuracy: 0.8096 - val_loss: 0.7896 - val_accuracy: 0.7611\n","Epoch 35/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.4874 - accuracy: 0.8469\n","Epoch 35: val_accuracy did not improve from 0.87802\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4878 - accuracy: 0.8475 - val_loss: 0.4989 - val_accuracy: 0.8640\n","Epoch 36/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.5088 - accuracy: 0.8390\n","Epoch 36: val_accuracy did not improve from 0.87802\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5113 - accuracy: 0.8385 - val_loss: 0.6400 - val_accuracy: 0.7579\n","Epoch 37/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5000 - accuracy: 0.8377\n","Epoch 37: val_accuracy did not improve from 0.87802\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4957 - accuracy: 0.8379 - val_loss: 0.4299 - val_accuracy: 0.8736\n","Epoch 38/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5006 - accuracy: 0.8499\n","Epoch 38: val_accuracy did not improve from 0.87802\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4980 - accuracy: 0.8507 - val_loss: 0.4303 - val_accuracy: 0.8679\n","Epoch 39/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4878 - accuracy: 0.8461\n","Epoch 39: val_accuracy improved from 0.87802 to 0.88056, saving model to pendigits_tnn2.h5\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4833 - accuracy: 0.8445 - val_loss: 0.3889 - val_accuracy: 0.8806\n","Epoch 40/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.4483 - accuracy: 0.8469\n","Epoch 40: val_accuracy did not improve from 0.88056\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4506 - accuracy: 0.8458 - val_loss: 0.4764 - val_accuracy: 0.8158\n","Epoch 41/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4813 - accuracy: 0.8434\n","Epoch 41: val_accuracy did not improve from 0.88056\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4817 - accuracy: 0.8428 - val_loss: 0.4840 - val_accuracy: 0.8304\n","Epoch 42/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4630 - accuracy: 0.8549\n","Epoch 42: val_accuracy did not improve from 0.88056\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4624 - accuracy: 0.8551 - val_loss: 0.4325 - val_accuracy: 0.8647\n","Epoch 43/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4822 - accuracy: 0.8399\n","Epoch 43: val_accuracy improved from 0.88056 to 0.89327, saving model to pendigits_tnn2.h5\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4727 - accuracy: 0.8428 - val_loss: 0.3796 - val_accuracy: 0.8933\n","Epoch 44/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4295 - accuracy: 0.8544\n","Epoch 44: val_accuracy did not improve from 0.89327\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4339 - accuracy: 0.8556 - val_loss: 0.4235 - val_accuracy: 0.8856\n","Epoch 45/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.4826 - accuracy: 0.8460\n","Epoch 45: val_accuracy did not improve from 0.89327\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4863 - accuracy: 0.8450 - val_loss: 0.4529 - val_accuracy: 0.8609\n","Epoch 46/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.4318 - accuracy: 0.8572\n","Epoch 46: val_accuracy did not improve from 0.89327\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4310 - accuracy: 0.8594 - val_loss: 0.3531 - val_accuracy: 0.8742\n","Epoch 47/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.3933 - accuracy: 0.8768\n","Epoch 47: val_accuracy did not improve from 0.89327\n","115/115 [==============================] - 1s 5ms/step - loss: 0.3956 - accuracy: 0.8766 - val_loss: 0.4910 - val_accuracy: 0.8469\n","Epoch 48/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.3959 - accuracy: 0.8616\n","Epoch 48: val_accuracy did not improve from 0.89327\n","115/115 [==============================] - 1s 6ms/step - loss: 0.3999 - accuracy: 0.8611 - val_loss: 0.3755 - val_accuracy: 0.8869\n","Epoch 49/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.4651 - accuracy: 0.8432\n","Epoch 49: val_accuracy did not improve from 0.89327\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4613 - accuracy: 0.8447 - val_loss: 0.4366 - val_accuracy: 0.8494\n","Epoch 50/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.8529\n","Epoch 50: val_accuracy did not improve from 0.89327\n","115/115 [==============================] - 1s 9ms/step - loss: 0.4397 - accuracy: 0.8529 - val_loss: 0.4466 - val_accuracy: 0.8571\n","Epoch 51/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.4876 - accuracy: 0.8432\n","Epoch 51: val_accuracy did not improve from 0.89327\n","115/115 [==============================] - 1s 9ms/step - loss: 0.5000 - accuracy: 0.8382 - val_loss: 0.5783 - val_accuracy: 0.8113\n","Epoch 52/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.4471 - accuracy: 0.8537\n","Epoch 52: val_accuracy did not improve from 0.89327\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4492 - accuracy: 0.8532 - val_loss: 0.5725 - val_accuracy: 0.8208\n","Epoch 53/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.4583 - accuracy: 0.8536\n","Epoch 53: val_accuracy did not improve from 0.89327\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4648 - accuracy: 0.8518 - val_loss: 0.3901 - val_accuracy: 0.8640\n","Epoch 54/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.4470 - accuracy: 0.8483\n","Epoch 54: val_accuracy did not improve from 0.89327\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4531 - accuracy: 0.8469 - val_loss: 0.4331 - val_accuracy: 0.8545\n","Epoch 55/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4485 - accuracy: 0.8609\n","Epoch 55: val_accuracy did not improve from 0.89327\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4405 - accuracy: 0.8597 - val_loss: 0.5349 - val_accuracy: 0.8659\n","Epoch 56/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.4773 - accuracy: 0.8564\n","Epoch 56: val_accuracy did not improve from 0.89327\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4780 - accuracy: 0.8570 - val_loss: 0.4104 - val_accuracy: 0.8672\n","Epoch 57/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.4792 - accuracy: 0.8557\n","Epoch 57: val_accuracy did not improve from 0.89327\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4635 - accuracy: 0.8594 - val_loss: 0.3886 - val_accuracy: 0.8837\n","Epoch 58/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4194 - accuracy: 0.8651\n","Epoch 58: val_accuracy did not improve from 0.89327\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4173 - accuracy: 0.8660 - val_loss: 0.4456 - val_accuracy: 0.8647\n","Epoch 59/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.3990 - accuracy: 0.8717\n","Epoch 59: val_accuracy improved from 0.89327 to 0.89644, saving model to pendigits_tnn2.h5\n","115/115 [==============================] - 1s 5ms/step - loss: 0.3890 - accuracy: 0.8736 - val_loss: 0.3455 - val_accuracy: 0.8964\n","Epoch 60/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4143 - accuracy: 0.8686\n","Epoch 60: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4113 - accuracy: 0.8703 - val_loss: 0.5432 - val_accuracy: 0.8812\n","Epoch 61/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4234 - accuracy: 0.8621\n","Epoch 61: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4542 - accuracy: 0.8526 - val_loss: 0.5532 - val_accuracy: 0.7649\n","Epoch 62/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.4135 - accuracy: 0.8669\n","Epoch 62: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4136 - accuracy: 0.8665 - val_loss: 0.3597 - val_accuracy: 0.8787\n","Epoch 63/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.4366 - accuracy: 0.8530\n","Epoch 63: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4323 - accuracy: 0.8543 - val_loss: 0.4023 - val_accuracy: 0.8640\n","Epoch 64/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.3920 - accuracy: 0.8738\n","Epoch 64: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4120 - accuracy: 0.8665 - val_loss: 0.5076 - val_accuracy: 0.8475\n","Epoch 65/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4298 - accuracy: 0.8647\n","Epoch 65: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4246 - accuracy: 0.8654 - val_loss: 0.4812 - val_accuracy: 0.8691\n","Epoch 66/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4719 - accuracy: 0.8478\n","Epoch 66: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4625 - accuracy: 0.8507 - val_loss: 0.4702 - val_accuracy: 0.8539\n","Epoch 67/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.4133 - accuracy: 0.8613\n","Epoch 67: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4118 - accuracy: 0.8611 - val_loss: 0.3801 - val_accuracy: 0.8926\n","Epoch 68/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.4620 - accuracy: 0.8501\n","Epoch 68: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4600 - accuracy: 0.8518 - val_loss: 0.4277 - val_accuracy: 0.8837\n","Epoch 69/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.4783 - accuracy: 0.8483\n","Epoch 69: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4768 - accuracy: 0.8496 - val_loss: 0.5190 - val_accuracy: 0.8253\n","Epoch 70/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.4287 - accuracy: 0.8556\n","Epoch 70: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4260 - accuracy: 0.8551 - val_loss: 0.5748 - val_accuracy: 0.8056\n","Epoch 71/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4269 - accuracy: 0.8712\n","Epoch 71: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4254 - accuracy: 0.8725 - val_loss: 0.4032 - val_accuracy: 0.8628\n","Epoch 72/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.4151 - accuracy: 0.8619\n","Epoch 72: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4170 - accuracy: 0.8611 - val_loss: 0.5841 - val_accuracy: 0.8126\n","Epoch 73/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.3825 - accuracy: 0.8788\n","Epoch 73: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.3870 - accuracy: 0.8782 - val_loss: 0.4216 - val_accuracy: 0.8494\n","Epoch 74/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4143 - accuracy: 0.8648\n","Epoch 74: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8676 - val_loss: 0.3921 - val_accuracy: 0.8736\n","Epoch 75/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4176 - accuracy: 0.8659\n","Epoch 75: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4162 - accuracy: 0.8662 - val_loss: 0.4326 - val_accuracy: 0.8742\n","Epoch 76/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4571 - accuracy: 0.8573\n","Epoch 76: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4483 - accuracy: 0.8575 - val_loss: 0.5153 - val_accuracy: 0.8577\n","Epoch 77/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.4934 - accuracy: 0.8482\n","Epoch 77: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4851 - accuracy: 0.8491 - val_loss: 0.5819 - val_accuracy: 0.8215\n","Epoch 78/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4409 - accuracy: 0.8568\n","Epoch 78: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4367 - accuracy: 0.8581 - val_loss: 0.4893 - val_accuracy: 0.8698\n","Epoch 79/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4252 - accuracy: 0.8631\n","Epoch 79: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4216 - accuracy: 0.8638 - val_loss: 0.3535 - val_accuracy: 0.8875\n","71/71 [==============================] - 0s 2ms/step\n","0.8848377056469542\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["110/115 [===========================>..] - ETA: 0s - loss: 3.3562 - accuracy: 0.2358\n","Epoch 1: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 2s 8ms/step - loss: 3.2890 - accuracy: 0.2438 - val_loss: 1.4788 - val_accuracy: 0.4956\n","Epoch 2/100\n","109/115 [===========================>..] - ETA: 0s - loss: 1.3807 - accuracy: 0.5579\n","Epoch 2: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 1.3690 - accuracy: 0.5622 - val_loss: 1.1293 - val_accuracy: 0.6086\n","Epoch 3/100\n","111/115 [===========================>..] - ETA: 0s - loss: 1.1479 - accuracy: 0.6244\n","Epoch 3: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 1.1420 - accuracy: 0.6257 - val_loss: 0.8922 - val_accuracy: 0.7014\n","Epoch 4/100\n","108/115 [===========================>..] - ETA: 0s - loss: 1.0155 - accuracy: 0.6742\n","Epoch 4: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 1.0186 - accuracy: 0.6720 - val_loss: 0.7692 - val_accuracy: 0.7681\n","Epoch 5/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.9415 - accuracy: 0.7046\n","Epoch 5: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 9ms/step - loss: 0.9375 - accuracy: 0.7058 - val_loss: 0.7635 - val_accuracy: 0.7249\n","Epoch 6/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.8081 - accuracy: 0.7316\n","Epoch 6: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.8037 - accuracy: 0.7328 - val_loss: 0.8578 - val_accuracy: 0.7097\n","Epoch 7/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.7899 - accuracy: 0.7534\n","Epoch 7: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.7862 - accuracy: 0.7543 - val_loss: 0.8767 - val_accuracy: 0.7236\n","Epoch 8/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.7375 - accuracy: 0.7473\n","Epoch 8: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7348 - accuracy: 0.7475 - val_loss: 0.7835 - val_accuracy: 0.6703\n","Epoch 9/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.7172 - accuracy: 0.7582\n","Epoch 9: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7046 - accuracy: 0.7625 - val_loss: 0.7105 - val_accuracy: 0.7516\n","Epoch 10/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6348 - accuracy: 0.7857\n","Epoch 10: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6361 - accuracy: 0.7892 - val_loss: 0.5545 - val_accuracy: 0.8310\n","Epoch 11/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.6074 - accuracy: 0.7890\n","Epoch 11: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6051 - accuracy: 0.7892 - val_loss: 0.6085 - val_accuracy: 0.7986\n","Epoch 12/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.6159 - accuracy: 0.7903\n","Epoch 12: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6118 - accuracy: 0.7916 - val_loss: 0.7195 - val_accuracy: 0.7649\n","Epoch 13/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.6153 - accuracy: 0.7931\n","Epoch 13: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6141 - accuracy: 0.7943 - val_loss: 0.5933 - val_accuracy: 0.8285\n","Epoch 14/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.6025 - accuracy: 0.8090\n","Epoch 14: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6096 - accuracy: 0.8050 - val_loss: 0.6830 - val_accuracy: 0.7872\n","Epoch 15/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.6277 - accuracy: 0.7955\n","Epoch 15: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6437 - accuracy: 0.7908 - val_loss: 0.6481 - val_accuracy: 0.7783\n","Epoch 16/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.6070 - accuracy: 0.7934\n","Epoch 16: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6055 - accuracy: 0.7943 - val_loss: 0.5883 - val_accuracy: 0.8100\n","Epoch 17/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.6069 - accuracy: 0.7975\n","Epoch 17: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5982 - accuracy: 0.7984 - val_loss: 0.5648 - val_accuracy: 0.8247\n","Epoch 18/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6714 - accuracy: 0.7812\n","Epoch 18: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6828 - accuracy: 0.7780 - val_loss: 0.6104 - val_accuracy: 0.8183\n","Epoch 19/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.6464 - accuracy: 0.8024\n","Epoch 19: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6510 - accuracy: 0.8001 - val_loss: 0.6878 - val_accuracy: 0.8151\n","Epoch 20/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5607 - accuracy: 0.8244\n","Epoch 20: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5554 - accuracy: 0.8232 - val_loss: 0.4695 - val_accuracy: 0.8202\n","Epoch 21/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.5168 - accuracy: 0.8300\n","Epoch 21: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5165 - accuracy: 0.8297 - val_loss: 0.6280 - val_accuracy: 0.7859\n","Epoch 22/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.5199 - accuracy: 0.8361\n","Epoch 22: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5179 - accuracy: 0.8366 - val_loss: 0.5181 - val_accuracy: 0.8208\n","Epoch 23/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.5041 - accuracy: 0.8361\n","Epoch 23: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5008 - accuracy: 0.8366 - val_loss: 0.3968 - val_accuracy: 0.8844\n","Epoch 24/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.5281 - accuracy: 0.8266\n","Epoch 24: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 9ms/step - loss: 0.5263 - accuracy: 0.8273 - val_loss: 0.5832 - val_accuracy: 0.8005\n","Epoch 25/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.5057 - accuracy: 0.8356\n","Epoch 25: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4976 - accuracy: 0.8379 - val_loss: 0.4375 - val_accuracy: 0.8679\n","Epoch 26/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4826 - accuracy: 0.8374\n","Epoch 26: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 9ms/step - loss: 0.4821 - accuracy: 0.8379 - val_loss: 0.4361 - val_accuracy: 0.8755\n","Epoch 27/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4778 - accuracy: 0.8444\n","Epoch 27: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4865 - accuracy: 0.8420 - val_loss: 0.5562 - val_accuracy: 0.8247\n","Epoch 28/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.5461 - accuracy: 0.8190\n","Epoch 28: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5382 - accuracy: 0.8186 - val_loss: 0.6427 - val_accuracy: 0.7967\n","Epoch 29/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4799 - accuracy: 0.8373\n","Epoch 29: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4801 - accuracy: 0.8379 - val_loss: 0.4681 - val_accuracy: 0.8208\n","Epoch 30/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4911 - accuracy: 0.8396\n","Epoch 30: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4939 - accuracy: 0.8390 - val_loss: 0.4811 - val_accuracy: 0.8380\n","Epoch 31/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4872 - accuracy: 0.8389\n","Epoch 31: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4883 - accuracy: 0.8371 - val_loss: 0.5033 - val_accuracy: 0.8571\n","Epoch 32/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4051 - accuracy: 0.8606\n","Epoch 32: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4064 - accuracy: 0.8592 - val_loss: 0.3835 - val_accuracy: 0.8755\n","Epoch 33/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4777 - accuracy: 0.8499\n","Epoch 33: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4714 - accuracy: 0.8504 - val_loss: 0.6236 - val_accuracy: 0.8170\n","Epoch 34/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.4623 - accuracy: 0.8435\n","Epoch 34: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4701 - accuracy: 0.8409 - val_loss: 0.4130 - val_accuracy: 0.8914\n","Epoch 35/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4578 - accuracy: 0.8550\n","Epoch 35: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4555 - accuracy: 0.8554 - val_loss: 0.4879 - val_accuracy: 0.8634\n","Epoch 36/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4491 - accuracy: 0.8555\n","Epoch 36: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4485 - accuracy: 0.8567 - val_loss: 0.4383 - val_accuracy: 0.8634\n","Epoch 37/100\n","102/115 [=========================>....] - ETA: 0s - loss: 0.4443 - accuracy: 0.8621\n","Epoch 37: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4525 - accuracy: 0.8589 - val_loss: 0.5812 - val_accuracy: 0.8297\n","Epoch 38/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4417 - accuracy: 0.8645\n","Epoch 38: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4397 - accuracy: 0.8654 - val_loss: 0.3359 - val_accuracy: 0.8831\n","Epoch 39/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4432 - accuracy: 0.8508\n","Epoch 39: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4476 - accuracy: 0.8507 - val_loss: 0.5040 - val_accuracy: 0.8234\n","Epoch 40/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4888 - accuracy: 0.8454\n","Epoch 40: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4879 - accuracy: 0.8445 - val_loss: 0.5045 - val_accuracy: 0.8717\n","Epoch 41/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4667 - accuracy: 0.8493\n","Epoch 41: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4649 - accuracy: 0.8507 - val_loss: 0.4316 - val_accuracy: 0.8895\n","Epoch 42/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4491 - accuracy: 0.8530\n","Epoch 42: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4511 - accuracy: 0.8526 - val_loss: 0.4367 - val_accuracy: 0.8698\n","Epoch 43/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.4479 - accuracy: 0.8530\n","Epoch 43: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4424 - accuracy: 0.8551 - val_loss: 0.3760 - val_accuracy: 0.8869\n","Epoch 44/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.4448 - accuracy: 0.8588\n","Epoch 44: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4397 - accuracy: 0.8616 - val_loss: 0.5570 - val_accuracy: 0.8355\n","Epoch 45/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.8471\n","Epoch 45: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4755 - accuracy: 0.8466 - val_loss: 0.4854 - val_accuracy: 0.8450\n","Epoch 46/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.5037 - accuracy: 0.8384\n","Epoch 46: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5030 - accuracy: 0.8371 - val_loss: 0.5109 - val_accuracy: 0.8119\n","Epoch 47/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4629 - accuracy: 0.8519\n","Epoch 47: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4708 - accuracy: 0.8502 - val_loss: 0.4863 - val_accuracy: 0.8450\n","Epoch 48/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4539 - accuracy: 0.8554\n","Epoch 48: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4580 - accuracy: 0.8529 - val_loss: 0.5903 - val_accuracy: 0.8100\n","Epoch 49/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4195 - accuracy: 0.8586\n","Epoch 49: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4208 - accuracy: 0.8586 - val_loss: 0.5565 - val_accuracy: 0.8018\n","Epoch 50/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.4150 - accuracy: 0.8717\n","Epoch 50: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4136 - accuracy: 0.8728 - val_loss: 0.4583 - val_accuracy: 0.8666\n","Epoch 51/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4154 - accuracy: 0.8624\n","Epoch 51: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4154 - accuracy: 0.8624 - val_loss: 0.4508 - val_accuracy: 0.8450\n","Epoch 52/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4542 - accuracy: 0.8492\n","Epoch 52: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4558 - accuracy: 0.8485 - val_loss: 0.5353 - val_accuracy: 0.8501\n","Epoch 53/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.4867 - accuracy: 0.8478\n","Epoch 53: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4788 - accuracy: 0.8499 - val_loss: 0.5269 - val_accuracy: 0.8640\n","Epoch 54/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.5098 - accuracy: 0.8358\n","Epoch 54: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4986 - accuracy: 0.8376 - val_loss: 0.4849 - val_accuracy: 0.8355\n","71/71 [==============================] - 0s 3ms/step\n","0.8786127167630058\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["114/115 [============================>.] - ETA: 0s - loss: 2.4186 - accuracy: 0.3583\n","Epoch 1: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 2s 8ms/step - loss: 2.4112 - accuracy: 0.3593 - val_loss: 1.3156 - val_accuracy: 0.5445\n","Epoch 2/100\n","113/115 [============================>.] - ETA: 0s - loss: 1.2835 - accuracy: 0.5711\n","Epoch 2: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 1.2789 - accuracy: 0.5729 - val_loss: 1.0284 - val_accuracy: 0.6341\n","Epoch 3/100\n","108/115 [===========================>..] - ETA: 0s - loss: 1.1013 - accuracy: 0.6406\n","Epoch 3: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 1.0873 - accuracy: 0.6464 - val_loss: 0.9999 - val_accuracy: 0.6474\n","Epoch 4/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.9372 - accuracy: 0.7014\n","Epoch 4: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.9463 - accuracy: 0.6990 - val_loss: 1.0911 - val_accuracy: 0.6252\n","Epoch 5/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.9132 - accuracy: 0.7080\n","Epoch 5: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.9127 - accuracy: 0.7074 - val_loss: 0.9457 - val_accuracy: 0.6874\n","Epoch 6/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.7845 - accuracy: 0.7439\n","Epoch 6: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.7774 - accuracy: 0.7461 - val_loss: 0.5899 - val_accuracy: 0.7694\n","Epoch 7/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.6544 - accuracy: 0.7806\n","Epoch 7: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6537 - accuracy: 0.7794 - val_loss: 0.5948 - val_accuracy: 0.8094\n","Epoch 8/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.7139 - accuracy: 0.7711\n","Epoch 8: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7108 - accuracy: 0.7712 - val_loss: 0.7298 - val_accuracy: 0.7611\n","Epoch 9/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.6997 - accuracy: 0.7724\n","Epoch 9: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7024 - accuracy: 0.7706 - val_loss: 0.7623 - val_accuracy: 0.7535\n","Epoch 10/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.6633 - accuracy: 0.7767\n","Epoch 10: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.6613 - accuracy: 0.7791 - val_loss: 0.5452 - val_accuracy: 0.8088\n","Epoch 11/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.6032 - accuracy: 0.8035\n","Epoch 11: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5961 - accuracy: 0.8060 - val_loss: 0.6782 - val_accuracy: 0.7776\n","Epoch 12/100\n","115/115 [==============================] - ETA: 0s - loss: 0.6551 - accuracy: 0.7922\n","Epoch 12: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6551 - accuracy: 0.7922 - val_loss: 0.6036 - val_accuracy: 0.7980\n","Epoch 13/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.7128 - accuracy: 0.7737\n","Epoch 13: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7145 - accuracy: 0.7712 - val_loss: 0.6126 - val_accuracy: 0.7802\n","Epoch 14/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6331 - accuracy: 0.7933\n","Epoch 14: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6198 - accuracy: 0.7965 - val_loss: 0.5767 - val_accuracy: 0.8342\n","Epoch 15/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5736 - accuracy: 0.8140\n","Epoch 15: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5773 - accuracy: 0.8145 - val_loss: 0.5101 - val_accuracy: 0.8469\n","Epoch 16/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.5614 - accuracy: 0.8122\n","Epoch 16: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5642 - accuracy: 0.8110 - val_loss: 0.5266 - val_accuracy: 0.8342\n","Epoch 17/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5941 - accuracy: 0.8058\n","Epoch 17: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5897 - accuracy: 0.8071 - val_loss: 0.5942 - val_accuracy: 0.7992\n","Epoch 18/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.5803 - accuracy: 0.8128\n","Epoch 18: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5718 - accuracy: 0.8148 - val_loss: 0.4924 - val_accuracy: 0.8640\n","Epoch 19/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.5527 - accuracy: 0.8286\n","Epoch 19: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5569 - accuracy: 0.8251 - val_loss: 0.5098 - val_accuracy: 0.8253\n","Epoch 20/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.5397 - accuracy: 0.8205\n","Epoch 20: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5469 - accuracy: 0.8197 - val_loss: 0.5894 - val_accuracy: 0.8158\n","Epoch 21/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.6189 - accuracy: 0.7966\n","Epoch 21: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6216 - accuracy: 0.7962 - val_loss: 0.6249 - val_accuracy: 0.7452\n","Epoch 22/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5498 - accuracy: 0.8233\n","Epoch 22: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5580 - accuracy: 0.8202 - val_loss: 0.6191 - val_accuracy: 0.7541\n","Epoch 23/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5866 - accuracy: 0.8085\n","Epoch 23: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.5866 - accuracy: 0.8085 - val_loss: 0.4675 - val_accuracy: 0.8145\n","Epoch 24/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5940 - accuracy: 0.8093\n","Epoch 24: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.5941 - accuracy: 0.8099 - val_loss: 0.5739 - val_accuracy: 0.8126\n","Epoch 25/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.6303 - accuracy: 0.7944\n","Epoch 25: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.6236 - accuracy: 0.7957 - val_loss: 0.4437 - val_accuracy: 0.8564\n","Epoch 26/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5635 - accuracy: 0.8197\n","Epoch 26: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5661 - accuracy: 0.8197 - val_loss: 0.6362 - val_accuracy: 0.8278\n","Epoch 27/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.5375 - accuracy: 0.8287\n","Epoch 27: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5496 - accuracy: 0.8227 - val_loss: 0.6720 - val_accuracy: 0.7814\n","Epoch 28/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5693 - accuracy: 0.8168\n","Epoch 28: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5730 - accuracy: 0.8164 - val_loss: 0.5540 - val_accuracy: 0.8405\n","Epoch 29/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.5727 - accuracy: 0.8225\n","Epoch 29: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5626 - accuracy: 0.8243 - val_loss: 0.5699 - val_accuracy: 0.8469\n","Epoch 30/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5992 - accuracy: 0.8257\n","Epoch 30: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5992 - accuracy: 0.8257 - val_loss: 0.5645 - val_accuracy: 0.8456\n","Epoch 31/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5617 - accuracy: 0.8229\n","Epoch 31: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5617 - accuracy: 0.8229 - val_loss: 0.5715 - val_accuracy: 0.7891\n","Epoch 32/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.5312 - accuracy: 0.8320\n","Epoch 32: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5353 - accuracy: 0.8306 - val_loss: 0.6459 - val_accuracy: 0.7554\n","Epoch 33/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.5365 - accuracy: 0.8273\n","Epoch 33: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5316 - accuracy: 0.8289 - val_loss: 0.5357 - val_accuracy: 0.8399\n","Epoch 34/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.5431 - accuracy: 0.8331\n","Epoch 34: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5429 - accuracy: 0.8330 - val_loss: 0.4418 - val_accuracy: 0.8621\n","Epoch 35/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.5314 - accuracy: 0.8330\n","Epoch 35: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5318 - accuracy: 0.8330 - val_loss: 0.4318 - val_accuracy: 0.8863\n","Epoch 36/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4906 - accuracy: 0.8496\n","Epoch 36: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4875 - accuracy: 0.8507 - val_loss: 0.5793 - val_accuracy: 0.8386\n","Epoch 37/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.5148 - accuracy: 0.8265\n","Epoch 37: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5121 - accuracy: 0.8278 - val_loss: 0.6634 - val_accuracy: 0.8100\n","Epoch 38/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6198 - accuracy: 0.8013\n","Epoch 38: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6125 - accuracy: 0.8011 - val_loss: 0.4885 - val_accuracy: 0.8520\n","Epoch 39/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5477 - accuracy: 0.8306\n","Epoch 39: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5527 - accuracy: 0.8297 - val_loss: 0.6672 - val_accuracy: 0.8189\n","Epoch 40/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.5284 - accuracy: 0.8219\n","Epoch 40: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5255 - accuracy: 0.8254 - val_loss: 0.5922 - val_accuracy: 0.8196\n","Epoch 41/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5348 - accuracy: 0.8192\n","Epoch 41: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.5399 - accuracy: 0.8172 - val_loss: 0.5495 - val_accuracy: 0.8323\n","Epoch 42/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.5380 - accuracy: 0.8283\n","Epoch 42: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 9ms/step - loss: 0.5376 - accuracy: 0.8287 - val_loss: 0.5012 - val_accuracy: 0.8424\n","Epoch 43/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5167 - accuracy: 0.8306\n","Epoch 43: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 9ms/step - loss: 0.5167 - accuracy: 0.8306 - val_loss: 0.6651 - val_accuracy: 0.7973\n","Epoch 44/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.5665 - accuracy: 0.8255\n","Epoch 44: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5682 - accuracy: 0.8246 - val_loss: 0.5533 - val_accuracy: 0.8424\n","Epoch 45/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.6069 - accuracy: 0.8131\n","Epoch 45: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6046 - accuracy: 0.8129 - val_loss: 0.4543 - val_accuracy: 0.8526\n","Epoch 46/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5356 - accuracy: 0.8291\n","Epoch 46: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5251 - accuracy: 0.8314 - val_loss: 0.5558 - val_accuracy: 0.8380\n","Epoch 47/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4963 - accuracy: 0.8445\n","Epoch 47: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4963 - accuracy: 0.8445 - val_loss: 0.5730 - val_accuracy: 0.8443\n","Epoch 48/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4887 - accuracy: 0.8414\n","Epoch 48: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4995 - accuracy: 0.8396 - val_loss: 0.5186 - val_accuracy: 0.8247\n","Epoch 49/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.5321 - accuracy: 0.8340\n","Epoch 49: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5398 - accuracy: 0.8308 - val_loss: 0.9902 - val_accuracy: 0.7281\n","Epoch 50/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.5524 - accuracy: 0.8136\n","Epoch 50: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5543 - accuracy: 0.8139 - val_loss: 0.4937 - val_accuracy: 0.8590\n","Epoch 51/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.8314\n","Epoch 51: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5396 - accuracy: 0.8314 - val_loss: 0.5527 - val_accuracy: 0.8558\n","Epoch 52/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.5647 - accuracy: 0.8298\n","Epoch 52: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5718 - accuracy: 0.8270 - val_loss: 0.6008 - val_accuracy: 0.8081\n","Epoch 53/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5547 - accuracy: 0.8270\n","Epoch 53: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5547 - accuracy: 0.8270 - val_loss: 0.5068 - val_accuracy: 0.8291\n","Epoch 54/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.5282 - accuracy: 0.8208\n","Epoch 54: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5321 - accuracy: 0.8205 - val_loss: 0.6578 - val_accuracy: 0.7776\n","Epoch 55/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.5593 - accuracy: 0.8130\n","Epoch 55: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5602 - accuracy: 0.8129 - val_loss: 0.7034 - val_accuracy: 0.7713\n","71/71 [==============================] - 0s 3ms/step\n","0.8781680746998666\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["109/115 [===========================>..] - ETA: 0s - loss: 2.7356 - accuracy: 0.3076\n","Epoch 1: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 3s 13ms/step - loss: 2.6812 - accuracy: 0.3201 - val_loss: 1.4948 - val_accuracy: 0.5845\n","Epoch 2/100\n","114/115 [============================>.] - ETA: 0s - loss: 1.3340 - accuracy: 0.6069\n","Epoch 2: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 1.3322 - accuracy: 0.6072 - val_loss: 1.1476 - val_accuracy: 0.6334\n","Epoch 3/100\n","105/115 [==========================>...] - ETA: 0s - loss: 1.0680 - accuracy: 0.6631\n","Epoch 3: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 1.0799 - accuracy: 0.6600 - val_loss: 1.0709 - val_accuracy: 0.6474\n","Epoch 4/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.9797 - accuracy: 0.6726\n","Epoch 4: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.9637 - accuracy: 0.6769 - val_loss: 0.7901 - val_accuracy: 0.7198\n","Epoch 5/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.9094 - accuracy: 0.6960\n","Epoch 5: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.9091 - accuracy: 0.6976 - val_loss: 0.6853 - val_accuracy: 0.7363\n","Epoch 6/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.7862 - accuracy: 0.7419\n","Epoch 6: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7801 - accuracy: 0.7418 - val_loss: 0.7237 - val_accuracy: 0.7903\n","Epoch 7/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.7436 - accuracy: 0.7505\n","Epoch 7: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7419 - accuracy: 0.7513 - val_loss: 0.6358 - val_accuracy: 0.7827\n","Epoch 8/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.7504 - accuracy: 0.7423\n","Epoch 8: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.7678 - accuracy: 0.7377 - val_loss: 0.8322 - val_accuracy: 0.7198\n","Epoch 9/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.6926 - accuracy: 0.7612\n","Epoch 9: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6982 - accuracy: 0.7600 - val_loss: 0.7212 - val_accuracy: 0.7757\n","Epoch 10/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.7130 - accuracy: 0.7722\n","Epoch 10: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7055 - accuracy: 0.7734 - val_loss: 0.6954 - val_accuracy: 0.8100\n","Epoch 11/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.6777 - accuracy: 0.7821\n","Epoch 11: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6762 - accuracy: 0.7807 - val_loss: 0.5409 - val_accuracy: 0.8266\n","Epoch 12/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.6944 - accuracy: 0.7763\n","Epoch 12: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7021 - accuracy: 0.7728 - val_loss: 0.6185 - val_accuracy: 0.8196\n","Epoch 13/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6873 - accuracy: 0.7863\n","Epoch 13: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6796 - accuracy: 0.7873 - val_loss: 0.9612 - val_accuracy: 0.6601\n","Epoch 14/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.7072 - accuracy: 0.7862\n","Epoch 14: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7019 - accuracy: 0.7862 - val_loss: 0.6369 - val_accuracy: 0.7770\n","Epoch 15/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6053 - accuracy: 0.8031\n","Epoch 15: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6105 - accuracy: 0.8022 - val_loss: 0.5687 - val_accuracy: 0.7967\n","Epoch 16/100\n","102/115 [=========================>....] - ETA: 0s - loss: 0.6379 - accuracy: 0.7904\n","Epoch 16: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6268 - accuracy: 0.7927 - val_loss: 0.4986 - val_accuracy: 0.8431\n","Epoch 17/100\n","115/115 [==============================] - ETA: 0s - loss: 0.6535 - accuracy: 0.7946\n","Epoch 17: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.6535 - accuracy: 0.7946 - val_loss: 0.6156 - val_accuracy: 0.7942\n","Epoch 18/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.6117 - accuracy: 0.8065\n","Epoch 18: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.6101 - accuracy: 0.8066 - val_loss: 0.5663 - val_accuracy: 0.8088\n","Epoch 19/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5942 - accuracy: 0.8082\n","Epoch 19: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 9ms/step - loss: 0.5942 - accuracy: 0.8082 - val_loss: 0.6618 - val_accuracy: 0.8177\n","Epoch 20/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5841 - accuracy: 0.8168\n","Epoch 20: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 9ms/step - loss: 0.5801 - accuracy: 0.8183 - val_loss: 0.4912 - val_accuracy: 0.8367\n","Epoch 21/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6384 - accuracy: 0.8096\n","Epoch 21: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6441 - accuracy: 0.8071 - val_loss: 0.6488 - val_accuracy: 0.8520\n","Epoch 22/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.6209 - accuracy: 0.8046\n","Epoch 22: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6118 - accuracy: 0.8071 - val_loss: 0.6235 - val_accuracy: 0.7656\n","Epoch 23/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.6446 - accuracy: 0.7967\n","Epoch 23: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.6402 - accuracy: 0.7987 - val_loss: 0.8248 - val_accuracy: 0.7884\n","Epoch 24/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.6959 - accuracy: 0.7870\n","Epoch 24: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6989 - accuracy: 0.7867 - val_loss: 0.5418 - val_accuracy: 0.8513\n","Epoch 25/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.5815 - accuracy: 0.8069\n","Epoch 25: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5742 - accuracy: 0.8090 - val_loss: 0.3784 - val_accuracy: 0.8526\n","Epoch 26/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5283 - accuracy: 0.8261\n","Epoch 26: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5308 - accuracy: 0.8254 - val_loss: 0.4618 - val_accuracy: 0.8583\n","Epoch 27/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.6853 - accuracy: 0.7897\n","Epoch 27: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.6821 - accuracy: 0.7905 - val_loss: 0.7153 - val_accuracy: 0.7637\n","Epoch 28/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6639 - accuracy: 0.7922\n","Epoch 28: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6540 - accuracy: 0.7943 - val_loss: 0.5408 - val_accuracy: 0.7980\n","Epoch 29/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.6277 - accuracy: 0.8035\n","Epoch 29: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.8063 - val_loss: 0.5809 - val_accuracy: 0.8113\n","Epoch 30/100\n","115/115 [==============================] - ETA: 0s - loss: 0.6397 - accuracy: 0.8009\n","Epoch 30: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6397 - accuracy: 0.8009 - val_loss: 0.5117 - val_accuracy: 0.8526\n","Epoch 31/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6223 - accuracy: 0.8010\n","Epoch 31: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6330 - accuracy: 0.7984 - val_loss: 0.5929 - val_accuracy: 0.7853\n","Epoch 32/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.6152 - accuracy: 0.7988\n","Epoch 32: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6031 - accuracy: 0.8031 - val_loss: 0.6136 - val_accuracy: 0.7980\n","Epoch 33/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.6217 - accuracy: 0.8019\n","Epoch 33: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6193 - accuracy: 0.8039 - val_loss: 0.7520 - val_accuracy: 0.7910\n","Epoch 34/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.6540 - accuracy: 0.7807\n","Epoch 34: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6513 - accuracy: 0.7821 - val_loss: 0.5466 - val_accuracy: 0.8386\n","Epoch 35/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.6847 - accuracy: 0.7922\n","Epoch 35: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.6862 - accuracy: 0.7922 - val_loss: 0.8843 - val_accuracy: 0.7440\n","Epoch 36/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.6369 - accuracy: 0.7977\n","Epoch 36: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.6346 - accuracy: 0.7976 - val_loss: 0.4828 - val_accuracy: 0.8431\n","Epoch 37/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.5577 - accuracy: 0.8226\n","Epoch 37: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5654 - accuracy: 0.8197 - val_loss: 0.7413 - val_accuracy: 0.6868\n","Epoch 38/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.6041 - accuracy: 0.8025\n","Epoch 38: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.6038 - accuracy: 0.8020 - val_loss: 0.5076 - val_accuracy: 0.8335\n","Epoch 39/100\n","115/115 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.7976\n","Epoch 39: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6249 - accuracy: 0.7976 - val_loss: 0.5943 - val_accuracy: 0.7967\n","Epoch 40/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.8159\n","Epoch 40: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5611 - accuracy: 0.8159 - val_loss: 0.6341 - val_accuracy: 0.7834\n","Epoch 41/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4748 - accuracy: 0.8450\n","Epoch 41: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4887 - accuracy: 0.8417 - val_loss: 0.6636 - val_accuracy: 0.7922\n","Epoch 42/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5196 - accuracy: 0.8309\n","Epoch 42: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5219 - accuracy: 0.8306 - val_loss: 0.4872 - val_accuracy: 0.8412\n","Epoch 43/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.5380 - accuracy: 0.8277\n","Epoch 43: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5322 - accuracy: 0.8308 - val_loss: 0.5475 - val_accuracy: 0.8139\n","Epoch 44/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5851 - accuracy: 0.8164\n","Epoch 44: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5851 - accuracy: 0.8164 - val_loss: 0.6004 - val_accuracy: 0.7618\n","Epoch 45/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.5183 - accuracy: 0.8335\n","Epoch 45: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5153 - accuracy: 0.8344 - val_loss: 0.6213 - val_accuracy: 0.8126\n","Epoch 46/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.5233 - accuracy: 0.8292\n","Epoch 46: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5258 - accuracy: 0.8276 - val_loss: 0.4413 - val_accuracy: 0.8100\n","71/71 [==============================] - 0s 3ms/step\n","0.855935971542908\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["103/115 [=========================>....] - ETA: 0s - loss: 2.9764 - accuracy: 0.2509\n","Epoch 1: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 2s 9ms/step - loss: 2.8591 - accuracy: 0.2640 - val_loss: 1.8954 - val_accuracy: 0.3513\n","Epoch 2/100\n","104/115 [==========================>...] - ETA: 0s - loss: 1.5101 - accuracy: 0.4949\n","Epoch 2: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 1.4911 - accuracy: 0.4958 - val_loss: 1.3651 - val_accuracy: 0.5133\n","Epoch 3/100\n","103/115 [=========================>....] - ETA: 0s - loss: 1.1925 - accuracy: 0.5992\n","Epoch 3: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 1.1832 - accuracy: 0.5982 - val_loss: 1.0138 - val_accuracy: 0.5705\n","Epoch 4/100\n","111/115 [===========================>..] - ETA: 0s - loss: 1.0738 - accuracy: 0.6475\n","Epoch 4: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 1.0678 - accuracy: 0.6481 - val_loss: 0.9002 - val_accuracy: 0.6557\n","Epoch 5/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.9497 - accuracy: 0.6777\n","Epoch 5: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.9437 - accuracy: 0.6791 - val_loss: 0.7333 - val_accuracy: 0.7446\n","Epoch 6/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.7714 - accuracy: 0.7372\n","Epoch 6: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 9ms/step - loss: 0.7706 - accuracy: 0.7377 - val_loss: 0.7282 - val_accuracy: 0.7694\n","Epoch 7/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.7433 - accuracy: 0.7335\n","Epoch 7: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.7458 - accuracy: 0.7330 - val_loss: 0.6620 - val_accuracy: 0.7973\n","Epoch 8/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.7204 - accuracy: 0.7524\n","Epoch 8: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7317 - accuracy: 0.7499 - val_loss: 0.6279 - val_accuracy: 0.7789\n","Epoch 9/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.6550 - accuracy: 0.7774\n","Epoch 9: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6551 - accuracy: 0.7774 - val_loss: 0.5448 - val_accuracy: 0.8132\n","Epoch 10/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6459 - accuracy: 0.7801\n","Epoch 10: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6515 - accuracy: 0.7774 - val_loss: 0.6669 - val_accuracy: 0.7884\n","Epoch 11/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.6947 - accuracy: 0.7804\n","Epoch 11: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6876 - accuracy: 0.7821 - val_loss: 0.6167 - val_accuracy: 0.7694\n","Epoch 12/100\n","115/115 [==============================] - ETA: 0s - loss: 0.6226 - accuracy: 0.7932\n","Epoch 12: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6226 - accuracy: 0.7932 - val_loss: 0.6456 - val_accuracy: 0.7789\n","Epoch 13/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.6704 - accuracy: 0.7749\n","Epoch 13: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6711 - accuracy: 0.7739 - val_loss: 0.8145 - val_accuracy: 0.7313\n","Epoch 14/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.6654 - accuracy: 0.7795\n","Epoch 14: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6770 - accuracy: 0.7785 - val_loss: 0.6702 - val_accuracy: 0.8183\n","Epoch 15/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.6486 - accuracy: 0.7940\n","Epoch 15: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6458 - accuracy: 0.7968 - val_loss: 0.5755 - val_accuracy: 0.8196\n","Epoch 16/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.6321 - accuracy: 0.7967\n","Epoch 16: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6261 - accuracy: 0.7979 - val_loss: 0.4806 - val_accuracy: 0.8463\n","Epoch 17/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5834 - accuracy: 0.8151\n","Epoch 17: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5813 - accuracy: 0.8148 - val_loss: 0.7085 - val_accuracy: 0.7789\n","Epoch 18/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.5623 - accuracy: 0.8218\n","Epoch 18: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5598 - accuracy: 0.8224 - val_loss: 0.4560 - val_accuracy: 0.8609\n","Epoch 19/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.6273 - accuracy: 0.8038\n","Epoch 19: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6273 - accuracy: 0.8044 - val_loss: 0.5590 - val_accuracy: 0.8139\n","Epoch 20/100\n","102/115 [=========================>....] - ETA: 0s - loss: 0.5304 - accuracy: 0.8330\n","Epoch 20: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5336 - accuracy: 0.8333 - val_loss: 0.5410 - val_accuracy: 0.8189\n","Epoch 21/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.5071 - accuracy: 0.8396\n","Epoch 21: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5051 - accuracy: 0.8425 - val_loss: 0.3983 - val_accuracy: 0.8723\n","Epoch 22/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.5450 - accuracy: 0.8275\n","Epoch 22: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5463 - accuracy: 0.8273 - val_loss: 0.4299 - val_accuracy: 0.8672\n","Epoch 23/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4861 - accuracy: 0.8451\n","Epoch 23: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4836 - accuracy: 0.8464 - val_loss: 0.5357 - val_accuracy: 0.8361\n","Epoch 24/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4912 - accuracy: 0.8479\n","Epoch 24: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4905 - accuracy: 0.8477 - val_loss: 0.4655 - val_accuracy: 0.8539\n","Epoch 25/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.5202 - accuracy: 0.8300\n","Epoch 25: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5089 - accuracy: 0.8327 - val_loss: 0.4341 - val_accuracy: 0.8844\n","Epoch 26/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.5453 - accuracy: 0.8322\n","Epoch 26: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5478 - accuracy: 0.8311 - val_loss: 0.5850 - val_accuracy: 0.8272\n","Epoch 27/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5043 - accuracy: 0.8445\n","Epoch 27: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5043 - accuracy: 0.8445 - val_loss: 0.3595 - val_accuracy: 0.8729\n","Epoch 28/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4895 - accuracy: 0.8474\n","Epoch 28: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4799 - accuracy: 0.8499 - val_loss: 0.4054 - val_accuracy: 0.8818\n","Epoch 29/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.5207 - accuracy: 0.8289\n","Epoch 29: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5287 - accuracy: 0.8273 - val_loss: 0.5113 - val_accuracy: 0.8609\n","Epoch 30/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5202 - accuracy: 0.8338\n","Epoch 30: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5146 - accuracy: 0.8366 - val_loss: 0.5228 - val_accuracy: 0.8005\n","Epoch 31/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4327 - accuracy: 0.8562\n","Epoch 31: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4327 - accuracy: 0.8562 - val_loss: 0.4545 - val_accuracy: 0.8628\n","Epoch 32/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4705 - accuracy: 0.8479\n","Epoch 32: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4704 - accuracy: 0.8477 - val_loss: 0.5597 - val_accuracy: 0.8558\n","Epoch 33/100\n","102/115 [=========================>....] - ETA: 0s - loss: 0.4917 - accuracy: 0.8456\n","Epoch 33: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4842 - accuracy: 0.8480 - val_loss: 0.3856 - val_accuracy: 0.8685\n","Epoch 34/100\n","102/115 [=========================>....] - ETA: 0s - loss: 0.4691 - accuracy: 0.8477\n","Epoch 34: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4689 - accuracy: 0.8445 - val_loss: 0.4616 - val_accuracy: 0.8806\n","Epoch 35/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.4538 - accuracy: 0.8527\n","Epoch 35: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4450 - accuracy: 0.8548 - val_loss: 0.4448 - val_accuracy: 0.8291\n","Epoch 36/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4091 - accuracy: 0.8729\n","Epoch 36: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4120 - accuracy: 0.8695 - val_loss: 0.6356 - val_accuracy: 0.8050\n","Epoch 37/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.5008 - accuracy: 0.8464\n","Epoch 37: val_accuracy did not improve from 0.89644\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4924 - accuracy: 0.8477 - val_loss: 0.4943 - val_accuracy: 0.8450\n","Epoch 38/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4475 - accuracy: 0.8521\n","Epoch 38: val_accuracy improved from 0.89644 to 0.91804, saving model to pendigits_tnn2.h5\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4475 - accuracy: 0.8521 - val_loss: 0.3326 - val_accuracy: 0.9180\n","Epoch 39/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4193 - accuracy: 0.8656\n","Epoch 39: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4140 - accuracy: 0.8643 - val_loss: 0.3971 - val_accuracy: 0.8793\n","Epoch 40/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.4465 - accuracy: 0.8606\n","Epoch 40: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4418 - accuracy: 0.8622 - val_loss: 0.5023 - val_accuracy: 0.8596\n","Epoch 41/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4987 - accuracy: 0.8330\n","Epoch 41: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4966 - accuracy: 0.8336 - val_loss: 0.4155 - val_accuracy: 0.8520\n","Epoch 42/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.4515 - accuracy: 0.8516\n","Epoch 42: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4528 - accuracy: 0.8532 - val_loss: 0.4734 - val_accuracy: 0.8310\n","Epoch 43/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.5061 - accuracy: 0.8373\n","Epoch 43: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.5114 - accuracy: 0.8366 - val_loss: 0.6670 - val_accuracy: 0.7814\n","Epoch 44/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.4606 - accuracy: 0.8584\n","Epoch 44: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4620 - accuracy: 0.8589 - val_loss: 0.3863 - val_accuracy: 0.8742\n","Epoch 45/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.3942 - accuracy: 0.8733\n","Epoch 45: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 9ms/step - loss: 0.3895 - accuracy: 0.8744 - val_loss: 0.3876 - val_accuracy: 0.8856\n","Epoch 46/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4358 - accuracy: 0.8658\n","Epoch 46: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4326 - accuracy: 0.8671 - val_loss: 0.4102 - val_accuracy: 0.8691\n","Epoch 47/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4172 - accuracy: 0.8741\n","Epoch 47: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4183 - accuracy: 0.8731 - val_loss: 0.5586 - val_accuracy: 0.8247\n","Epoch 48/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4746 - accuracy: 0.8480\n","Epoch 48: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4678 - accuracy: 0.8502 - val_loss: 0.4670 - val_accuracy: 0.8679\n","Epoch 49/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4344 - accuracy: 0.8586\n","Epoch 49: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4352 - accuracy: 0.8581 - val_loss: 0.4460 - val_accuracy: 0.8717\n","Epoch 50/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4778 - accuracy: 0.8513\n","Epoch 50: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4696 - accuracy: 0.8534 - val_loss: 0.4744 - val_accuracy: 0.8640\n","Epoch 51/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4413 - accuracy: 0.8560\n","Epoch 51: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4432 - accuracy: 0.8559 - val_loss: 0.4964 - val_accuracy: 0.8469\n","Epoch 52/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.4414 - accuracy: 0.8640\n","Epoch 52: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4432 - accuracy: 0.8630 - val_loss: 0.4203 - val_accuracy: 0.8907\n","Epoch 53/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4547 - accuracy: 0.8528\n","Epoch 53: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4584 - accuracy: 0.8521 - val_loss: 0.4896 - val_accuracy: 0.7916\n","Epoch 54/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.4171 - accuracy: 0.8680\n","Epoch 54: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4200 - accuracy: 0.8679 - val_loss: 0.3919 - val_accuracy: 0.8736\n","Epoch 55/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4501 - accuracy: 0.8589\n","Epoch 55: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4421 - accuracy: 0.8611 - val_loss: 0.3580 - val_accuracy: 0.8755\n","Epoch 56/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4869 - accuracy: 0.8365\n","Epoch 56: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4744 - accuracy: 0.8420 - val_loss: 0.3934 - val_accuracy: 0.8882\n","Epoch 57/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4506 - accuracy: 0.8544\n","Epoch 57: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4572 - accuracy: 0.8518 - val_loss: 0.5633 - val_accuracy: 0.8704\n","Epoch 58/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4559 - accuracy: 0.8579\n","Epoch 58: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4524 - accuracy: 0.8589 - val_loss: 0.4800 - val_accuracy: 0.8501\n","71/71 [==============================] - 0s 2ms/step\n","0.9106269453090262\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["108/115 [===========================>..] - ETA: 0s - loss: 3.1369 - accuracy: 0.2263\n","Epoch 1: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 3s 12ms/step - loss: 3.0620 - accuracy: 0.2340 - val_loss: 1.8335 - val_accuracy: 0.3939\n","Epoch 2/100\n","113/115 [============================>.] - ETA: 0s - loss: 1.6312 - accuracy: 0.4793\n","Epoch 2: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 1.6307 - accuracy: 0.4800 - val_loss: 1.4480 - val_accuracy: 0.5731\n","Epoch 3/100\n","105/115 [==========================>...] - ETA: 0s - loss: 1.2960 - accuracy: 0.5708\n","Epoch 3: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 1.2833 - accuracy: 0.5750 - val_loss: 1.0786 - val_accuracy: 0.6010\n","Epoch 4/100\n","111/115 [===========================>..] - ETA: 0s - loss: 1.1072 - accuracy: 0.6295\n","Epoch 4: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 1.1113 - accuracy: 0.6279 - val_loss: 1.0526 - val_accuracy: 0.6588\n","Epoch 5/100\n","111/115 [===========================>..] - ETA: 0s - loss: 1.0322 - accuracy: 0.6534\n","Epoch 5: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 1.0290 - accuracy: 0.6535 - val_loss: 0.9090 - val_accuracy: 0.6950\n","Epoch 6/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.9098 - accuracy: 0.6968\n","Epoch 6: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.9092 - accuracy: 0.6957 - val_loss: 0.6905 - val_accuracy: 0.7382\n","Epoch 7/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.7825 - accuracy: 0.7350\n","Epoch 7: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7835 - accuracy: 0.7349 - val_loss: 1.0013 - val_accuracy: 0.6290\n","Epoch 8/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.7953 - accuracy: 0.7379\n","Epoch 8: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7983 - accuracy: 0.7360 - val_loss: 0.7496 - val_accuracy: 0.7166\n","Epoch 9/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.7525 - accuracy: 0.7524\n","Epoch 9: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7558 - accuracy: 0.7518 - val_loss: 0.5788 - val_accuracy: 0.7713\n","Epoch 10/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6761 - accuracy: 0.7671\n","Epoch 10: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6699 - accuracy: 0.7695 - val_loss: 0.5849 - val_accuracy: 0.8208\n","Epoch 11/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.6497 - accuracy: 0.7803\n","Epoch 11: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6657 - accuracy: 0.7758 - val_loss: 0.8656 - val_accuracy: 0.6798\n","Epoch 12/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.7211 - accuracy: 0.7549\n","Epoch 12: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7224 - accuracy: 0.7537 - val_loss: 0.6024 - val_accuracy: 0.7630\n","Epoch 13/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.6943 - accuracy: 0.7634\n","Epoch 13: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6945 - accuracy: 0.7638 - val_loss: 0.5758 - val_accuracy: 0.8234\n","Epoch 14/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6472 - accuracy: 0.7927\n","Epoch 14: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6407 - accuracy: 0.7943 - val_loss: 0.6604 - val_accuracy: 0.7471\n","Epoch 15/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.7090 - accuracy: 0.7594\n","Epoch 15: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.7082 - accuracy: 0.7606 - val_loss: 0.7064 - val_accuracy: 0.7795\n","Epoch 16/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.6534 - accuracy: 0.7801\n","Epoch 16: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6425 - accuracy: 0.7813 - val_loss: 0.5181 - val_accuracy: 0.8285\n","Epoch 17/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.6301 - accuracy: 0.7888\n","Epoch 17: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6454 - accuracy: 0.7878 - val_loss: 0.7213 - val_accuracy: 0.7935\n","Epoch 18/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.6557 - accuracy: 0.7843\n","Epoch 18: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.6529 - accuracy: 0.7859 - val_loss: 0.7502 - val_accuracy: 0.7541\n","Epoch 19/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.6918 - accuracy: 0.7718\n","Epoch 19: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.6927 - accuracy: 0.7715 - val_loss: 0.5768 - val_accuracy: 0.8062\n","Epoch 20/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.6497 - accuracy: 0.7830\n","Epoch 20: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.6473 - accuracy: 0.7818 - val_loss: 0.5937 - val_accuracy: 0.8139\n","Epoch 21/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.6189 - accuracy: 0.7923\n","Epoch 21: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.6198 - accuracy: 0.7919 - val_loss: 0.6537 - val_accuracy: 0.8297\n","Epoch 22/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.6927 - accuracy: 0.7719\n","Epoch 22: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.7704 - val_loss: 0.5734 - val_accuracy: 0.8374\n","Epoch 23/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.7394 - accuracy: 0.7561\n","Epoch 23: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7290 - accuracy: 0.7592 - val_loss: 0.5856 - val_accuracy: 0.8291\n","Epoch 24/100\n","115/115 [==============================] - ETA: 0s - loss: 0.6595 - accuracy: 0.7804\n","Epoch 24: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6595 - accuracy: 0.7804 - val_loss: 0.6790 - val_accuracy: 0.8024\n","Epoch 25/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.6312 - accuracy: 0.7907\n","Epoch 25: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6310 - accuracy: 0.7905 - val_loss: 0.8604 - val_accuracy: 0.6976\n","Epoch 26/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.6898 - accuracy: 0.7748\n","Epoch 26: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6847 - accuracy: 0.7772 - val_loss: 0.5528 - val_accuracy: 0.7935\n","Epoch 27/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.6456 - accuracy: 0.7905\n","Epoch 27: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6405 - accuracy: 0.7919 - val_loss: 0.5266 - val_accuracy: 0.8139\n","Epoch 28/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.6627 - accuracy: 0.7846\n","Epoch 28: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6570 - accuracy: 0.7832 - val_loss: 0.7194 - val_accuracy: 0.7402\n","Epoch 29/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.6252 - accuracy: 0.7966\n","Epoch 29: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6214 - accuracy: 0.7971 - val_loss: 0.5595 - val_accuracy: 0.8062\n","Epoch 30/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.6110 - accuracy: 0.7927\n","Epoch 30: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6094 - accuracy: 0.7927 - val_loss: 0.5380 - val_accuracy: 0.8513\n","Epoch 31/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.6193 - accuracy: 0.7982\n","Epoch 31: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6188 - accuracy: 0.7984 - val_loss: 0.5973 - val_accuracy: 0.7268\n","Epoch 32/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.6036 - accuracy: 0.8070\n","Epoch 32: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6025 - accuracy: 0.8074 - val_loss: 0.7745 - val_accuracy: 0.7433\n","Epoch 33/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.6802 - accuracy: 0.7745\n","Epoch 33: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6693 - accuracy: 0.7785 - val_loss: 0.7990 - val_accuracy: 0.7738\n","Epoch 34/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.6322 - accuracy: 0.7878\n","Epoch 34: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6367 - accuracy: 0.7867 - val_loss: 0.8533 - val_accuracy: 0.7713\n","Epoch 35/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.6354 - accuracy: 0.7922\n","Epoch 35: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6362 - accuracy: 0.7924 - val_loss: 0.5417 - val_accuracy: 0.8247\n","Epoch 36/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.5457 - accuracy: 0.8122\n","Epoch 36: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5492 - accuracy: 0.8104 - val_loss: 0.5502 - val_accuracy: 0.8272\n","Epoch 37/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.5426 - accuracy: 0.8243\n","Epoch 37: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.5434 - accuracy: 0.8235 - val_loss: 0.5323 - val_accuracy: 0.8132\n","Epoch 38/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.5342 - accuracy: 0.8136\n","Epoch 38: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.5333 - accuracy: 0.8139 - val_loss: 0.4568 - val_accuracy: 0.8615\n","Epoch 39/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5777 - accuracy: 0.8061\n","Epoch 39: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.5783 - accuracy: 0.8074 - val_loss: 0.4910 - val_accuracy: 0.8393\n","Epoch 40/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.6060 - accuracy: 0.7986\n","Epoch 40: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.6033 - accuracy: 0.7992 - val_loss: 0.7935 - val_accuracy: 0.7490\n","Epoch 41/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.5809 - accuracy: 0.8090\n","Epoch 41: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5883 - accuracy: 0.8099 - val_loss: 0.6584 - val_accuracy: 0.7516\n","Epoch 42/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5936 - accuracy: 0.8056\n","Epoch 42: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5907 - accuracy: 0.8058 - val_loss: 0.5256 - val_accuracy: 0.8704\n","Epoch 43/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.5465 - accuracy: 0.8145\n","Epoch 43: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5476 - accuracy: 0.8137 - val_loss: 0.5265 - val_accuracy: 0.8056\n","Epoch 44/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.5622 - accuracy: 0.8166\n","Epoch 44: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5731 - accuracy: 0.8131 - val_loss: 0.6976 - val_accuracy: 0.7738\n","Epoch 45/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.6045 - accuracy: 0.7988\n","Epoch 45: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6039 - accuracy: 0.7992 - val_loss: 0.6450 - val_accuracy: 0.7961\n","Epoch 46/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.5289 - accuracy: 0.8278\n","Epoch 46: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5269 - accuracy: 0.8295 - val_loss: 0.4907 - val_accuracy: 0.8196\n","Epoch 47/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.5343 - accuracy: 0.8229\n","Epoch 47: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5510 - accuracy: 0.8208 - val_loss: 0.6467 - val_accuracy: 0.7973\n","Epoch 48/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.5930 - accuracy: 0.8095\n","Epoch 48: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5938 - accuracy: 0.8093 - val_loss: 0.5125 - val_accuracy: 0.8367\n","Epoch 49/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.6143 - accuracy: 0.7904\n","Epoch 49: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6217 - accuracy: 0.7905 - val_loss: 0.4485 - val_accuracy: 0.8412\n","Epoch 50/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.5741 - accuracy: 0.8114\n","Epoch 50: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5696 - accuracy: 0.8123 - val_loss: 0.5918 - val_accuracy: 0.8094\n","Epoch 51/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.5304 - accuracy: 0.8278\n","Epoch 51: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5278 - accuracy: 0.8289 - val_loss: 0.4834 - val_accuracy: 0.8380\n","Epoch 52/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.5008 - accuracy: 0.8346\n","Epoch 52: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5109 - accuracy: 0.8317 - val_loss: 0.5671 - val_accuracy: 0.7776\n","Epoch 53/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.5847 - accuracy: 0.8103\n","Epoch 53: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5828 - accuracy: 0.8107 - val_loss: 0.4575 - val_accuracy: 0.8355\n","Epoch 54/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.4852 - accuracy: 0.8454\n","Epoch 54: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4864 - accuracy: 0.8450 - val_loss: 0.4776 - val_accuracy: 0.8774\n","Epoch 55/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.5280 - accuracy: 0.8249\n","Epoch 55: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5278 - accuracy: 0.8259 - val_loss: 0.5161 - val_accuracy: 0.8437\n","Epoch 56/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4826 - accuracy: 0.8476\n","Epoch 56: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4796 - accuracy: 0.8488 - val_loss: 0.4022 - val_accuracy: 0.8710\n","Epoch 57/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4982 - accuracy: 0.8443\n","Epoch 57: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4970 - accuracy: 0.8447 - val_loss: 0.6343 - val_accuracy: 0.7795\n","Epoch 58/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.4886 - accuracy: 0.8401\n","Epoch 58: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 9ms/step - loss: 0.4856 - accuracy: 0.8404 - val_loss: 0.5840 - val_accuracy: 0.8005\n","Epoch 59/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.5106 - accuracy: 0.8292\n","Epoch 59: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5114 - accuracy: 0.8297 - val_loss: 0.5168 - val_accuracy: 0.8469\n","Epoch 60/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4860 - accuracy: 0.8353\n","Epoch 60: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4943 - accuracy: 0.8327 - val_loss: 0.6051 - val_accuracy: 0.7891\n","Epoch 61/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5737 - accuracy: 0.8128\n","Epoch 61: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5779 - accuracy: 0.8123 - val_loss: 0.5943 - val_accuracy: 0.8030\n","Epoch 62/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5164 - accuracy: 0.8308\n","Epoch 62: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5164 - accuracy: 0.8308 - val_loss: 0.4302 - val_accuracy: 0.8672\n","Epoch 63/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.5090 - accuracy: 0.8352\n","Epoch 63: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5080 - accuracy: 0.8366 - val_loss: 0.3997 - val_accuracy: 0.8806\n","Epoch 64/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.4166 - accuracy: 0.8522\n","Epoch 64: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4267 - accuracy: 0.8502 - val_loss: 0.3977 - val_accuracy: 0.8761\n","Epoch 65/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4980 - accuracy: 0.8331\n","Epoch 65: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5000 - accuracy: 0.8330 - val_loss: 0.4864 - val_accuracy: 0.8634\n","Epoch 66/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.5157 - accuracy: 0.8320\n","Epoch 66: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5138 - accuracy: 0.8330 - val_loss: 0.5492 - val_accuracy: 0.8075\n","Epoch 67/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.5122 - accuracy: 0.8322\n","Epoch 67: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5113 - accuracy: 0.8325 - val_loss: 0.5577 - val_accuracy: 0.8037\n","Epoch 68/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4981 - accuracy: 0.8325\n","Epoch 68: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5035 - accuracy: 0.8311 - val_loss: 0.4981 - val_accuracy: 0.8609\n","Epoch 69/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.4252 - accuracy: 0.8503\n","Epoch 69: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4248 - accuracy: 0.8526 - val_loss: 0.7656 - val_accuracy: 0.7954\n","Epoch 70/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.5321 - accuracy: 0.8302\n","Epoch 70: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5257 - accuracy: 0.8336 - val_loss: 0.5623 - val_accuracy: 0.8374\n","Epoch 71/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.5238 - accuracy: 0.8334\n","Epoch 71: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5209 - accuracy: 0.8349 - val_loss: 0.5578 - val_accuracy: 0.8355\n","Epoch 72/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4561 - accuracy: 0.8599\n","Epoch 72: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4543 - accuracy: 0.8603 - val_loss: 0.4433 - val_accuracy: 0.8634\n","Epoch 73/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4890 - accuracy: 0.8393\n","Epoch 73: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4909 - accuracy: 0.8398 - val_loss: 0.3798 - val_accuracy: 0.8621\n","Epoch 74/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5005 - accuracy: 0.8382\n","Epoch 74: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5039 - accuracy: 0.8360 - val_loss: 0.6518 - val_accuracy: 0.8081\n","Epoch 75/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.4905 - accuracy: 0.8499\n","Epoch 75: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4905 - accuracy: 0.8499 - val_loss: 0.5139 - val_accuracy: 0.8539\n","Epoch 76/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4552 - accuracy: 0.8465\n","Epoch 76: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4546 - accuracy: 0.8475 - val_loss: 0.4372 - val_accuracy: 0.8615\n","Epoch 77/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4978 - accuracy: 0.8379\n","Epoch 77: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4999 - accuracy: 0.8366 - val_loss: 0.5219 - val_accuracy: 0.8132\n","Epoch 78/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.4416 - accuracy: 0.8480\n","Epoch 78: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4525 - accuracy: 0.8455 - val_loss: 0.5448 - val_accuracy: 0.8227\n","Epoch 79/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4966 - accuracy: 0.8459\n","Epoch 79: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5260 - accuracy: 0.8382 - val_loss: 0.9368 - val_accuracy: 0.7643\n","Epoch 80/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.6030 - accuracy: 0.8111\n","Epoch 80: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5987 - accuracy: 0.8118 - val_loss: 0.6138 - val_accuracy: 0.7999\n","Epoch 81/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.5252 - accuracy: 0.8341\n","Epoch 81: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5231 - accuracy: 0.8349 - val_loss: 0.5286 - val_accuracy: 0.8342\n","Epoch 82/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4999 - accuracy: 0.8418\n","Epoch 82: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5047 - accuracy: 0.8396 - val_loss: 0.5408 - val_accuracy: 0.8609\n","Epoch 83/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4706 - accuracy: 0.8429\n","Epoch 83: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4703 - accuracy: 0.8436 - val_loss: 0.5690 - val_accuracy: 0.8100\n","71/71 [==============================] - 0s 3ms/step\n","0.868830591373944\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["104/115 [==========================>...] - ETA: 0s - loss: 2.9304 - accuracy: 0.2091\n","Epoch 1: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 2s 9ms/step - loss: 2.8222 - accuracy: 0.2253 - val_loss: 1.8710 - val_accuracy: 0.4161\n","Epoch 2/100\n","107/115 [==========================>...] - ETA: 0s - loss: 1.5562 - accuracy: 0.5053\n","Epoch 2: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 1.5373 - accuracy: 0.5132 - val_loss: 1.4147 - val_accuracy: 0.5476\n","Epoch 3/100\n","106/115 [==========================>...] - ETA: 0s - loss: 1.1491 - accuracy: 0.6359\n","Epoch 3: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 1.1524 - accuracy: 0.6314 - val_loss: 0.9696 - val_accuracy: 0.6626\n","Epoch 4/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.9588 - accuracy: 0.6713\n","Epoch 4: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.9566 - accuracy: 0.6731 - val_loss: 0.8849 - val_accuracy: 0.6588\n","Epoch 5/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.8542 - accuracy: 0.7190\n","Epoch 5: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.8521 - accuracy: 0.7200 - val_loss: 0.7800 - val_accuracy: 0.6976\n","Epoch 6/100\n","115/115 [==============================] - ETA: 0s - loss: 0.7556 - accuracy: 0.7551\n","Epoch 6: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7556 - accuracy: 0.7551 - val_loss: 0.6812 - val_accuracy: 0.7795\n","Epoch 7/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.7650 - accuracy: 0.7515\n","Epoch 7: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.7615 - accuracy: 0.7524 - val_loss: 0.7393 - val_accuracy: 0.7630\n","Epoch 8/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.7679 - accuracy: 0.7537\n","Epoch 8: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.7713 - accuracy: 0.7529 - val_loss: 0.7249 - val_accuracy: 0.7713\n","Epoch 9/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.7018 - accuracy: 0.7770\n","Epoch 9: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 9ms/step - loss: 0.7066 - accuracy: 0.7747 - val_loss: 0.6701 - val_accuracy: 0.7802\n","Epoch 10/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.7518 - accuracy: 0.7520\n","Epoch 10: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.7517 - accuracy: 0.7518 - val_loss: 0.6090 - val_accuracy: 0.8075\n","Epoch 11/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.7171 - accuracy: 0.7547\n","Epoch 11: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.7207 - accuracy: 0.7516 - val_loss: 0.6778 - val_accuracy: 0.7872\n","Epoch 12/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.6684 - accuracy: 0.7818\n","Epoch 12: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.6635 - accuracy: 0.7815 - val_loss: 0.6399 - val_accuracy: 0.7992\n","Epoch 13/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.6415 - accuracy: 0.7841\n","Epoch 13: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6358 - accuracy: 0.7864 - val_loss: 0.5955 - val_accuracy: 0.8316\n","Epoch 14/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.6090 - accuracy: 0.7979\n","Epoch 14: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6113 - accuracy: 0.7979 - val_loss: 0.5888 - val_accuracy: 0.8189\n","Epoch 15/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.5814 - accuracy: 0.8089\n","Epoch 15: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5851 - accuracy: 0.8080 - val_loss: 0.5723 - val_accuracy: 0.7929\n","Epoch 16/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.5968 - accuracy: 0.8089\n","Epoch 16: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5938 - accuracy: 0.8090 - val_loss: 0.7622 - val_accuracy: 0.7243\n","Epoch 17/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.5845 - accuracy: 0.8108\n","Epoch 17: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5842 - accuracy: 0.8110 - val_loss: 0.5236 - val_accuracy: 0.8418\n","Epoch 18/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.6284 - accuracy: 0.7949\n","Epoch 18: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6251 - accuracy: 0.7949 - val_loss: 0.6043 - val_accuracy: 0.8050\n","Epoch 19/100\n","102/115 [=========================>....] - ETA: 0s - loss: 0.6034 - accuracy: 0.8051\n","Epoch 19: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6113 - accuracy: 0.8020 - val_loss: 0.6368 - val_accuracy: 0.7961\n","Epoch 20/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.6120 - accuracy: 0.7969\n","Epoch 20: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6147 - accuracy: 0.7965 - val_loss: 0.6069 - val_accuracy: 0.8132\n","Epoch 21/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.5760 - accuracy: 0.8092\n","Epoch 21: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5656 - accuracy: 0.8120 - val_loss: 0.6123 - val_accuracy: 0.8285\n","Epoch 22/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.5869 - accuracy: 0.8031\n","Epoch 22: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5854 - accuracy: 0.8039 - val_loss: 0.5578 - val_accuracy: 0.8424\n","Epoch 23/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.5550 - accuracy: 0.8172\n","Epoch 23: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5546 - accuracy: 0.8180 - val_loss: 0.5744 - val_accuracy: 0.8437\n","Epoch 24/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.5332 - accuracy: 0.8326\n","Epoch 24: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5314 - accuracy: 0.8322 - val_loss: 0.4904 - val_accuracy: 0.8482\n","Epoch 25/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.5933 - accuracy: 0.8080\n","Epoch 25: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5896 - accuracy: 0.8090 - val_loss: 0.6659 - val_accuracy: 0.7846\n","Epoch 26/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.5499 - accuracy: 0.8153\n","Epoch 26: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5508 - accuracy: 0.8139 - val_loss: 0.8425 - val_accuracy: 0.7535\n","Epoch 27/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.5345 - accuracy: 0.8286\n","Epoch 27: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 9ms/step - loss: 0.5331 - accuracy: 0.8289 - val_loss: 0.6067 - val_accuracy: 0.8215\n","Epoch 28/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4891 - accuracy: 0.8376\n","Epoch 28: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4803 - accuracy: 0.8406 - val_loss: 0.5917 - val_accuracy: 0.8291\n","Epoch 29/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.5153 - accuracy: 0.8377\n","Epoch 29: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5177 - accuracy: 0.8368 - val_loss: 0.5269 - val_accuracy: 0.7967\n","Epoch 30/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.4974 - accuracy: 0.8336\n","Epoch 30: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4950 - accuracy: 0.8352 - val_loss: 0.5842 - val_accuracy: 0.8285\n","Epoch 31/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5432 - accuracy: 0.8322\n","Epoch 31: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5343 - accuracy: 0.8338 - val_loss: 0.4470 - val_accuracy: 0.8647\n","Epoch 32/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4875 - accuracy: 0.8431\n","Epoch 32: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4875 - accuracy: 0.8431 - val_loss: 0.6089 - val_accuracy: 0.7687\n","Epoch 33/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.4522 - accuracy: 0.8460\n","Epoch 33: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4529 - accuracy: 0.8461 - val_loss: 0.4894 - val_accuracy: 0.8183\n","Epoch 34/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4756 - accuracy: 0.8428\n","Epoch 34: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4631 - accuracy: 0.8469 - val_loss: 0.4411 - val_accuracy: 0.8761\n","Epoch 35/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.4695 - accuracy: 0.8475\n","Epoch 35: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4621 - accuracy: 0.8504 - val_loss: 0.5185 - val_accuracy: 0.8183\n","Epoch 36/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.4955 - accuracy: 0.8426\n","Epoch 36: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4945 - accuracy: 0.8415 - val_loss: 0.5712 - val_accuracy: 0.7834\n","Epoch 37/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.4683 - accuracy: 0.8429\n","Epoch 37: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4608 - accuracy: 0.8455 - val_loss: 0.4150 - val_accuracy: 0.8723\n","Epoch 38/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4582 - accuracy: 0.8514\n","Epoch 38: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4570 - accuracy: 0.8513 - val_loss: 0.5227 - val_accuracy: 0.8399\n","Epoch 39/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4810 - accuracy: 0.8454\n","Epoch 39: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4789 - accuracy: 0.8461 - val_loss: 0.4389 - val_accuracy: 0.8653\n","Epoch 40/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4351 - accuracy: 0.8556\n","Epoch 40: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4333 - accuracy: 0.8554 - val_loss: 0.4460 - val_accuracy: 0.8545\n","Epoch 41/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4748 - accuracy: 0.8414\n","Epoch 41: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4772 - accuracy: 0.8406 - val_loss: 0.4181 - val_accuracy: 0.8774\n","Epoch 42/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.8573\n","Epoch 42: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4324 - accuracy: 0.8573 - val_loss: 0.4359 - val_accuracy: 0.8640\n","Epoch 43/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4076 - accuracy: 0.8690\n","Epoch 43: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4168 - accuracy: 0.8690 - val_loss: 0.4890 - val_accuracy: 0.7942\n","Epoch 44/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4797 - accuracy: 0.8459\n","Epoch 44: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4873 - accuracy: 0.8442 - val_loss: 0.5470 - val_accuracy: 0.8139\n","Epoch 45/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4524 - accuracy: 0.8546\n","Epoch 45: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 9ms/step - loss: 0.4581 - accuracy: 0.8562 - val_loss: 0.4140 - val_accuracy: 0.8609\n","Epoch 46/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.4184 - accuracy: 0.8552\n","Epoch 46: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 9ms/step - loss: 0.4196 - accuracy: 0.8559 - val_loss: 0.4311 - val_accuracy: 0.8539\n","Epoch 47/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.4374 - accuracy: 0.8565\n","Epoch 47: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 9ms/step - loss: 0.4490 - accuracy: 0.8529 - val_loss: 0.4868 - val_accuracy: 0.8424\n","Epoch 48/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4271 - accuracy: 0.8624\n","Epoch 48: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4240 - accuracy: 0.8622 - val_loss: 0.4407 - val_accuracy: 0.8653\n","Epoch 49/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4435 - accuracy: 0.8582\n","Epoch 49: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4378 - accuracy: 0.8597 - val_loss: 0.4644 - val_accuracy: 0.8564\n","Epoch 50/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4121 - accuracy: 0.8603\n","Epoch 50: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4121 - accuracy: 0.8603 - val_loss: 0.5923 - val_accuracy: 0.8030\n","Epoch 51/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.4642 - accuracy: 0.8438\n","Epoch 51: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4615 - accuracy: 0.8453 - val_loss: 0.4071 - val_accuracy: 0.8075\n","Epoch 52/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.4339 - accuracy: 0.8592\n","Epoch 52: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4371 - accuracy: 0.8586 - val_loss: 0.4684 - val_accuracy: 0.8526\n","Epoch 53/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.3888 - accuracy: 0.8693\n","Epoch 53: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.3967 - accuracy: 0.8679 - val_loss: 0.4802 - val_accuracy: 0.8158\n","Epoch 54/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4979 - accuracy: 0.8387\n","Epoch 54: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4923 - accuracy: 0.8393 - val_loss: 0.4364 - val_accuracy: 0.8767\n","Epoch 55/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.4777 - accuracy: 0.8386\n","Epoch 55: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4754 - accuracy: 0.8409 - val_loss: 0.5372 - val_accuracy: 0.8291\n","Epoch 56/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4080 - accuracy: 0.8662\n","Epoch 56: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4080 - accuracy: 0.8662 - val_loss: 0.3050 - val_accuracy: 0.9053\n","Epoch 57/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.3759 - accuracy: 0.8794\n","Epoch 57: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.3742 - accuracy: 0.8780 - val_loss: 0.2774 - val_accuracy: 0.9034\n","Epoch 58/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4329 - accuracy: 0.8598\n","Epoch 58: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4153 - accuracy: 0.8654 - val_loss: 0.2886 - val_accuracy: 0.9085\n","Epoch 59/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4198 - accuracy: 0.8638\n","Epoch 59: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4216 - accuracy: 0.8641 - val_loss: 0.5007 - val_accuracy: 0.8482\n","Epoch 60/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4786 - accuracy: 0.8431\n","Epoch 60: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4710 - accuracy: 0.8458 - val_loss: 0.4508 - val_accuracy: 0.8856\n","Epoch 61/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4310 - accuracy: 0.8583\n","Epoch 61: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4310 - accuracy: 0.8583 - val_loss: 0.4140 - val_accuracy: 0.8787\n","Epoch 62/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.3878 - accuracy: 0.8773\n","Epoch 62: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.3908 - accuracy: 0.8763 - val_loss: 0.4397 - val_accuracy: 0.8596\n","Epoch 63/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4495 - accuracy: 0.8552\n","Epoch 63: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4486 - accuracy: 0.8556 - val_loss: 0.4792 - val_accuracy: 0.8450\n","Epoch 64/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4288 - accuracy: 0.8591\n","Epoch 64: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4324 - accuracy: 0.8600 - val_loss: 0.4373 - val_accuracy: 0.8691\n","Epoch 65/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4824 - accuracy: 0.8514\n","Epoch 65: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4809 - accuracy: 0.8518 - val_loss: 0.3947 - val_accuracy: 0.8596\n","Epoch 66/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4417 - accuracy: 0.8670\n","Epoch 66: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 9ms/step - loss: 0.4413 - accuracy: 0.8671 - val_loss: 0.4994 - val_accuracy: 0.8520\n","Epoch 67/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.4094 - accuracy: 0.8572\n","Epoch 67: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4180 - accuracy: 0.8570 - val_loss: 0.6147 - val_accuracy: 0.8139\n","Epoch 68/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4279 - accuracy: 0.8610\n","Epoch 68: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4252 - accuracy: 0.8608 - val_loss: 0.5092 - val_accuracy: 0.8475\n","Epoch 69/100\n","102/115 [=========================>....] - ETA: 0s - loss: 0.4262 - accuracy: 0.8600\n","Epoch 69: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4318 - accuracy: 0.8573 - val_loss: 0.3966 - val_accuracy: 0.8761\n","Epoch 70/100\n","115/115 [==============================] - ETA: 0s - loss: 0.3981 - accuracy: 0.8652\n","Epoch 70: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.3981 - accuracy: 0.8652 - val_loss: 0.5393 - val_accuracy: 0.8234\n","Epoch 71/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.3976 - accuracy: 0.8697\n","Epoch 71: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.3963 - accuracy: 0.8706 - val_loss: 0.3550 - val_accuracy: 0.8837\n","Epoch 72/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.3773 - accuracy: 0.8758\n","Epoch 72: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.3854 - accuracy: 0.8741 - val_loss: 0.4702 - val_accuracy: 0.8672\n","Epoch 73/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.3742 - accuracy: 0.8814\n","Epoch 73: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.3719 - accuracy: 0.8820 - val_loss: 0.3727 - val_accuracy: 0.8482\n","Epoch 74/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4497 - accuracy: 0.8554\n","Epoch 74: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4442 - accuracy: 0.8581 - val_loss: 0.4432 - val_accuracy: 0.8583\n","Epoch 75/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.3758 - accuracy: 0.8793\n","Epoch 75: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.3753 - accuracy: 0.8801 - val_loss: 0.4133 - val_accuracy: 0.8596\n","Epoch 76/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8695\n","Epoch 76: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.3857 - accuracy: 0.8687 - val_loss: 0.4040 - val_accuracy: 0.8831\n","Epoch 77/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4479 - accuracy: 0.8514\n","Epoch 77: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4520 - accuracy: 0.8507 - val_loss: 0.4244 - val_accuracy: 0.8323\n","Epoch 78/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4515 - accuracy: 0.8532\n","Epoch 78: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4549 - accuracy: 0.8524 - val_loss: 0.4746 - val_accuracy: 0.8450\n","71/71 [==============================] - 0s 2ms/step\n","0.9012894619831036\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["112/115 [============================>.] - ETA: 0s - loss: 3.8221 - accuracy: 0.2241\n","Epoch 1: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 2s 12ms/step - loss: 3.7828 - accuracy: 0.2266 - val_loss: 1.9561 - val_accuracy: 0.4263\n","Epoch 2/100\n","109/115 [===========================>..] - ETA: 0s - loss: 1.5894 - accuracy: 0.5152\n","Epoch 2: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 1.5639 - accuracy: 0.5247 - val_loss: 1.1463 - val_accuracy: 0.6201\n","Epoch 3/100\n","110/115 [===========================>..] - ETA: 0s - loss: 1.0121 - accuracy: 0.6693\n","Epoch 3: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 9ms/step - loss: 1.0070 - accuracy: 0.6709 - val_loss: 0.9974 - val_accuracy: 0.6499\n","Epoch 4/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.9004 - accuracy: 0.7031\n","Epoch 4: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.8947 - accuracy: 0.7047 - val_loss: 0.7481 - val_accuracy: 0.7408\n","Epoch 5/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.8294 - accuracy: 0.7400\n","Epoch 5: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.8248 - accuracy: 0.7418 - val_loss: 0.7495 - val_accuracy: 0.7834\n","Epoch 6/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.7304 - accuracy: 0.7740\n","Epoch 6: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7359 - accuracy: 0.7731 - val_loss: 0.7127 - val_accuracy: 0.7579\n","Epoch 7/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.7057 - accuracy: 0.7702\n","Epoch 7: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6961 - accuracy: 0.7712 - val_loss: 0.6139 - val_accuracy: 0.7872\n","Epoch 8/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.6828 - accuracy: 0.7812\n","Epoch 8: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6854 - accuracy: 0.7788 - val_loss: 0.5594 - val_accuracy: 0.7986\n","Epoch 9/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6279 - accuracy: 0.7857\n","Epoch 9: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6218 - accuracy: 0.7856 - val_loss: 0.6165 - val_accuracy: 0.7732\n","Epoch 10/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.6072 - accuracy: 0.7988\n","Epoch 10: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6078 - accuracy: 0.7990 - val_loss: 0.5709 - val_accuracy: 0.8329\n","Epoch 11/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5747 - accuracy: 0.8022\n","Epoch 11: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5747 - accuracy: 0.8022 - val_loss: 0.6368 - val_accuracy: 0.7961\n","Epoch 12/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5901 - accuracy: 0.8077\n","Epoch 12: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5901 - accuracy: 0.8077 - val_loss: 0.6873 - val_accuracy: 0.7808\n","Epoch 13/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.5669 - accuracy: 0.8134\n","Epoch 13: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5800 - accuracy: 0.8085 - val_loss: 0.5886 - val_accuracy: 0.8139\n","Epoch 14/100\n","102/115 [=========================>....] - ETA: 0s - loss: 0.5658 - accuracy: 0.8195\n","Epoch 14: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5501 - accuracy: 0.8238 - val_loss: 0.3619 - val_accuracy: 0.8717\n","Epoch 15/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.4872 - accuracy: 0.8403\n","Epoch 15: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4940 - accuracy: 0.8385 - val_loss: 0.4508 - val_accuracy: 0.8247\n","Epoch 16/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4572 - accuracy: 0.8519\n","Epoch 16: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4677 - accuracy: 0.8480 - val_loss: 0.4599 - val_accuracy: 0.8564\n","Epoch 17/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4819 - accuracy: 0.8357\n","Epoch 17: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4780 - accuracy: 0.8368 - val_loss: 0.4785 - val_accuracy: 0.8418\n","Epoch 18/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4966 - accuracy: 0.8334\n","Epoch 18: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4885 - accuracy: 0.8355 - val_loss: 0.4498 - val_accuracy: 0.8494\n","Epoch 19/100\n","102/115 [=========================>....] - ETA: 0s - loss: 0.4916 - accuracy: 0.8428\n","Epoch 19: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4782 - accuracy: 0.8485 - val_loss: 0.3788 - val_accuracy: 0.8806\n","Epoch 20/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4690 - accuracy: 0.8455\n","Epoch 20: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.8442 - val_loss: 0.4030 - val_accuracy: 0.8691\n","Epoch 21/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4823 - accuracy: 0.8421\n","Epoch 21: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4847 - accuracy: 0.8415 - val_loss: 0.4504 - val_accuracy: 0.8469\n","Epoch 22/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4881 - accuracy: 0.8449\n","Epoch 22: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4912 - accuracy: 0.8434 - val_loss: 0.5574 - val_accuracy: 0.8342\n","Epoch 23/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.5055 - accuracy: 0.8309\n","Epoch 23: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5061 - accuracy: 0.8306 - val_loss: 0.4065 - val_accuracy: 0.8596\n","Epoch 24/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4728 - accuracy: 0.8422\n","Epoch 24: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4739 - accuracy: 0.8415 - val_loss: 0.6095 - val_accuracy: 0.8374\n","Epoch 25/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.4910 - accuracy: 0.8390\n","Epoch 25: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4810 - accuracy: 0.8398 - val_loss: 0.4156 - val_accuracy: 0.8291\n","Epoch 26/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4931 - accuracy: 0.8371\n","Epoch 26: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4928 - accuracy: 0.8376 - val_loss: 0.5465 - val_accuracy: 0.8285\n","Epoch 27/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.5742 - accuracy: 0.8137\n","Epoch 27: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5782 - accuracy: 0.8120 - val_loss: 0.4635 - val_accuracy: 0.8532\n","Epoch 28/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4971 - accuracy: 0.8358\n","Epoch 28: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4975 - accuracy: 0.8357 - val_loss: 0.5195 - val_accuracy: 0.8291\n","Epoch 29/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4944 - accuracy: 0.8436\n","Epoch 29: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4944 - accuracy: 0.8436 - val_loss: 0.4519 - val_accuracy: 0.8475\n","Epoch 30/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4677 - accuracy: 0.8508\n","Epoch 30: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4589 - accuracy: 0.8534 - val_loss: 0.4622 - val_accuracy: 0.8640\n","Epoch 31/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4699 - accuracy: 0.8490\n","Epoch 31: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4685 - accuracy: 0.8491 - val_loss: 0.4583 - val_accuracy: 0.8571\n","Epoch 32/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.4869 - accuracy: 0.8426\n","Epoch 32: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4821 - accuracy: 0.8436 - val_loss: 0.4250 - val_accuracy: 0.8501\n","Epoch 33/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4183 - accuracy: 0.8591\n","Epoch 33: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4205 - accuracy: 0.8603 - val_loss: 0.5381 - val_accuracy: 0.8139\n","Epoch 34/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4979 - accuracy: 0.8399\n","Epoch 34: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5016 - accuracy: 0.8387 - val_loss: 0.4597 - val_accuracy: 0.8590\n","Epoch 35/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.5240 - accuracy: 0.8323\n","Epoch 35: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5262 - accuracy: 0.8317 - val_loss: 0.4992 - val_accuracy: 0.8119\n","Epoch 36/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4798 - accuracy: 0.8474\n","Epoch 36: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4755 - accuracy: 0.8477 - val_loss: 0.5941 - val_accuracy: 0.8278\n","Epoch 37/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4918 - accuracy: 0.8443\n","Epoch 37: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4947 - accuracy: 0.8445 - val_loss: 0.5657 - val_accuracy: 0.7922\n","Epoch 38/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4791 - accuracy: 0.8494\n","Epoch 38: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4791 - accuracy: 0.8494 - val_loss: 0.5367 - val_accuracy: 0.8018\n","Epoch 39/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4842 - accuracy: 0.8451\n","Epoch 39: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4831 - accuracy: 0.8442 - val_loss: 0.4460 - val_accuracy: 0.8399\n","71/71 [==============================] - 1s 3ms/step\n","0.8706091596265007\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["107/115 [==========================>...] - ETA: 0s - loss: 3.1353 - accuracy: 0.2631\n","Epoch 1: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 2s 8ms/step - loss: 3.0714 - accuracy: 0.2721 - val_loss: 1.7540 - val_accuracy: 0.4428\n","Epoch 2/100\n","115/115 [==============================] - ETA: 0s - loss: 1.4926 - accuracy: 0.5339\n","Epoch 2: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 1.4926 - accuracy: 0.5339 - val_loss: 1.1926 - val_accuracy: 0.5985\n","Epoch 3/100\n","105/115 [==========================>...] - ETA: 0s - loss: 1.1170 - accuracy: 0.6387\n","Epoch 3: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 1.1068 - accuracy: 0.6440 - val_loss: 0.8090 - val_accuracy: 0.7560\n","Epoch 4/100\n","115/115 [==============================] - ETA: 0s - loss: 0.9330 - accuracy: 0.6916\n","Epoch 4: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.9330 - accuracy: 0.6916 - val_loss: 0.9169 - val_accuracy: 0.7427\n","Epoch 5/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.8449 - accuracy: 0.7345\n","Epoch 5: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.8346 - accuracy: 0.7374 - val_loss: 0.6038 - val_accuracy: 0.8151\n","Epoch 6/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.7387 - accuracy: 0.7626\n","Epoch 6: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.7348 - accuracy: 0.7652 - val_loss: 0.6083 - val_accuracy: 0.7878\n","Epoch 7/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5985 - accuracy: 0.8056\n","Epoch 7: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5908 - accuracy: 0.8099 - val_loss: 0.4838 - val_accuracy: 0.8297\n","Epoch 8/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.5933 - accuracy: 0.8128\n","Epoch 8: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5780 - accuracy: 0.8183 - val_loss: 0.4350 - val_accuracy: 0.8736\n","Epoch 9/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.5549 - accuracy: 0.8168\n","Epoch 9: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5581 - accuracy: 0.8156 - val_loss: 0.5592 - val_accuracy: 0.7910\n","Epoch 10/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.5636 - accuracy: 0.8140\n","Epoch 10: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5739 - accuracy: 0.8120 - val_loss: 0.7145 - val_accuracy: 0.7243\n","Epoch 11/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5556 - accuracy: 0.8210\n","Epoch 11: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5556 - accuracy: 0.8210 - val_loss: 0.5057 - val_accuracy: 0.8240\n","Epoch 12/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5633 - accuracy: 0.8166\n","Epoch 12: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5607 - accuracy: 0.8156 - val_loss: 0.6734 - val_accuracy: 0.7427\n","Epoch 13/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.5943 - accuracy: 0.8103\n","Epoch 13: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5905 - accuracy: 0.8110 - val_loss: 0.5847 - val_accuracy: 0.8316\n","Epoch 14/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.5226 - accuracy: 0.8341\n","Epoch 14: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5216 - accuracy: 0.8344 - val_loss: 0.6762 - val_accuracy: 0.7961\n","Epoch 15/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.5306 - accuracy: 0.8331\n","Epoch 15: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.5286 - accuracy: 0.8336 - val_loss: 0.4924 - val_accuracy: 0.8266\n","Epoch 16/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.5444 - accuracy: 0.8210\n","Epoch 16: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.5467 - accuracy: 0.8213 - val_loss: 0.4625 - val_accuracy: 0.8615\n","Epoch 17/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4825 - accuracy: 0.8357\n","Epoch 17: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 9ms/step - loss: 0.4837 - accuracy: 0.8363 - val_loss: 0.5960 - val_accuracy: 0.8100\n","Epoch 18/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.5325 - accuracy: 0.8305\n","Epoch 18: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5348 - accuracy: 0.8300 - val_loss: 0.4482 - val_accuracy: 0.8659\n","Epoch 19/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.5019 - accuracy: 0.8432\n","Epoch 19: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5043 - accuracy: 0.8415 - val_loss: 0.5406 - val_accuracy: 0.7681\n","Epoch 20/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5304 - accuracy: 0.8294\n","Epoch 20: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5248 - accuracy: 0.8314 - val_loss: 0.6108 - val_accuracy: 0.7764\n","Epoch 21/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4989 - accuracy: 0.8393\n","Epoch 21: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4989 - accuracy: 0.8393 - val_loss: 0.5684 - val_accuracy: 0.8367\n","Epoch 22/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4964 - accuracy: 0.8432\n","Epoch 22: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4959 - accuracy: 0.8434 - val_loss: 0.3974 - val_accuracy: 0.8799\n","Epoch 23/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.5075 - accuracy: 0.8314\n","Epoch 23: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5073 - accuracy: 0.8333 - val_loss: 0.6218 - val_accuracy: 0.8062\n","Epoch 24/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.5142 - accuracy: 0.8413\n","Epoch 24: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5194 - accuracy: 0.8404 - val_loss: 0.5913 - val_accuracy: 0.7961\n","Epoch 25/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.5291 - accuracy: 0.8255\n","Epoch 25: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5247 - accuracy: 0.8268 - val_loss: 0.5635 - val_accuracy: 0.8145\n","Epoch 26/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.4619 - accuracy: 0.8466\n","Epoch 26: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4686 - accuracy: 0.8450 - val_loss: 0.4475 - val_accuracy: 0.8335\n","Epoch 27/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4942 - accuracy: 0.8394\n","Epoch 27: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4937 - accuracy: 0.8393 - val_loss: 0.4776 - val_accuracy: 0.8679\n","Epoch 28/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.8622\n","Epoch 28: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4267 - accuracy: 0.8622 - val_loss: 0.4792 - val_accuracy: 0.8615\n","Epoch 29/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4853 - accuracy: 0.8402\n","Epoch 29: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4796 - accuracy: 0.8412 - val_loss: 0.3910 - val_accuracy: 0.8742\n","Epoch 30/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.5095 - accuracy: 0.8300\n","Epoch 30: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5158 - accuracy: 0.8278 - val_loss: 0.6449 - val_accuracy: 0.7922\n","Epoch 31/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5298 - accuracy: 0.8297\n","Epoch 31: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5282 - accuracy: 0.8308 - val_loss: 0.5949 - val_accuracy: 0.7783\n","Epoch 32/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.4897 - accuracy: 0.8333\n","Epoch 32: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4894 - accuracy: 0.8338 - val_loss: 0.4184 - val_accuracy: 0.8564\n","Epoch 33/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.4887 - accuracy: 0.8471\n","Epoch 33: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4876 - accuracy: 0.8480 - val_loss: 0.4483 - val_accuracy: 0.8679\n","Epoch 34/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.4662 - accuracy: 0.8432\n","Epoch 34: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4728 - accuracy: 0.8423 - val_loss: 0.5595 - val_accuracy: 0.8355\n","Epoch 35/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4994 - accuracy: 0.8346\n","Epoch 35: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4994 - accuracy: 0.8346 - val_loss: 0.4655 - val_accuracy: 0.8272\n","Epoch 36/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5701 - accuracy: 0.8235\n","Epoch 36: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.5662 - accuracy: 0.8213 - val_loss: 0.5623 - val_accuracy: 0.7745\n","Epoch 37/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.5452 - accuracy: 0.8145\n","Epoch 37: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.5576 - accuracy: 0.8148 - val_loss: 0.5141 - val_accuracy: 0.8113\n","Epoch 38/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4752 - accuracy: 0.8503\n","Epoch 38: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4762 - accuracy: 0.8502 - val_loss: 0.4106 - val_accuracy: 0.8736\n","Epoch 39/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.5164 - accuracy: 0.8339\n","Epoch 39: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5152 - accuracy: 0.8341 - val_loss: 0.5482 - val_accuracy: 0.8310\n","Epoch 40/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4617 - accuracy: 0.8473\n","Epoch 40: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4620 - accuracy: 0.8477 - val_loss: 0.5614 - val_accuracy: 0.8005\n","Epoch 41/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4421 - accuracy: 0.8474\n","Epoch 41: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4581 - accuracy: 0.8453 - val_loss: 0.4428 - val_accuracy: 0.8583\n","Epoch 42/100\n","115/115 [==============================] - ETA: 0s - loss: 0.5069 - accuracy: 0.8401\n","Epoch 42: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5069 - accuracy: 0.8401 - val_loss: 0.4871 - val_accuracy: 0.8615\n","71/71 [==============================] - 0s 2ms/step\n","0.874166296131614\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["105/115 [==========================>...] - ETA: 0s - loss: 3.4322 - accuracy: 0.2190\n","Epoch 1: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 2s 8ms/step - loss: 3.2939 - accuracy: 0.2389 - val_loss: 1.6479 - val_accuracy: 0.5070\n","Epoch 2/100\n","115/115 [==============================] - ETA: 0s - loss: 1.4308 - accuracy: 0.5508\n","Epoch 2: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 1.4308 - accuracy: 0.5508 - val_loss: 1.2797 - val_accuracy: 0.5832\n","Epoch 3/100\n","106/115 [==========================>...] - ETA: 0s - loss: 1.0102 - accuracy: 0.6704\n","Epoch 3: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 1.0066 - accuracy: 0.6723 - val_loss: 0.8248 - val_accuracy: 0.7592\n","Epoch 4/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.9918 - accuracy: 0.6711\n","Epoch 4: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 1.0023 - accuracy: 0.6671 - val_loss: 0.7943 - val_accuracy: 0.7719\n","Epoch 5/100\n","115/115 [==============================] - ETA: 0s - loss: 0.8672 - accuracy: 0.7053\n","Epoch 5: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.8672 - accuracy: 0.7053 - val_loss: 0.7584 - val_accuracy: 0.7471\n","Epoch 6/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.8747 - accuracy: 0.7201\n","Epoch 6: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.8748 - accuracy: 0.7200 - val_loss: 0.7662 - val_accuracy: 0.7224\n","Epoch 7/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.8337 - accuracy: 0.7296\n","Epoch 7: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.8254 - accuracy: 0.7336 - val_loss: 0.7839 - val_accuracy: 0.7510\n","Epoch 8/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.7333 - accuracy: 0.7670\n","Epoch 8: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.7361 - accuracy: 0.7668 - val_loss: 0.7596 - val_accuracy: 0.7243\n","Epoch 9/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.7275 - accuracy: 0.7688\n","Epoch 9: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.7251 - accuracy: 0.7679 - val_loss: 0.8172 - val_accuracy: 0.7281\n","Epoch 10/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.6759 - accuracy: 0.7857\n","Epoch 10: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.6732 - accuracy: 0.7870 - val_loss: 0.5447 - val_accuracy: 0.7935\n","Epoch 11/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.6824 - accuracy: 0.7824\n","Epoch 11: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.6828 - accuracy: 0.7810 - val_loss: 0.6852 - val_accuracy: 0.7516\n","Epoch 12/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.6378 - accuracy: 0.7980\n","Epoch 12: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 9ms/step - loss: 0.6309 - accuracy: 0.7998 - val_loss: 0.5535 - val_accuracy: 0.8278\n","Epoch 13/100\n","115/115 [==============================] - ETA: 0s - loss: 0.6061 - accuracy: 0.8101\n","Epoch 13: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6061 - accuracy: 0.8101 - val_loss: 0.6808 - val_accuracy: 0.7878\n","Epoch 14/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.7113 - accuracy: 0.7726\n","Epoch 14: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.7098 - accuracy: 0.7720 - val_loss: 0.7337 - val_accuracy: 0.7668\n","Epoch 15/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.6095 - accuracy: 0.8133\n","Epoch 15: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.6088 - accuracy: 0.8131 - val_loss: 0.5749 - val_accuracy: 0.8151\n","Epoch 16/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.6196 - accuracy: 0.7980\n","Epoch 16: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.6201 - accuracy: 0.7979 - val_loss: 0.6037 - val_accuracy: 0.7859\n","Epoch 17/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.5337 - accuracy: 0.8247\n","Epoch 17: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.8246 - val_loss: 0.5105 - val_accuracy: 0.8380\n","Epoch 18/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.5408 - accuracy: 0.8125\n","Epoch 18: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5561 - accuracy: 0.8082 - val_loss: 0.5903 - val_accuracy: 0.7935\n","Epoch 19/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.5999 - accuracy: 0.8018\n","Epoch 19: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5959 - accuracy: 0.8031 - val_loss: 0.4841 - val_accuracy: 0.8221\n","Epoch 20/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.5632 - accuracy: 0.8239\n","Epoch 20: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5683 - accuracy: 0.8213 - val_loss: 0.5630 - val_accuracy: 0.8177\n","Epoch 21/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.5782 - accuracy: 0.8134\n","Epoch 21: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5775 - accuracy: 0.8137 - val_loss: 0.6246 - val_accuracy: 0.7897\n","Epoch 22/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.5167 - accuracy: 0.8256\n","Epoch 22: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5153 - accuracy: 0.8273 - val_loss: 0.5322 - val_accuracy: 0.8450\n","Epoch 23/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.5160 - accuracy: 0.8374\n","Epoch 23: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5084 - accuracy: 0.8409 - val_loss: 0.3946 - val_accuracy: 0.8590\n","Epoch 24/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.5248 - accuracy: 0.8371\n","Epoch 24: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5230 - accuracy: 0.8385 - val_loss: 0.4990 - val_accuracy: 0.8482\n","Epoch 25/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.5173 - accuracy: 0.8335\n","Epoch 25: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5235 - accuracy: 0.8308 - val_loss: 0.5192 - val_accuracy: 0.8310\n","Epoch 26/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.5081 - accuracy: 0.8240\n","Epoch 26: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5063 - accuracy: 0.8257 - val_loss: 0.4861 - val_accuracy: 0.8386\n","Epoch 27/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4765 - accuracy: 0.8398\n","Epoch 27: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4797 - accuracy: 0.8393 - val_loss: 0.4507 - val_accuracy: 0.8691\n","Epoch 28/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4734 - accuracy: 0.8417\n","Epoch 28: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4853 - accuracy: 0.8387 - val_loss: 0.4826 - val_accuracy: 0.8043\n","Epoch 29/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.4812 - accuracy: 0.8333\n","Epoch 29: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4727 - accuracy: 0.8360 - val_loss: 0.4176 - val_accuracy: 0.8812\n","Epoch 30/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.4709 - accuracy: 0.8409\n","Epoch 30: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4684 - accuracy: 0.8417 - val_loss: 0.4849 - val_accuracy: 0.8196\n","Epoch 31/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.4925 - accuracy: 0.8423\n","Epoch 31: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4861 - accuracy: 0.8442 - val_loss: 0.6112 - val_accuracy: 0.7637\n","Epoch 32/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.4753 - accuracy: 0.8455\n","Epoch 32: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4727 - accuracy: 0.8461 - val_loss: 0.4216 - val_accuracy: 0.8526\n","Epoch 33/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4267 - accuracy: 0.8544\n","Epoch 33: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4278 - accuracy: 0.8537 - val_loss: 0.5647 - val_accuracy: 0.8342\n","Epoch 34/100\n","102/115 [=========================>....] - ETA: 0s - loss: 0.4984 - accuracy: 0.8349\n","Epoch 34: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5087 - accuracy: 0.8314 - val_loss: 0.4553 - val_accuracy: 0.8526\n","Epoch 35/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4791 - accuracy: 0.8379\n","Epoch 35: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4837 - accuracy: 0.8376 - val_loss: 0.4852 - val_accuracy: 0.8456\n","Epoch 36/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4848 - accuracy: 0.8410\n","Epoch 36: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4840 - accuracy: 0.8398 - val_loss: 0.6196 - val_accuracy: 0.8189\n","Epoch 37/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4692 - accuracy: 0.8510\n","Epoch 37: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4674 - accuracy: 0.8504 - val_loss: 0.4537 - val_accuracy: 0.8564\n","Epoch 38/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.5032 - accuracy: 0.8479\n","Epoch 38: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.5068 - accuracy: 0.8466 - val_loss: 0.4172 - val_accuracy: 0.8590\n","Epoch 39/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4797 - accuracy: 0.8471\n","Epoch 39: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4782 - accuracy: 0.8469 - val_loss: 0.3848 - val_accuracy: 0.8774\n","Epoch 40/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4594 - accuracy: 0.8562\n","Epoch 40: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4635 - accuracy: 0.8556 - val_loss: 0.4192 - val_accuracy: 0.8526\n","Epoch 41/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.4358 - accuracy: 0.8574\n","Epoch 41: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4313 - accuracy: 0.8570 - val_loss: 0.5396 - val_accuracy: 0.8310\n","Epoch 42/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4186 - accuracy: 0.8584\n","Epoch 42: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4177 - accuracy: 0.8575 - val_loss: 0.5252 - val_accuracy: 0.8412\n","Epoch 43/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4609 - accuracy: 0.8614\n","Epoch 43: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4632 - accuracy: 0.8605 - val_loss: 0.4845 - val_accuracy: 0.8628\n","Epoch 44/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4673 - accuracy: 0.8530\n","Epoch 44: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4665 - accuracy: 0.8524 - val_loss: 0.4278 - val_accuracy: 0.8710\n","Epoch 45/100\n","111/115 [===========================>..] - ETA: 0s - loss: 0.4959 - accuracy: 0.8367\n","Epoch 45: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4944 - accuracy: 0.8363 - val_loss: 0.4483 - val_accuracy: 0.8463\n","Epoch 46/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.4572 - accuracy: 0.8518\n","Epoch 46: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4558 - accuracy: 0.8513 - val_loss: 0.5861 - val_accuracy: 0.8253\n","Epoch 47/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4575 - accuracy: 0.8516\n","Epoch 47: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4679 - accuracy: 0.8477 - val_loss: 0.4784 - val_accuracy: 0.8405\n","Epoch 48/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.4569 - accuracy: 0.8627\n","Epoch 48: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4533 - accuracy: 0.8624 - val_loss: 0.3793 - val_accuracy: 0.8914\n","Epoch 49/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.4407 - accuracy: 0.8608\n","Epoch 49: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4456 - accuracy: 0.8594 - val_loss: 0.5016 - val_accuracy: 0.8520\n","Epoch 50/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4509 - accuracy: 0.8510\n","Epoch 50: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 9ms/step - loss: 0.4475 - accuracy: 0.8532 - val_loss: 0.4270 - val_accuracy: 0.8958\n","Epoch 51/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.5329 - accuracy: 0.8435\n","Epoch 51: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.5304 - accuracy: 0.8431 - val_loss: 0.3507 - val_accuracy: 0.8952\n","Epoch 52/100\n","102/115 [=========================>....] - ETA: 0s - loss: 0.4154 - accuracy: 0.8661\n","Epoch 52: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4182 - accuracy: 0.8671 - val_loss: 0.5146 - val_accuracy: 0.8456\n","Epoch 53/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4532 - accuracy: 0.8582\n","Epoch 53: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4400 - accuracy: 0.8613 - val_loss: 0.3932 - val_accuracy: 0.8590\n","Epoch 54/100\n","102/115 [=========================>....] - ETA: 0s - loss: 0.4290 - accuracy: 0.8621\n","Epoch 54: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4149 - accuracy: 0.8673 - val_loss: 0.3624 - val_accuracy: 0.8863\n","Epoch 55/100\n","103/115 [=========================>....] - ETA: 0s - loss: 0.3916 - accuracy: 0.8723\n","Epoch 55: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.3920 - accuracy: 0.8731 - val_loss: 0.3732 - val_accuracy: 0.8787\n","Epoch 56/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4202 - accuracy: 0.8654\n","Epoch 56: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4197 - accuracy: 0.8660 - val_loss: 0.3132 - val_accuracy: 0.9123\n","Epoch 57/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4582 - accuracy: 0.8523\n","Epoch 57: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4574 - accuracy: 0.8537 - val_loss: 0.4817 - val_accuracy: 0.8628\n","Epoch 58/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4421 - accuracy: 0.8557\n","Epoch 58: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4354 - accuracy: 0.8575 - val_loss: 0.3859 - val_accuracy: 0.8983\n","Epoch 59/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4284 - accuracy: 0.8592\n","Epoch 59: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4418 - accuracy: 0.8581 - val_loss: 0.6061 - val_accuracy: 0.8469\n","Epoch 60/100\n","104/115 [==========================>...] - ETA: 0s - loss: 0.4761 - accuracy: 0.8570\n","Epoch 60: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4687 - accuracy: 0.8581 - val_loss: 0.4916 - val_accuracy: 0.8393\n","Epoch 61/100\n","113/115 [============================>.] - ETA: 0s - loss: 0.4264 - accuracy: 0.8609\n","Epoch 61: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4249 - accuracy: 0.8613 - val_loss: 0.5703 - val_accuracy: 0.7999\n","Epoch 62/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4621 - accuracy: 0.8566\n","Epoch 62: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4610 - accuracy: 0.8567 - val_loss: 0.4996 - val_accuracy: 0.8469\n","Epoch 63/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4066 - accuracy: 0.8585\n","Epoch 63: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4075 - accuracy: 0.8578 - val_loss: 0.4034 - val_accuracy: 0.8825\n","Epoch 64/100\n","105/115 [==========================>...] - ETA: 0s - loss: 0.4077 - accuracy: 0.8738\n","Epoch 64: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4089 - accuracy: 0.8712 - val_loss: 0.4310 - val_accuracy: 0.8640\n","Epoch 65/100\n","107/115 [==========================>...] - ETA: 0s - loss: 0.4082 - accuracy: 0.8700\n","Epoch 65: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4074 - accuracy: 0.8703 - val_loss: 0.6146 - val_accuracy: 0.8380\n","Epoch 66/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4402 - accuracy: 0.8607\n","Epoch 66: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 9ms/step - loss: 0.4402 - accuracy: 0.8605 - val_loss: 0.3867 - val_accuracy: 0.8793\n","Epoch 67/100\n","109/115 [===========================>..] - ETA: 0s - loss: 0.4642 - accuracy: 0.8518\n","Epoch 67: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4620 - accuracy: 0.8518 - val_loss: 0.4574 - val_accuracy: 0.8418\n","Epoch 68/100\n","110/115 [===========================>..] - ETA: 0s - loss: 0.4383 - accuracy: 0.8517\n","Epoch 68: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 8ms/step - loss: 0.4318 - accuracy: 0.8534 - val_loss: 0.4220 - val_accuracy: 0.8659\n","Epoch 69/100\n","106/115 [==========================>...] - ETA: 0s - loss: 0.4089 - accuracy: 0.8644\n","Epoch 69: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.8619 - val_loss: 0.5197 - val_accuracy: 0.8304\n","Epoch 70/100\n","114/115 [============================>.] - ETA: 0s - loss: 0.4764 - accuracy: 0.8363\n","Epoch 70: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4768 - accuracy: 0.8366 - val_loss: 0.7997 - val_accuracy: 0.7891\n","Epoch 71/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4197 - accuracy: 0.8586\n","Epoch 71: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4197 - accuracy: 0.8586 - val_loss: 0.5707 - val_accuracy: 0.8221\n","Epoch 72/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.4424 - accuracy: 0.8550\n","Epoch 72: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4484 - accuracy: 0.8537 - val_loss: 0.4457 - val_accuracy: 0.8685\n","Epoch 73/100\n","115/115 [==============================] - ETA: 0s - loss: 0.4545 - accuracy: 0.8594\n","Epoch 73: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 5ms/step - loss: 0.4545 - accuracy: 0.8594 - val_loss: 0.4276 - val_accuracy: 0.8596\n","Epoch 74/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4586 - accuracy: 0.8524\n","Epoch 74: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4651 - accuracy: 0.8515 - val_loss: 0.5953 - val_accuracy: 0.8310\n","Epoch 75/100\n","112/115 [============================>.] - ETA: 0s - loss: 0.4092 - accuracy: 0.8697\n","Epoch 75: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4120 - accuracy: 0.8695 - val_loss: 0.4895 - val_accuracy: 0.8355\n","Epoch 76/100\n","108/115 [===========================>..] - ETA: 0s - loss: 0.4506 - accuracy: 0.8521\n","Epoch 76: val_accuracy did not improve from 0.91804\n","115/115 [==============================] - 1s 6ms/step - loss: 0.4396 - accuracy: 0.8562 - val_loss: 0.3706 - val_accuracy: 0.8825\n","71/71 [==============================] - 0s 3ms/step\n","0.9235215651400622\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["71/71 [==============================] - 1s 4ms/step - loss: 0.3370 - accuracy: 0.9106\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["67/75 [=========================>....] - ETA: 0s - loss: 2.1707 - accuracy: 0.3475\n","Epoch 1: val_accuracy improved from -inf to 0.32750, saving model to winewhite_tnn2.h5\n","75/75 [==============================] - 2s 11ms/step - loss: 2.1249 - accuracy: 0.3485 - val_loss: 1.8145 - val_accuracy: 0.3275\n","Epoch 2/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.5888 - accuracy: 0.4108\n","Epoch 2: val_accuracy improved from 0.32750 to 0.35277, saving model to winewhite_tnn2.h5\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5928 - accuracy: 0.4118 - val_loss: 1.5539 - val_accuracy: 0.3528\n","Epoch 3/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5392 - accuracy: 0.4111\n","Epoch 3: val_accuracy improved from 0.35277 to 0.44023, saving model to winewhite_tnn2.h5\n","75/75 [==============================] - 0s 7ms/step - loss: 1.5435 - accuracy: 0.4168 - val_loss: 1.6294 - val_accuracy: 0.4402\n","Epoch 4/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.5141 - accuracy: 0.4497\n","Epoch 4: val_accuracy did not improve from 0.44023\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5032 - accuracy: 0.4510 - val_loss: 1.4865 - val_accuracy: 0.4091\n","Epoch 5/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4830 - accuracy: 0.4569\n","Epoch 5: val_accuracy improved from 0.44023 to 0.45578, saving model to winewhite_tnn2.h5\n","75/75 [==============================] - 1s 7ms/step - loss: 1.4830 - accuracy: 0.4569 - val_loss: 1.4948 - val_accuracy: 0.4558\n","Epoch 6/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.4687 - accuracy: 0.4321\n","Epoch 6: val_accuracy did not improve from 0.45578\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4687 - accuracy: 0.4327 - val_loss: 1.3683 - val_accuracy: 0.4276\n","Epoch 7/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.4819 - accuracy: 0.4036\n","Epoch 7: val_accuracy did not improve from 0.45578\n","75/75 [==============================] - 1s 9ms/step - loss: 1.4954 - accuracy: 0.4052 - val_loss: 1.5110 - val_accuracy: 0.4441\n","Epoch 8/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.5615 - accuracy: 0.4054\n","Epoch 8: val_accuracy did not improve from 0.45578\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5687 - accuracy: 0.4039 - val_loss: 1.6124 - val_accuracy: 0.4461\n","Epoch 9/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.4003 - accuracy: 0.4415\n","Epoch 9: val_accuracy did not improve from 0.45578\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4098 - accuracy: 0.4352 - val_loss: 1.4861 - val_accuracy: 0.4344\n","Epoch 10/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.4879 - accuracy: 0.4219\n","Epoch 10: val_accuracy did not improve from 0.45578\n","75/75 [==============================] - 1s 9ms/step - loss: 1.4897 - accuracy: 0.4231 - val_loss: 1.4638 - val_accuracy: 0.3489\n","Epoch 11/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.4867 - accuracy: 0.4353\n","Epoch 11: val_accuracy improved from 0.45578 to 0.46939, saving model to winewhite_tnn2.h5\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4909 - accuracy: 0.4348 - val_loss: 1.4411 - val_accuracy: 0.4694\n","Epoch 12/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5074 - accuracy: 0.4274\n","Epoch 12: val_accuracy did not improve from 0.46939\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4925 - accuracy: 0.4314 - val_loss: 1.6488 - val_accuracy: 0.4014\n","Epoch 13/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.4699 - accuracy: 0.4347\n","Epoch 13: val_accuracy did not improve from 0.46939\n","75/75 [==============================] - 0s 5ms/step - loss: 1.4646 - accuracy: 0.4368 - val_loss: 1.3711 - val_accuracy: 0.4286\n","Epoch 14/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.4299 - accuracy: 0.4425\n","Epoch 14: val_accuracy did not improve from 0.46939\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4437 - accuracy: 0.4406 - val_loss: 1.5524 - val_accuracy: 0.4121\n","Epoch 15/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.5395 - accuracy: 0.4268\n","Epoch 15: val_accuracy did not improve from 0.46939\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5345 - accuracy: 0.4281 - val_loss: 1.6204 - val_accuracy: 0.4140\n","Epoch 16/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.4413 - accuracy: 0.4370\n","Epoch 16: val_accuracy did not improve from 0.46939\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4500 - accuracy: 0.4389 - val_loss: 1.5995 - val_accuracy: 0.4334\n","Epoch 17/100\n","62/75 [=======================>......] - ETA: 0s - loss: 1.5034 - accuracy: 0.4244\n","Epoch 17: val_accuracy improved from 0.46939 to 0.49660, saving model to winewhite_tnn2.h5\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5089 - accuracy: 0.4356 - val_loss: 1.8697 - val_accuracy: 0.4966\n","Epoch 18/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.5779 - accuracy: 0.4385\n","Epoch 18: val_accuracy did not improve from 0.49660\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5695 - accuracy: 0.4406 - val_loss: 1.5827 - val_accuracy: 0.3984\n","Epoch 19/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5240 - accuracy: 0.4489\n","Epoch 19: val_accuracy did not improve from 0.49660\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5036 - accuracy: 0.4477 - val_loss: 1.4083 - val_accuracy: 0.3557\n","Epoch 20/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5228 - accuracy: 0.4231\n","Epoch 20: val_accuracy did not improve from 0.49660\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5034 - accuracy: 0.4314 - val_loss: 1.5522 - val_accuracy: 0.4645\n","Epoch 21/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5648 - accuracy: 0.4401\n","Epoch 21: val_accuracy did not improve from 0.49660\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5521 - accuracy: 0.4423 - val_loss: 1.5760 - val_accuracy: 0.3547\n","Epoch 22/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5215 - accuracy: 0.4380\n","Epoch 22: val_accuracy did not improve from 0.49660\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5035 - accuracy: 0.4389 - val_loss: 1.3834 - val_accuracy: 0.4655\n","Epoch 23/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.5075 - accuracy: 0.4351\n","Epoch 23: val_accuracy did not improve from 0.49660\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5210 - accuracy: 0.4327 - val_loss: 1.4857 - val_accuracy: 0.4373\n","Epoch 24/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5417 - accuracy: 0.4370\n","Epoch 24: val_accuracy did not improve from 0.49660\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5275 - accuracy: 0.4419 - val_loss: 1.4635 - val_accuracy: 0.4500\n","Epoch 25/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5074 - accuracy: 0.4449\n","Epoch 25: val_accuracy did not improve from 0.49660\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4937 - accuracy: 0.4460 - val_loss: 1.5649 - val_accuracy: 0.4529\n","Epoch 26/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5787 - accuracy: 0.4297\n","Epoch 26: val_accuracy improved from 0.49660 to 0.49854, saving model to winewhite_tnn2.h5\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5686 - accuracy: 0.4339 - val_loss: 1.6389 - val_accuracy: 0.4985\n","Epoch 27/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5504 - accuracy: 0.4452\n","Epoch 27: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5504 - accuracy: 0.4452 - val_loss: 1.3496 - val_accuracy: 0.4538\n","Epoch 28/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4946 - accuracy: 0.4380\n","Epoch 28: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4827 - accuracy: 0.4427 - val_loss: 1.4411 - val_accuracy: 0.4616\n","Epoch 29/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5591 - accuracy: 0.4289\n","Epoch 29: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5591 - accuracy: 0.4289 - val_loss: 1.6486 - val_accuracy: 0.3868\n","Epoch 30/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5053 - accuracy: 0.4302\n","Epoch 30: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5053 - accuracy: 0.4302 - val_loss: 1.7202 - val_accuracy: 0.4519\n","Epoch 31/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5805 - accuracy: 0.4191\n","Epoch 31: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5803 - accuracy: 0.4227 - val_loss: 1.6693 - val_accuracy: 0.4189\n","Epoch 32/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4701 - accuracy: 0.4277\n","Epoch 32: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4473 - accuracy: 0.4293 - val_loss: 1.4929 - val_accuracy: 0.3975\n","Epoch 33/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.4900 - accuracy: 0.4370\n","Epoch 33: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4911 - accuracy: 0.4314 - val_loss: 1.5347 - val_accuracy: 0.3887\n","Epoch 34/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.5565 - accuracy: 0.4401\n","Epoch 34: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5593 - accuracy: 0.4398 - val_loss: 1.7948 - val_accuracy: 0.3635\n","Epoch 35/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.5334 - accuracy: 0.4228\n","Epoch 35: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5237 - accuracy: 0.4227 - val_loss: 1.4354 - val_accuracy: 0.3897\n","Epoch 36/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.5114 - accuracy: 0.4510\n","Epoch 36: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5099 - accuracy: 0.4423 - val_loss: 1.3203 - val_accuracy: 0.4179\n","Epoch 37/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.4496 - accuracy: 0.4389\n","Epoch 37: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4393 - accuracy: 0.4444 - val_loss: 1.6906 - val_accuracy: 0.4636\n","Epoch 38/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5786 - accuracy: 0.4206\n","Epoch 38: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5786 - accuracy: 0.4206 - val_loss: 1.6259 - val_accuracy: 0.4694\n","Epoch 39/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.5438 - accuracy: 0.4324\n","Epoch 39: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5343 - accuracy: 0.4360 - val_loss: 1.3659 - val_accuracy: 0.4169\n","Epoch 40/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4981 - accuracy: 0.4127\n","Epoch 40: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4981 - accuracy: 0.4127 - val_loss: 1.5747 - val_accuracy: 0.4169\n","Epoch 41/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5504 - accuracy: 0.4257\n","Epoch 41: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 5ms/step - loss: 1.5291 - accuracy: 0.4277 - val_loss: 1.4913 - val_accuracy: 0.4606\n","Epoch 42/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.5222 - accuracy: 0.4093\n","Epoch 42: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5256 - accuracy: 0.4093 - val_loss: 1.4021 - val_accuracy: 0.4461\n","Epoch 43/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.4857 - accuracy: 0.4246\n","Epoch 43: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4699 - accuracy: 0.4223 - val_loss: 1.3542 - val_accuracy: 0.4111\n","Epoch 44/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5852 - accuracy: 0.4236\n","Epoch 44: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5831 - accuracy: 0.4214 - val_loss: 1.3984 - val_accuracy: 0.3469\n","Epoch 45/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5008 - accuracy: 0.4156\n","Epoch 45: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 7ms/step - loss: 1.5008 - accuracy: 0.4156 - val_loss: 1.7466 - val_accuracy: 0.4665\n","Epoch 46/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.5634 - accuracy: 0.4136\n","Epoch 46: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5489 - accuracy: 0.4177 - val_loss: 1.5423 - val_accuracy: 0.3644\n","46/46 [==============================] - 0s 3ms/step\n","0.5034013605442177\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["68/75 [==========================>...] - ETA: 0s - loss: 2.8979 - accuracy: 0.2587\n","Epoch 1: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 3s 23ms/step - loss: 2.7805 - accuracy: 0.2730 - val_loss: 1.7728 - val_accuracy: 0.4509\n","Epoch 2/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.7707 - accuracy: 0.3952\n","Epoch 2: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 5ms/step - loss: 1.7653 - accuracy: 0.3856 - val_loss: 1.6249 - val_accuracy: 0.3926\n","Epoch 3/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5481 - accuracy: 0.4173\n","Epoch 3: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5611 - accuracy: 0.4060 - val_loss: 1.8052 - val_accuracy: 0.3178\n","Epoch 4/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4678 - accuracy: 0.4139\n","Epoch 4: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4642 - accuracy: 0.4156 - val_loss: 1.5084 - val_accuracy: 0.4597\n","Epoch 5/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.4849 - accuracy: 0.4062\n","Epoch 5: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4770 - accuracy: 0.3989 - val_loss: 1.6481 - val_accuracy: 0.4295\n","Epoch 6/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.5539 - accuracy: 0.4009\n","Epoch 6: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5285 - accuracy: 0.4068 - val_loss: 1.3421 - val_accuracy: 0.3431\n","Epoch 7/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.4495 - accuracy: 0.4030\n","Epoch 7: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4600 - accuracy: 0.4043 - val_loss: 1.8971 - val_accuracy: 0.3207\n","Epoch 8/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5177 - accuracy: 0.4034\n","Epoch 8: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 7ms/step - loss: 1.5216 - accuracy: 0.4035 - val_loss: 1.3729 - val_accuracy: 0.4742\n","Epoch 9/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.3854 - accuracy: 0.4441\n","Epoch 9: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.3855 - accuracy: 0.4423 - val_loss: 1.3950 - val_accuracy: 0.4257\n","Epoch 10/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4247 - accuracy: 0.4322\n","Epoch 10: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4394 - accuracy: 0.4302 - val_loss: 1.5790 - val_accuracy: 0.3178\n","Epoch 11/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.4585 - accuracy: 0.4266\n","Epoch 11: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4480 - accuracy: 0.4314 - val_loss: 1.3601 - val_accuracy: 0.4713\n","Epoch 12/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4597 - accuracy: 0.4481\n","Epoch 12: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4585 - accuracy: 0.4469 - val_loss: 1.7678 - val_accuracy: 0.4908\n","Epoch 13/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4481 - accuracy: 0.4375\n","Epoch 13: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4509 - accuracy: 0.4406 - val_loss: 1.3637 - val_accuracy: 0.4363\n","Epoch 14/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.4106 - accuracy: 0.4527\n","Epoch 14: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4090 - accuracy: 0.4481 - val_loss: 1.4977 - val_accuracy: 0.2809\n","Epoch 15/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.4695 - accuracy: 0.4296\n","Epoch 15: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4534 - accuracy: 0.4343 - val_loss: 1.3889 - val_accuracy: 0.4713\n","Epoch 16/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4296 - accuracy: 0.4326\n","Epoch 16: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4529 - accuracy: 0.4314 - val_loss: 1.8018 - val_accuracy: 0.4684\n","Epoch 17/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.4927 - accuracy: 0.4252\n","Epoch 17: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4995 - accuracy: 0.4243 - val_loss: 1.6104 - val_accuracy: 0.4674\n","Epoch 18/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.4699 - accuracy: 0.4187\n","Epoch 18: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 5ms/step - loss: 1.4643 - accuracy: 0.4177 - val_loss: 1.3691 - val_accuracy: 0.4402\n","Epoch 19/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.4528 - accuracy: 0.4426\n","Epoch 19: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4561 - accuracy: 0.4398 - val_loss: 1.3901 - val_accuracy: 0.4101\n","Epoch 20/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4495 - accuracy: 0.4431\n","Epoch 20: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4495 - accuracy: 0.4431 - val_loss: 1.4833 - val_accuracy: 0.4665\n","Epoch 21/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.4352 - accuracy: 0.4237\n","Epoch 21: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4274 - accuracy: 0.4256 - val_loss: 1.4232 - val_accuracy: 0.3732\n","Epoch 22/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.4288 - accuracy: 0.4423\n","Epoch 22: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4341 - accuracy: 0.4402 - val_loss: 1.7731 - val_accuracy: 0.4674\n","Epoch 23/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4775 - accuracy: 0.4380\n","Epoch 23: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4654 - accuracy: 0.4402 - val_loss: 1.3791 - val_accuracy: 0.4412\n","Epoch 24/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.5653 - accuracy: 0.4357\n","Epoch 24: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5645 - accuracy: 0.4335 - val_loss: 1.5348 - val_accuracy: 0.4538\n","Epoch 25/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.4186 - accuracy: 0.4344\n","Epoch 25: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4262 - accuracy: 0.4323 - val_loss: 1.4257 - val_accuracy: 0.4111\n","Epoch 26/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.4186 - accuracy: 0.4357\n","Epoch 26: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4300 - accuracy: 0.4385 - val_loss: 1.6602 - val_accuracy: 0.3712\n","Epoch 27/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4979 - accuracy: 0.4265\n","Epoch 27: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 1s 10ms/step - loss: 1.4975 - accuracy: 0.4277 - val_loss: 1.4566 - val_accuracy: 0.4500\n","Epoch 28/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.4735 - accuracy: 0.4510\n","Epoch 28: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4691 - accuracy: 0.4502 - val_loss: 1.4086 - val_accuracy: 0.4305\n","Epoch 29/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.3818 - accuracy: 0.4524\n","Epoch 29: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 1s 7ms/step - loss: 1.3977 - accuracy: 0.4523 - val_loss: 1.5402 - val_accuracy: 0.3188\n","Epoch 30/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4426 - accuracy: 0.4481\n","Epoch 30: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4426 - accuracy: 0.4481 - val_loss: 1.3565 - val_accuracy: 0.4198\n","Epoch 31/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4107 - accuracy: 0.4570\n","Epoch 31: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4155 - accuracy: 0.4539 - val_loss: 1.5467 - val_accuracy: 0.4490\n","Epoch 32/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.3285 - accuracy: 0.4678\n","Epoch 32: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.3423 - accuracy: 0.4681 - val_loss: 1.5090 - val_accuracy: 0.3625\n","46/46 [==============================] - 0s 3ms/step\n","0.48435374149659866\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["63/75 [========================>.....] - ETA: 0s - loss: 4.0547 - accuracy: 0.2073\n","Epoch 1: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 2s 10ms/step - loss: 3.7000 - accuracy: 0.2430 - val_loss: 1.9314 - val_accuracy: 0.3975\n","Epoch 2/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.7666 - accuracy: 0.4228\n","Epoch 2: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.7662 - accuracy: 0.4168 - val_loss: 1.5633 - val_accuracy: 0.4830\n","Epoch 3/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5843 - accuracy: 0.4280\n","Epoch 3: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5760 - accuracy: 0.4260 - val_loss: 1.4897 - val_accuracy: 0.4150\n","Epoch 4/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5665 - accuracy: 0.4337\n","Epoch 4: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5653 - accuracy: 0.4356 - val_loss: 1.6476 - val_accuracy: 0.3635\n","Epoch 5/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5734 - accuracy: 0.4223\n","Epoch 5: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5808 - accuracy: 0.4164 - val_loss: 1.3933 - val_accuracy: 0.4500\n","Epoch 6/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5133 - accuracy: 0.4380\n","Epoch 6: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5015 - accuracy: 0.4398 - val_loss: 1.6419 - val_accuracy: 0.3751\n","Epoch 7/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.5129 - accuracy: 0.4439\n","Epoch 7: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5228 - accuracy: 0.4393 - val_loss: 1.6570 - val_accuracy: 0.4325\n","Epoch 8/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4868 - accuracy: 0.4331\n","Epoch 8: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4868 - accuracy: 0.4331 - val_loss: 1.5281 - val_accuracy: 0.4636\n","Epoch 9/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.4921 - accuracy: 0.4105\n","Epoch 9: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4902 - accuracy: 0.4156 - val_loss: 1.4246 - val_accuracy: 0.4470\n","Epoch 10/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4962 - accuracy: 0.4500\n","Epoch 10: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4923 - accuracy: 0.4502 - val_loss: 1.4510 - val_accuracy: 0.3858\n","Epoch 11/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.4675 - accuracy: 0.4338\n","Epoch 11: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4829 - accuracy: 0.4356 - val_loss: 1.4506 - val_accuracy: 0.3858\n","Epoch 12/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.4605 - accuracy: 0.4432\n","Epoch 12: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4941 - accuracy: 0.4435 - val_loss: 1.3854 - val_accuracy: 0.4548\n","Epoch 13/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4921 - accuracy: 0.4204\n","Epoch 13: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4904 - accuracy: 0.4214 - val_loss: 1.5793 - val_accuracy: 0.4820\n","Epoch 14/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.4668 - accuracy: 0.4349\n","Epoch 14: val_accuracy did not improve from 0.49854\n","75/75 [==============================] - 1s 7ms/step - loss: 1.4728 - accuracy: 0.4318 - val_loss: 1.5320 - val_accuracy: 0.4130\n","Epoch 15/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.4579 - accuracy: 0.4579\n","Epoch 15: val_accuracy improved from 0.49854 to 0.51020, saving model to winewhite_tnn2.h5\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4605 - accuracy: 0.4514 - val_loss: 1.3567 - val_accuracy: 0.5102\n","Epoch 16/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.4683 - accuracy: 0.4375\n","Epoch 16: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4689 - accuracy: 0.4389 - val_loss: 1.7062 - val_accuracy: 0.4665\n","Epoch 17/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.4531 - accuracy: 0.4503\n","Epoch 17: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4543 - accuracy: 0.4481 - val_loss: 1.8611 - val_accuracy: 0.3683\n","Epoch 18/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.5802 - accuracy: 0.4277\n","Epoch 18: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5620 - accuracy: 0.4323 - val_loss: 1.5467 - val_accuracy: 0.3596\n","Epoch 19/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.4526 - accuracy: 0.4389\n","Epoch 19: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4596 - accuracy: 0.4410 - val_loss: 1.4927 - val_accuracy: 0.4121\n","Epoch 20/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4345 - accuracy: 0.4409\n","Epoch 20: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4545 - accuracy: 0.4377 - val_loss: 1.4642 - val_accuracy: 0.4976\n","Epoch 21/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4544 - accuracy: 0.4256\n","Epoch 21: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4544 - accuracy: 0.4256 - val_loss: 1.4849 - val_accuracy: 0.4247\n","Epoch 22/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5010 - accuracy: 0.4201\n","Epoch 22: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4907 - accuracy: 0.4231 - val_loss: 1.8200 - val_accuracy: 0.3936\n","Epoch 23/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5334 - accuracy: 0.4216\n","Epoch 23: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4987 - accuracy: 0.4298 - val_loss: 1.5734 - val_accuracy: 0.4470\n","Epoch 24/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4691 - accuracy: 0.4552\n","Epoch 24: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4677 - accuracy: 0.4519 - val_loss: 1.3999 - val_accuracy: 0.4480\n","Epoch 25/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4842 - accuracy: 0.4535\n","Epoch 25: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4934 - accuracy: 0.4523 - val_loss: 1.8608 - val_accuracy: 0.4470\n","Epoch 26/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.4657 - accuracy: 0.4371\n","Epoch 26: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4778 - accuracy: 0.4314 - val_loss: 1.7459 - val_accuracy: 0.3265\n","Epoch 27/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5202 - accuracy: 0.4295\n","Epoch 27: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 5ms/step - loss: 1.5010 - accuracy: 0.4306 - val_loss: 1.4066 - val_accuracy: 0.4645\n","Epoch 28/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.4550 - accuracy: 0.4413\n","Epoch 28: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4522 - accuracy: 0.4456 - val_loss: 1.5968 - val_accuracy: 0.4276\n","Epoch 29/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.5115 - accuracy: 0.4375\n","Epoch 29: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4978 - accuracy: 0.4406 - val_loss: 1.3217 - val_accuracy: 0.4665\n","Epoch 30/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.4505 - accuracy: 0.4448\n","Epoch 30: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4473 - accuracy: 0.4452 - val_loss: 1.5178 - val_accuracy: 0.4577\n","Epoch 31/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5351 - accuracy: 0.4159\n","Epoch 31: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5379 - accuracy: 0.4239 - val_loss: 1.4313 - val_accuracy: 0.4879\n","Epoch 32/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4476 - accuracy: 0.4418\n","Epoch 32: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4614 - accuracy: 0.4431 - val_loss: 1.4133 - val_accuracy: 0.4879\n","Epoch 33/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4865 - accuracy: 0.4268\n","Epoch 33: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5016 - accuracy: 0.4260 - val_loss: 1.4517 - val_accuracy: 0.4237\n","Epoch 34/100\n","62/75 [=======================>......] - ETA: 0s - loss: 1.5104 - accuracy: 0.4269\n","Epoch 34: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5187 - accuracy: 0.4293 - val_loss: 1.4699 - val_accuracy: 0.3819\n","Epoch 35/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4581 - accuracy: 0.4502\n","Epoch 35: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4502 - accuracy: 0.4502 - val_loss: 1.4529 - val_accuracy: 0.4315\n","46/46 [==============================] - 1s 4ms/step\n","0.5122448979591837\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["62/75 [=======================>......] - ETA: 0s - loss: 4.4801 - accuracy: 0.1794\n","Epoch 1: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 2s 11ms/step - loss: 4.1306 - accuracy: 0.2213 - val_loss: 2.2169 - val_accuracy: 0.3926\n","Epoch 2/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.9697 - accuracy: 0.3833\n","Epoch 2: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.9706 - accuracy: 0.3806 - val_loss: 1.8337 - val_accuracy: 0.2750\n","Epoch 3/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.8355 - accuracy: 0.3909\n","Epoch 3: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 5ms/step - loss: 1.8663 - accuracy: 0.3847 - val_loss: 1.7978 - val_accuracy: 0.3712\n","Epoch 4/100\n","75/75 [==============================] - ETA: 0s - loss: 1.7438 - accuracy: 0.4068\n","Epoch 4: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.7438 - accuracy: 0.4068 - val_loss: 1.8079 - val_accuracy: 0.3304\n","Epoch 5/100\n","75/75 [==============================] - ETA: 0s - loss: 1.6927 - accuracy: 0.4231\n","Epoch 5: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6927 - accuracy: 0.4231 - val_loss: 1.9242 - val_accuracy: 0.3780\n","Epoch 6/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.5490 - accuracy: 0.4128\n","Epoch 6: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5637 - accuracy: 0.4085 - val_loss: 1.6356 - val_accuracy: 0.3537\n","Epoch 7/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5372 - accuracy: 0.4135\n","Epoch 7: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5170 - accuracy: 0.4135 - val_loss: 1.4956 - val_accuracy: 0.3508\n","Epoch 8/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.5329 - accuracy: 0.4191\n","Epoch 8: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5314 - accuracy: 0.4143 - val_loss: 1.4411 - val_accuracy: 0.4422\n","Epoch 9/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.4831 - accuracy: 0.4454\n","Epoch 9: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.5214 - accuracy: 0.4335 - val_loss: 1.5211 - val_accuracy: 0.4568\n","Epoch 10/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.4645 - accuracy: 0.4171\n","Epoch 10: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4674 - accuracy: 0.4206 - val_loss: 1.6073 - val_accuracy: 0.3907\n","Epoch 11/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5875 - accuracy: 0.4043\n","Epoch 11: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.5875 - accuracy: 0.4043 - val_loss: 1.5782 - val_accuracy: 0.4140\n","Epoch 12/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5081 - accuracy: 0.4266\n","Epoch 12: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 5ms/step - loss: 1.4920 - accuracy: 0.4206 - val_loss: 1.7003 - val_accuracy: 0.4509\n","Epoch 13/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5268 - accuracy: 0.4286\n","Epoch 13: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5326 - accuracy: 0.4289 - val_loss: 1.5804 - val_accuracy: 0.3965\n","Epoch 14/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.4910 - accuracy: 0.4259\n","Epoch 14: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4815 - accuracy: 0.4281 - val_loss: 1.4882 - val_accuracy: 0.4422\n","Epoch 15/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4648 - accuracy: 0.4185\n","Epoch 15: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4639 - accuracy: 0.4189 - val_loss: 1.3401 - val_accuracy: 0.3528\n","Epoch 16/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5404 - accuracy: 0.4012\n","Epoch 16: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.5514 - accuracy: 0.4002 - val_loss: 1.7072 - val_accuracy: 0.3392\n","Epoch 17/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5930 - accuracy: 0.3947\n","Epoch 17: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5930 - accuracy: 0.3947 - val_loss: 1.4280 - val_accuracy: 0.3537\n","Epoch 18/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.5129 - accuracy: 0.4165\n","Epoch 18: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5163 - accuracy: 0.4152 - val_loss: 1.5297 - val_accuracy: 0.3421\n","Epoch 19/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4443 - accuracy: 0.4438\n","Epoch 19: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4396 - accuracy: 0.4431 - val_loss: 1.7331 - val_accuracy: 0.4694\n","Epoch 20/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.5033 - accuracy: 0.4159\n","Epoch 20: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.4966 - accuracy: 0.4148 - val_loss: 1.3608 - val_accuracy: 0.3654\n","Epoch 21/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.4425 - accuracy: 0.4432\n","Epoch 21: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4542 - accuracy: 0.4402 - val_loss: 1.5798 - val_accuracy: 0.4626\n","Epoch 22/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5193 - accuracy: 0.4291\n","Epoch 22: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5169 - accuracy: 0.4302 - val_loss: 1.3968 - val_accuracy: 0.4587\n","Epoch 23/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4826 - accuracy: 0.4439\n","Epoch 23: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4826 - accuracy: 0.4439 - val_loss: 1.6835 - val_accuracy: 0.4636\n","Epoch 24/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.5675 - accuracy: 0.4149\n","Epoch 24: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 9ms/step - loss: 1.5643 - accuracy: 0.4185 - val_loss: 1.5989 - val_accuracy: 0.4179\n","Epoch 25/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.5311 - accuracy: 0.4164\n","Epoch 25: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5483 - accuracy: 0.4135 - val_loss: 1.6056 - val_accuracy: 0.4091\n","Epoch 26/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5497 - accuracy: 0.4233\n","Epoch 26: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5346 - accuracy: 0.4268 - val_loss: 1.3822 - val_accuracy: 0.4917\n","Epoch 27/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4389 - accuracy: 0.4611\n","Epoch 27: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4367 - accuracy: 0.4656 - val_loss: 1.6934 - val_accuracy: 0.3858\n","Epoch 28/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.5286 - accuracy: 0.3938\n","Epoch 28: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 5ms/step - loss: 1.5269 - accuracy: 0.3972 - val_loss: 1.5447 - val_accuracy: 0.4519\n","Epoch 29/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4763 - accuracy: 0.4130\n","Epoch 29: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4788 - accuracy: 0.4102 - val_loss: 1.5936 - val_accuracy: 0.3605\n","Epoch 30/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.4670 - accuracy: 0.4119\n","Epoch 30: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4771 - accuracy: 0.4127 - val_loss: 1.4648 - val_accuracy: 0.2672\n","Epoch 31/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5066 - accuracy: 0.4024\n","Epoch 31: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5069 - accuracy: 0.4081 - val_loss: 1.4961 - val_accuracy: 0.3615\n","Epoch 32/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5874 - accuracy: 0.4206\n","Epoch 32: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5848 - accuracy: 0.4202 - val_loss: 1.5148 - val_accuracy: 0.4480\n","Epoch 33/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.6495 - accuracy: 0.3928\n","Epoch 33: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6410 - accuracy: 0.4006 - val_loss: 1.6772 - val_accuracy: 0.4694\n","Epoch 34/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.4906 - accuracy: 0.4411\n","Epoch 34: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4830 - accuracy: 0.4435 - val_loss: 1.4350 - val_accuracy: 0.3362\n","Epoch 35/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.4780 - accuracy: 0.4409\n","Epoch 35: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4883 - accuracy: 0.4402 - val_loss: 1.6528 - val_accuracy: 0.3411\n","Epoch 36/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.5790 - accuracy: 0.4033\n","Epoch 36: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 5ms/step - loss: 1.5666 - accuracy: 0.4110 - val_loss: 1.7411 - val_accuracy: 0.4917\n","Epoch 37/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4821 - accuracy: 0.4556\n","Epoch 37: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4687 - accuracy: 0.4539 - val_loss: 1.3188 - val_accuracy: 0.4548\n","Epoch 38/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.4767 - accuracy: 0.4385\n","Epoch 38: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4711 - accuracy: 0.4427 - val_loss: 1.2867 - val_accuracy: 0.5073\n","Epoch 39/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4318 - accuracy: 0.4256\n","Epoch 39: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4318 - accuracy: 0.4256 - val_loss: 1.5833 - val_accuracy: 0.4694\n","Epoch 40/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.5933 - accuracy: 0.4148\n","Epoch 40: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.6004 - accuracy: 0.4168 - val_loss: 1.4893 - val_accuracy: 0.4859\n","Epoch 41/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5178 - accuracy: 0.4193\n","Epoch 41: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5178 - accuracy: 0.4193 - val_loss: 1.3689 - val_accuracy: 0.4859\n","Epoch 42/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4469 - accuracy: 0.4268\n","Epoch 42: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4755 - accuracy: 0.4223 - val_loss: 1.5271 - val_accuracy: 0.4888\n","Epoch 43/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.5184 - accuracy: 0.4221\n","Epoch 43: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5100 - accuracy: 0.4210 - val_loss: 1.3934 - val_accuracy: 0.4412\n","Epoch 44/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4932 - accuracy: 0.4463\n","Epoch 44: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4937 - accuracy: 0.4477 - val_loss: 1.9191 - val_accuracy: 0.4461\n","Epoch 45/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5751 - accuracy: 0.4266\n","Epoch 45: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5657 - accuracy: 0.4306 - val_loss: 1.5823 - val_accuracy: 0.4189\n","Epoch 46/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5439 - accuracy: 0.4123\n","Epoch 46: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5439 - accuracy: 0.4123 - val_loss: 1.7732 - val_accuracy: 0.4266\n","Epoch 47/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5110 - accuracy: 0.4248\n","Epoch 47: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5078 - accuracy: 0.4252 - val_loss: 1.4047 - val_accuracy: 0.4500\n","Epoch 48/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.4257 - accuracy: 0.4201\n","Epoch 48: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4263 - accuracy: 0.4198 - val_loss: 1.7344 - val_accuracy: 0.4645\n","Epoch 49/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.4962 - accuracy: 0.4318\n","Epoch 49: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5125 - accuracy: 0.4273 - val_loss: 1.3575 - val_accuracy: 0.4519\n","Epoch 50/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5796 - accuracy: 0.4257\n","Epoch 50: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5751 - accuracy: 0.4256 - val_loss: 1.4310 - val_accuracy: 0.4257\n","Epoch 51/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.5192 - accuracy: 0.4411\n","Epoch 51: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5267 - accuracy: 0.4444 - val_loss: 1.4878 - val_accuracy: 0.4879\n","Epoch 52/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.4544 - accuracy: 0.4416\n","Epoch 52: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4505 - accuracy: 0.4352 - val_loss: 1.3611 - val_accuracy: 0.5005\n","Epoch 53/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.5744 - accuracy: 0.4138\n","Epoch 53: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5685 - accuracy: 0.4198 - val_loss: 1.7161 - val_accuracy: 0.3596\n","Epoch 54/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.5232 - accuracy: 0.4080\n","Epoch 54: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5266 - accuracy: 0.4135 - val_loss: 1.3258 - val_accuracy: 0.2983\n","Epoch 55/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.5227 - accuracy: 0.4182\n","Epoch 55: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5388 - accuracy: 0.4268 - val_loss: 1.5023 - val_accuracy: 0.4266\n","Epoch 56/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.5423 - accuracy: 0.4341\n","Epoch 56: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5499 - accuracy: 0.4356 - val_loss: 1.4475 - val_accuracy: 0.2789\n","Epoch 57/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.4331 - accuracy: 0.4388\n","Epoch 57: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.4552 - accuracy: 0.4364 - val_loss: 1.4536 - val_accuracy: 0.5015\n","Epoch 58/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4985 - accuracy: 0.4336\n","Epoch 58: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4808 - accuracy: 0.4368 - val_loss: 1.4266 - val_accuracy: 0.3771\n","46/46 [==============================] - 0s 3ms/step\n","0.4884353741496599\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["63/75 [========================>.....] - ETA: 0s - loss: 2.1390 - accuracy: 0.3571\n","Epoch 1: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 2s 10ms/step - loss: 2.0574 - accuracy: 0.3714 - val_loss: 1.6715 - val_accuracy: 0.4334\n","Epoch 2/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.5690 - accuracy: 0.4288\n","Epoch 2: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 5ms/step - loss: 1.5633 - accuracy: 0.4239 - val_loss: 1.5609 - val_accuracy: 0.4363\n","Epoch 3/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.4610 - accuracy: 0.4599\n","Epoch 3: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 5ms/step - loss: 1.4621 - accuracy: 0.4498 - val_loss: 1.4542 - val_accuracy: 0.4626\n","Epoch 4/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4393 - accuracy: 0.4548\n","Epoch 4: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4491 - accuracy: 0.4498 - val_loss: 1.5661 - val_accuracy: 0.3022\n","Epoch 5/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.4331 - accuracy: 0.4531\n","Epoch 5: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.4361 - accuracy: 0.4481 - val_loss: 1.7871 - val_accuracy: 0.3421\n","Epoch 6/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4479 - accuracy: 0.4367\n","Epoch 6: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.4497 - accuracy: 0.4360 - val_loss: 1.5036 - val_accuracy: 0.3703\n","Epoch 7/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.4627 - accuracy: 0.4484\n","Epoch 7: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4591 - accuracy: 0.4531 - val_loss: 1.5753 - val_accuracy: 0.3926\n","Epoch 8/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4652 - accuracy: 0.4485\n","Epoch 8: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.4652 - accuracy: 0.4485 - val_loss: 1.5536 - val_accuracy: 0.4237\n","Epoch 9/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.4445 - accuracy: 0.4497\n","Epoch 9: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4465 - accuracy: 0.4489 - val_loss: 1.6711 - val_accuracy: 0.4548\n","Epoch 10/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5363 - accuracy: 0.4323\n","Epoch 10: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5250 - accuracy: 0.4343 - val_loss: 1.7255 - val_accuracy: 0.4422\n","Epoch 11/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5465 - accuracy: 0.4373\n","Epoch 11: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.5465 - accuracy: 0.4373 - val_loss: 1.6708 - val_accuracy: 0.3450\n","Epoch 12/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5077 - accuracy: 0.4517\n","Epoch 12: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4855 - accuracy: 0.4573 - val_loss: 1.4896 - val_accuracy: 0.4140\n","Epoch 13/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4955 - accuracy: 0.4712\n","Epoch 13: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4839 - accuracy: 0.4702 - val_loss: 1.4860 - val_accuracy: 0.4490\n","Epoch 14/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4810 - accuracy: 0.4497\n","Epoch 14: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.4830 - accuracy: 0.4506 - val_loss: 1.4844 - val_accuracy: 0.4558\n","Epoch 15/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4844 - accuracy: 0.4459\n","Epoch 15: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4802 - accuracy: 0.4464 - val_loss: 1.4011 - val_accuracy: 0.4587\n","Epoch 16/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4243 - accuracy: 0.4577\n","Epoch 16: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4243 - accuracy: 0.4577 - val_loss: 1.4443 - val_accuracy: 0.4470\n","Epoch 17/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.5111 - accuracy: 0.4307\n","Epoch 17: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5059 - accuracy: 0.4318 - val_loss: 1.5149 - val_accuracy: 0.4859\n","Epoch 18/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.5907 - accuracy: 0.4326\n","Epoch 18: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5953 - accuracy: 0.4310 - val_loss: 1.3517 - val_accuracy: 0.4879\n","Epoch 19/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.4813 - accuracy: 0.4309\n","Epoch 19: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4857 - accuracy: 0.4298 - val_loss: 1.4379 - val_accuracy: 0.3673\n","Epoch 20/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5268 - accuracy: 0.4435\n","Epoch 20: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5268 - accuracy: 0.4435 - val_loss: 1.5364 - val_accuracy: 0.4655\n","Epoch 21/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4719 - accuracy: 0.4546\n","Epoch 21: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 5ms/step - loss: 1.4708 - accuracy: 0.4585 - val_loss: 1.5689 - val_accuracy: 0.4431\n","Epoch 22/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.4454 - accuracy: 0.4465\n","Epoch 22: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4471 - accuracy: 0.4464 - val_loss: 1.5560 - val_accuracy: 0.4840\n","Epoch 23/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4631 - accuracy: 0.4341\n","Epoch 23: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4621 - accuracy: 0.4368 - val_loss: 1.4656 - val_accuracy: 0.5034\n","Epoch 24/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.3980 - accuracy: 0.4497\n","Epoch 24: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.3989 - accuracy: 0.4498 - val_loss: 1.6442 - val_accuracy: 0.4402\n","Epoch 25/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4873 - accuracy: 0.4250\n","Epoch 25: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4822 - accuracy: 0.4298 - val_loss: 1.4946 - val_accuracy: 0.4461\n","Epoch 26/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.4838 - accuracy: 0.4371\n","Epoch 26: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4751 - accuracy: 0.4393 - val_loss: 1.3728 - val_accuracy: 0.4908\n","Epoch 27/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.4744 - accuracy: 0.4515\n","Epoch 27: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4724 - accuracy: 0.4523 - val_loss: 1.6930 - val_accuracy: 0.4052\n","Epoch 28/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5021 - accuracy: 0.4476\n","Epoch 28: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.5035 - accuracy: 0.4464 - val_loss: 1.6236 - val_accuracy: 0.4101\n","Epoch 29/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4772 - accuracy: 0.4281\n","Epoch 29: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4772 - accuracy: 0.4281 - val_loss: 1.4558 - val_accuracy: 0.4325\n","Epoch 30/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5157 - accuracy: 0.4310\n","Epoch 30: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5157 - accuracy: 0.4310 - val_loss: 1.6859 - val_accuracy: 0.4568\n","Epoch 31/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5428 - accuracy: 0.4175\n","Epoch 31: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5411 - accuracy: 0.4156 - val_loss: 1.5744 - val_accuracy: 0.4830\n","Epoch 32/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5716 - accuracy: 0.4286\n","Epoch 32: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5709 - accuracy: 0.4289 - val_loss: 2.1942 - val_accuracy: 0.3071\n","Epoch 33/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4889 - accuracy: 0.4313\n","Epoch 33: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4929 - accuracy: 0.4339 - val_loss: 1.4416 - val_accuracy: 0.3751\n","Epoch 34/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.5006 - accuracy: 0.4497\n","Epoch 34: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4634 - accuracy: 0.4602 - val_loss: 1.6359 - val_accuracy: 0.3635\n","Epoch 35/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5234 - accuracy: 0.4245\n","Epoch 35: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5475 - accuracy: 0.4273 - val_loss: 1.6496 - val_accuracy: 0.3936\n","Epoch 36/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5016 - accuracy: 0.4335\n","Epoch 36: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5039 - accuracy: 0.4327 - val_loss: 1.3921 - val_accuracy: 0.3557\n","Epoch 37/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4737 - accuracy: 0.4312\n","Epoch 37: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4819 - accuracy: 0.4306 - val_loss: 1.5048 - val_accuracy: 0.4276\n","Epoch 38/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.4660 - accuracy: 0.4358\n","Epoch 38: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4705 - accuracy: 0.4348 - val_loss: 1.4538 - val_accuracy: 0.4684\n","Epoch 39/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.5409 - accuracy: 0.4223\n","Epoch 39: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5349 - accuracy: 0.4285 - val_loss: 1.2919 - val_accuracy: 0.4587\n","Epoch 40/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5195 - accuracy: 0.4417\n","Epoch 40: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.5164 - accuracy: 0.4427 - val_loss: 1.5310 - val_accuracy: 0.4645\n","Epoch 41/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.4444 - accuracy: 0.4576\n","Epoch 41: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.4391 - accuracy: 0.4552 - val_loss: 1.6574 - val_accuracy: 0.3819\n","Epoch 42/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5971 - accuracy: 0.4377\n","Epoch 42: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5971 - accuracy: 0.4377 - val_loss: 1.5619 - val_accuracy: 0.3013\n","Epoch 43/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4782 - accuracy: 0.4210\n","Epoch 43: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.4774 - accuracy: 0.4206 - val_loss: 1.5040 - val_accuracy: 0.4295\n","46/46 [==============================] - 1s 4ms/step\n","0.4931972789115646\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["67/75 [=========================>....] - ETA: 0s - loss: 2.2743 - accuracy: 0.3493\n","Epoch 1: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 2s 11ms/step - loss: 2.2347 - accuracy: 0.3501 - val_loss: 1.7547 - val_accuracy: 0.4121\n","Epoch 2/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.7120 - accuracy: 0.4130\n","Epoch 2: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6988 - accuracy: 0.4127 - val_loss: 1.5469 - val_accuracy: 0.3946\n","Epoch 3/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.6162 - accuracy: 0.3968\n","Epoch 3: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 5ms/step - loss: 1.6119 - accuracy: 0.3972 - val_loss: 1.5870 - val_accuracy: 0.3596\n","Epoch 4/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.5570 - accuracy: 0.4118\n","Epoch 4: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5422 - accuracy: 0.4168 - val_loss: 1.4589 - val_accuracy: 0.4150\n","Epoch 5/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.4571 - accuracy: 0.4204\n","Epoch 5: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4601 - accuracy: 0.4198 - val_loss: 1.4856 - val_accuracy: 0.3576\n","Epoch 6/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4291 - accuracy: 0.4308\n","Epoch 6: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4568 - accuracy: 0.4268 - val_loss: 1.4324 - val_accuracy: 0.4315\n","Epoch 7/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.4739 - accuracy: 0.4038\n","Epoch 7: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4765 - accuracy: 0.4068 - val_loss: 1.7157 - val_accuracy: 0.3732\n","Epoch 8/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4827 - accuracy: 0.4209\n","Epoch 8: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4592 - accuracy: 0.4248 - val_loss: 1.4099 - val_accuracy: 0.4023\n","Epoch 9/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.4326 - accuracy: 0.4247\n","Epoch 9: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4228 - accuracy: 0.4243 - val_loss: 1.5919 - val_accuracy: 0.3421\n","Epoch 10/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4084 - accuracy: 0.4371\n","Epoch 10: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.4103 - accuracy: 0.4356 - val_loss: 1.3697 - val_accuracy: 0.3780\n","Epoch 11/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5158 - accuracy: 0.4247\n","Epoch 11: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5214 - accuracy: 0.4198 - val_loss: 1.6452 - val_accuracy: 0.2847\n","Epoch 12/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.4681 - accuracy: 0.4427\n","Epoch 12: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4482 - accuracy: 0.4473 - val_loss: 1.5623 - val_accuracy: 0.3858\n","Epoch 13/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4470 - accuracy: 0.4306\n","Epoch 13: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4470 - accuracy: 0.4306 - val_loss: 1.3777 - val_accuracy: 0.4247\n","Epoch 14/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4962 - accuracy: 0.4364\n","Epoch 14: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4962 - accuracy: 0.4364 - val_loss: 1.4466 - val_accuracy: 0.3382\n","Epoch 15/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4045 - accuracy: 0.4327\n","Epoch 15: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4045 - accuracy: 0.4327 - val_loss: 1.4832 - val_accuracy: 0.3703\n","Epoch 16/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5363 - accuracy: 0.4370\n","Epoch 16: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5413 - accuracy: 0.4398 - val_loss: 1.6024 - val_accuracy: 0.4004\n","Epoch 17/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.4911 - accuracy: 0.4332\n","Epoch 17: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 5ms/step - loss: 1.4956 - accuracy: 0.4298 - val_loss: 1.3980 - val_accuracy: 0.4091\n","Epoch 18/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4648 - accuracy: 0.4487\n","Epoch 18: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5066 - accuracy: 0.4431 - val_loss: 1.5971 - val_accuracy: 0.4538\n","Epoch 19/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.5913 - accuracy: 0.4097\n","Epoch 19: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5968 - accuracy: 0.4089 - val_loss: 1.7430 - val_accuracy: 0.4227\n","Epoch 20/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.5176 - accuracy: 0.4300\n","Epoch 20: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5281 - accuracy: 0.4268 - val_loss: 1.5608 - val_accuracy: 0.4636\n","Epoch 21/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5664 - accuracy: 0.4453\n","Epoch 21: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5821 - accuracy: 0.4402 - val_loss: 1.7064 - val_accuracy: 0.3819\n","Epoch 22/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4981 - accuracy: 0.4531\n","Epoch 22: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5006 - accuracy: 0.4527 - val_loss: 1.5776 - val_accuracy: 0.4140\n","Epoch 23/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.5315 - accuracy: 0.4208\n","Epoch 23: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 9ms/step - loss: 1.5211 - accuracy: 0.4248 - val_loss: 1.3481 - val_accuracy: 0.4713\n","Epoch 24/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4343 - accuracy: 0.4414\n","Epoch 24: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4343 - accuracy: 0.4414 - val_loss: 1.3916 - val_accuracy: 0.4441\n","Epoch 25/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4515 - accuracy: 0.4312\n","Epoch 25: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 9ms/step - loss: 1.4458 - accuracy: 0.4327 - val_loss: 1.5142 - val_accuracy: 0.4422\n","Epoch 26/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.5087 - accuracy: 0.4409\n","Epoch 26: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5046 - accuracy: 0.4419 - val_loss: 1.7415 - val_accuracy: 0.4033\n","Epoch 27/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4759 - accuracy: 0.4430\n","Epoch 27: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.4769 - accuracy: 0.4427 - val_loss: 1.5051 - val_accuracy: 0.4043\n","Epoch 28/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4455 - accuracy: 0.4510\n","Epoch 28: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.4405 - accuracy: 0.4535 - val_loss: 1.6558 - val_accuracy: 0.4665\n","Epoch 29/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5856 - accuracy: 0.4312\n","Epoch 29: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5854 - accuracy: 0.4310 - val_loss: 1.4086 - val_accuracy: 0.4383\n","Epoch 30/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.4928 - accuracy: 0.4328\n","Epoch 30: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.4959 - accuracy: 0.4335 - val_loss: 1.8499 - val_accuracy: 0.4461\n","Epoch 31/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.5856 - accuracy: 0.4401\n","Epoch 31: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5803 - accuracy: 0.4402 - val_loss: 1.4742 - val_accuracy: 0.4159\n","Epoch 32/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4365 - accuracy: 0.4451\n","Epoch 32: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4413 - accuracy: 0.4456 - val_loss: 1.5657 - val_accuracy: 0.4529\n","Epoch 33/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5031 - accuracy: 0.4452\n","Epoch 33: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4831 - accuracy: 0.4506 - val_loss: 1.4602 - val_accuracy: 0.4606\n","Epoch 34/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5836 - accuracy: 0.4375\n","Epoch 34: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6157 - accuracy: 0.4293 - val_loss: 1.6604 - val_accuracy: 0.3936\n","Epoch 35/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5887 - accuracy: 0.4067\n","Epoch 35: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5799 - accuracy: 0.4143 - val_loss: 1.4624 - val_accuracy: 0.3965\n","Epoch 36/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.4900 - accuracy: 0.4208\n","Epoch 36: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4923 - accuracy: 0.4198 - val_loss: 1.5626 - val_accuracy: 0.3732\n","Epoch 37/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.4751 - accuracy: 0.4512\n","Epoch 37: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.4867 - accuracy: 0.4498 - val_loss: 1.6421 - val_accuracy: 0.3936\n","Epoch 38/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.5391 - accuracy: 0.4375\n","Epoch 38: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5574 - accuracy: 0.4385 - val_loss: 1.4656 - val_accuracy: 0.4334\n","Epoch 39/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.6515 - accuracy: 0.4126\n","Epoch 39: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.6546 - accuracy: 0.4127 - val_loss: 1.6709 - val_accuracy: 0.4470\n","Epoch 40/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.4907 - accuracy: 0.4622\n","Epoch 40: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.4961 - accuracy: 0.4585 - val_loss: 1.4871 - val_accuracy: 0.4218\n","Epoch 41/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.6995 - accuracy: 0.4282\n","Epoch 41: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.6957 - accuracy: 0.4298 - val_loss: 1.7131 - val_accuracy: 0.3858\n","Epoch 42/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.6380 - accuracy: 0.4303\n","Epoch 42: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6404 - accuracy: 0.4289 - val_loss: 1.4086 - val_accuracy: 0.4014\n","Epoch 43/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.5162 - accuracy: 0.4567\n","Epoch 43: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5487 - accuracy: 0.4506 - val_loss: 1.4756 - val_accuracy: 0.4694\n","46/46 [==============================] - 0s 2ms/step\n","0.47006802721088436\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["67/75 [=========================>....] - ETA: 0s - loss: 2.6375 - accuracy: 0.3386\n","Epoch 1: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 2s 15ms/step - loss: 2.5562 - accuracy: 0.3431 - val_loss: 1.7559 - val_accuracy: 0.4140\n","Epoch 2/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.7685 - accuracy: 0.4058\n","Epoch 2: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.7620 - accuracy: 0.4018 - val_loss: 1.7987 - val_accuracy: 0.3780\n","Epoch 3/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5478 - accuracy: 0.4544\n","Epoch 3: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5420 - accuracy: 0.4539 - val_loss: 1.5471 - val_accuracy: 0.3848\n","Epoch 4/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.4863 - accuracy: 0.4235\n","Epoch 4: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5106 - accuracy: 0.4268 - val_loss: 1.5476 - val_accuracy: 0.4033\n","Epoch 5/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.5819 - accuracy: 0.4324\n","Epoch 5: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5750 - accuracy: 0.4352 - val_loss: 1.4996 - val_accuracy: 0.4752\n","Epoch 6/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.5171 - accuracy: 0.4393\n","Epoch 6: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5084 - accuracy: 0.4406 - val_loss: 1.4855 - val_accuracy: 0.4568\n","Epoch 7/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5856 - accuracy: 0.4420\n","Epoch 7: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5750 - accuracy: 0.4335 - val_loss: 1.4952 - val_accuracy: 0.3858\n","Epoch 8/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5772 - accuracy: 0.4364\n","Epoch 8: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5772 - accuracy: 0.4364 - val_loss: 1.3526 - val_accuracy: 0.4694\n","Epoch 9/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.5931 - accuracy: 0.4098\n","Epoch 9: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5819 - accuracy: 0.4131 - val_loss: 1.4805 - val_accuracy: 0.4713\n","Epoch 10/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5563 - accuracy: 0.4171\n","Epoch 10: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5623 - accuracy: 0.4231 - val_loss: 1.3349 - val_accuracy: 0.4597\n","Epoch 11/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4394 - accuracy: 0.4460\n","Epoch 11: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.4394 - accuracy: 0.4460 - val_loss: 1.4440 - val_accuracy: 0.4295\n","Epoch 12/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5053 - accuracy: 0.4247\n","Epoch 12: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5005 - accuracy: 0.4239 - val_loss: 1.3659 - val_accuracy: 0.4694\n","Epoch 13/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.5437 - accuracy: 0.4321\n","Epoch 13: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5420 - accuracy: 0.4277 - val_loss: 1.3527 - val_accuracy: 0.4752\n","Epoch 14/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4378 - accuracy: 0.4303\n","Epoch 14: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4342 - accuracy: 0.4285 - val_loss: 1.5904 - val_accuracy: 0.4014\n","Epoch 15/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4867 - accuracy: 0.4322\n","Epoch 15: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5087 - accuracy: 0.4352 - val_loss: 1.3061 - val_accuracy: 0.4412\n","Epoch 16/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4687 - accuracy: 0.4154\n","Epoch 16: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4706 - accuracy: 0.4160 - val_loss: 1.9919 - val_accuracy: 0.3673\n","Epoch 17/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4936 - accuracy: 0.4264\n","Epoch 17: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4936 - accuracy: 0.4264 - val_loss: 1.4269 - val_accuracy: 0.4325\n","Epoch 18/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4561 - accuracy: 0.4373\n","Epoch 18: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.4561 - accuracy: 0.4373 - val_loss: 1.3695 - val_accuracy: 0.4645\n","Epoch 19/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4405 - accuracy: 0.4413\n","Epoch 19: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 5ms/step - loss: 1.4735 - accuracy: 0.4406 - val_loss: 1.9132 - val_accuracy: 0.4616\n","Epoch 20/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5552 - accuracy: 0.4193\n","Epoch 20: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5554 - accuracy: 0.4210 - val_loss: 1.7301 - val_accuracy: 0.4752\n","Epoch 21/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5733 - accuracy: 0.4190\n","Epoch 21: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6197 - accuracy: 0.4168 - val_loss: 1.4892 - val_accuracy: 0.3294\n","Epoch 22/100\n","75/75 [==============================] - ETA: 0s - loss: 1.6287 - accuracy: 0.4206\n","Epoch 22: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6287 - accuracy: 0.4206 - val_loss: 1.4830 - val_accuracy: 0.4937\n","Epoch 23/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5980 - accuracy: 0.4144\n","Epoch 23: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5657 - accuracy: 0.4143 - val_loss: 1.5862 - val_accuracy: 0.4393\n","Epoch 24/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5274 - accuracy: 0.4163\n","Epoch 24: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5542 - accuracy: 0.4189 - val_loss: 1.6719 - val_accuracy: 0.4529\n","Epoch 25/100\n","75/75 [==============================] - ETA: 0s - loss: 1.6255 - accuracy: 0.4252\n","Epoch 25: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6255 - accuracy: 0.4252 - val_loss: 1.5147 - val_accuracy: 0.3703\n","Epoch 26/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.6003 - accuracy: 0.4279\n","Epoch 26: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6201 - accuracy: 0.4214 - val_loss: 1.5249 - val_accuracy: 0.3664\n","Epoch 27/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.6098 - accuracy: 0.4226\n","Epoch 27: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5617 - accuracy: 0.4260 - val_loss: 1.4118 - val_accuracy: 0.4179\n","Epoch 28/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.6429 - accuracy: 0.4210\n","Epoch 28: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.6440 - accuracy: 0.4218 - val_loss: 1.6424 - val_accuracy: 0.3693\n","Epoch 29/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.6600 - accuracy: 0.4231\n","Epoch 29: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.6572 - accuracy: 0.4223 - val_loss: 1.5563 - val_accuracy: 0.3372\n","Epoch 30/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.5384 - accuracy: 0.4194\n","Epoch 30: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5515 - accuracy: 0.4227 - val_loss: 1.6515 - val_accuracy: 0.4266\n","Epoch 31/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.5404 - accuracy: 0.4230\n","Epoch 31: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5276 - accuracy: 0.4223 - val_loss: 1.5224 - val_accuracy: 0.4140\n","Epoch 32/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.4878 - accuracy: 0.4171\n","Epoch 32: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5072 - accuracy: 0.4235 - val_loss: 1.8563 - val_accuracy: 0.4354\n","Epoch 33/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.6738 - accuracy: 0.4269\n","Epoch 33: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.6613 - accuracy: 0.4256 - val_loss: 1.3091 - val_accuracy: 0.4976\n","Epoch 34/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.4944 - accuracy: 0.4231\n","Epoch 34: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4880 - accuracy: 0.4331 - val_loss: 1.7615 - val_accuracy: 0.3722\n","Epoch 35/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.4858 - accuracy: 0.4448\n","Epoch 35: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4899 - accuracy: 0.4460 - val_loss: 1.6077 - val_accuracy: 0.4723\n","Epoch 36/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.5257 - accuracy: 0.4335\n","Epoch 36: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5324 - accuracy: 0.4343 - val_loss: 1.8016 - val_accuracy: 0.4315\n","Epoch 37/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.6633 - accuracy: 0.4358\n","Epoch 37: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.6622 - accuracy: 0.4377 - val_loss: 1.5342 - val_accuracy: 0.4947\n","Epoch 38/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.4672 - accuracy: 0.4469\n","Epoch 38: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.4764 - accuracy: 0.4477 - val_loss: 2.1464 - val_accuracy: 0.3965\n","Epoch 39/100\n","75/75 [==============================] - ETA: 0s - loss: 1.6043 - accuracy: 0.4343\n","Epoch 39: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6043 - accuracy: 0.4343 - val_loss: 1.7245 - val_accuracy: 0.4354\n","Epoch 40/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.5804 - accuracy: 0.4193\n","Epoch 40: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5687 - accuracy: 0.4239 - val_loss: 1.4817 - val_accuracy: 0.4470\n","Epoch 41/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5417 - accuracy: 0.4328\n","Epoch 41: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5461 - accuracy: 0.4368 - val_loss: 1.8128 - val_accuracy: 0.3800\n","Epoch 42/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5942 - accuracy: 0.4202\n","Epoch 42: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5942 - accuracy: 0.4202 - val_loss: 1.4951 - val_accuracy: 0.4548\n","Epoch 43/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.5916 - accuracy: 0.4081\n","Epoch 43: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5829 - accuracy: 0.4048 - val_loss: 1.4949 - val_accuracy: 0.3994\n","Epoch 44/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.5661 - accuracy: 0.4429\n","Epoch 44: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5631 - accuracy: 0.4435 - val_loss: 1.6617 - val_accuracy: 0.4363\n","Epoch 45/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.6369 - accuracy: 0.4329\n","Epoch 45: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6355 - accuracy: 0.4335 - val_loss: 1.4393 - val_accuracy: 0.4645\n","Epoch 46/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.6209 - accuracy: 0.4271\n","Epoch 46: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6757 - accuracy: 0.4218 - val_loss: 1.7204 - val_accuracy: 0.4733\n","Epoch 47/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.5954 - accuracy: 0.4512\n","Epoch 47: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6315 - accuracy: 0.4460 - val_loss: 1.8572 - val_accuracy: 0.3149\n","Epoch 48/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5653 - accuracy: 0.4364\n","Epoch 48: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5653 - accuracy: 0.4364 - val_loss: 1.7573 - val_accuracy: 0.4354\n","Epoch 49/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.4985 - accuracy: 0.4366\n","Epoch 49: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5107 - accuracy: 0.4377 - val_loss: 1.6193 - val_accuracy: 0.4509\n","Epoch 50/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.5977 - accuracy: 0.4194\n","Epoch 50: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5954 - accuracy: 0.4227 - val_loss: 1.4059 - val_accuracy: 0.4665\n","Epoch 51/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4426 - accuracy: 0.4510\n","Epoch 51: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4452 - accuracy: 0.4514 - val_loss: 1.3981 - val_accuracy: 0.4849\n","Epoch 52/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5799 - accuracy: 0.4236\n","Epoch 52: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5961 - accuracy: 0.4293 - val_loss: 1.6105 - val_accuracy: 0.4402\n","Epoch 53/100\n","75/75 [==============================] - ETA: 0s - loss: 1.6206 - accuracy: 0.4239\n","Epoch 53: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6206 - accuracy: 0.4239 - val_loss: 1.4601 - val_accuracy: 0.4713\n","46/46 [==============================] - 0s 3ms/step\n","0.5040816326530613\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["75/75 [==============================] - ETA: 0s - loss: 2.6467 - accuracy: 0.3193\n","Epoch 1: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 3s 17ms/step - loss: 2.6467 - accuracy: 0.3193 - val_loss: 1.7787 - val_accuracy: 0.4461\n","Epoch 2/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.7105 - accuracy: 0.4332\n","Epoch 2: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.7104 - accuracy: 0.4323 - val_loss: 1.6072 - val_accuracy: 0.4597\n","Epoch 3/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5716 - accuracy: 0.4168\n","Epoch 3: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5428 - accuracy: 0.4223 - val_loss: 1.4216 - val_accuracy: 0.4849\n","Epoch 4/100\n","62/75 [=======================>......] - ETA: 0s - loss: 1.5609 - accuracy: 0.4294\n","Epoch 4: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5376 - accuracy: 0.4339 - val_loss: 1.6581 - val_accuracy: 0.4704\n","Epoch 5/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.4588 - accuracy: 0.4597\n","Epoch 5: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4616 - accuracy: 0.4598 - val_loss: 1.7013 - val_accuracy: 0.4237\n","Epoch 6/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.6034 - accuracy: 0.4340\n","Epoch 6: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5971 - accuracy: 0.4314 - val_loss: 1.4874 - val_accuracy: 0.4480\n","Epoch 7/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5200 - accuracy: 0.4474\n","Epoch 7: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5112 - accuracy: 0.4498 - val_loss: 1.6199 - val_accuracy: 0.3392\n","Epoch 8/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4986 - accuracy: 0.4381\n","Epoch 8: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.4986 - accuracy: 0.4381 - val_loss: 1.3784 - val_accuracy: 0.4898\n","Epoch 9/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.4960 - accuracy: 0.4281\n","Epoch 9: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5085 - accuracy: 0.4210 - val_loss: 1.4970 - val_accuracy: 0.4490\n","Epoch 10/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4405 - accuracy: 0.4548\n","Epoch 10: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4458 - accuracy: 0.4531 - val_loss: 1.7412 - val_accuracy: 0.4451\n","Epoch 11/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4420 - accuracy: 0.4635\n","Epoch 11: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4614 - accuracy: 0.4648 - val_loss: 1.3403 - val_accuracy: 0.4742\n","Epoch 12/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4180 - accuracy: 0.4649\n","Epoch 12: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4196 - accuracy: 0.4639 - val_loss: 1.4224 - val_accuracy: 0.4014\n","Epoch 13/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.4518 - accuracy: 0.4196\n","Epoch 13: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4377 - accuracy: 0.4227 - val_loss: 1.4238 - val_accuracy: 0.4344\n","Epoch 14/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5115 - accuracy: 0.4345\n","Epoch 14: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5124 - accuracy: 0.4268 - val_loss: 1.4579 - val_accuracy: 0.4616\n","Epoch 15/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.4433 - accuracy: 0.4361\n","Epoch 15: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4413 - accuracy: 0.4393 - val_loss: 1.3397 - val_accuracy: 0.4062\n","Epoch 16/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5308 - accuracy: 0.4406\n","Epoch 16: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5308 - accuracy: 0.4406 - val_loss: 1.5354 - val_accuracy: 0.4849\n","Epoch 17/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4259 - accuracy: 0.4352\n","Epoch 17: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4259 - accuracy: 0.4352 - val_loss: 1.4442 - val_accuracy: 0.4082\n","Epoch 18/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4207 - accuracy: 0.4493\n","Epoch 18: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4162 - accuracy: 0.4502 - val_loss: 1.3009 - val_accuracy: 0.4995\n","Epoch 19/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4921 - accuracy: 0.4502\n","Epoch 19: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4921 - accuracy: 0.4502 - val_loss: 1.4004 - val_accuracy: 0.5092\n","Epoch 20/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5197 - accuracy: 0.4088\n","Epoch 20: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.5215 - accuracy: 0.4089 - val_loss: 1.4728 - val_accuracy: 0.4606\n","Epoch 21/100\n","75/75 [==============================] - ETA: 0s - loss: 1.4555 - accuracy: 0.4423\n","Epoch 21: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4555 - accuracy: 0.4423 - val_loss: 1.4600 - val_accuracy: 0.4043\n","Epoch 22/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5371 - accuracy: 0.4348\n","Epoch 22: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5371 - accuracy: 0.4348 - val_loss: 1.3556 - val_accuracy: 0.4995\n","Epoch 23/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5559 - accuracy: 0.4285\n","Epoch 23: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5559 - accuracy: 0.4285 - val_loss: 1.6229 - val_accuracy: 0.4043\n","Epoch 24/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.3988 - accuracy: 0.4494\n","Epoch 24: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.3909 - accuracy: 0.4514 - val_loss: 1.4847 - val_accuracy: 0.3887\n","Epoch 25/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.4220 - accuracy: 0.4388\n","Epoch 25: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 10ms/step - loss: 1.4170 - accuracy: 0.4389 - val_loss: 1.4515 - val_accuracy: 0.4976\n","Epoch 26/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.5511 - accuracy: 0.4604\n","Epoch 26: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5294 - accuracy: 0.4614 - val_loss: 1.3908 - val_accuracy: 0.4344\n","Epoch 27/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.5415 - accuracy: 0.4379\n","Epoch 27: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5379 - accuracy: 0.4385 - val_loss: 1.5308 - val_accuracy: 0.4548\n","Epoch 28/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.5231 - accuracy: 0.4416\n","Epoch 28: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5238 - accuracy: 0.4360 - val_loss: 1.5275 - val_accuracy: 0.4762\n","Epoch 29/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4571 - accuracy: 0.4546\n","Epoch 29: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4494 - accuracy: 0.4602 - val_loss: 1.4611 - val_accuracy: 0.4655\n","Epoch 30/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4649 - accuracy: 0.4471\n","Epoch 30: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4704 - accuracy: 0.4506 - val_loss: 1.4615 - val_accuracy: 0.4694\n","Epoch 31/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4125 - accuracy: 0.4502\n","Epoch 31: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 5ms/step - loss: 1.4378 - accuracy: 0.4427 - val_loss: 1.3909 - val_accuracy: 0.4111\n","Epoch 32/100\n","62/75 [=======================>......] - ETA: 0s - loss: 1.5849 - accuracy: 0.4355\n","Epoch 32: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5575 - accuracy: 0.4343 - val_loss: 1.4464 - val_accuracy: 0.4101\n","Epoch 33/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4708 - accuracy: 0.4404\n","Epoch 33: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5081 - accuracy: 0.4402 - val_loss: 1.4288 - val_accuracy: 0.4529\n","Epoch 34/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5469 - accuracy: 0.4379\n","Epoch 34: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5378 - accuracy: 0.4398 - val_loss: 1.3545 - val_accuracy: 0.5083\n","Epoch 35/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.3965 - accuracy: 0.4787\n","Epoch 35: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4156 - accuracy: 0.4652 - val_loss: 1.9801 - val_accuracy: 0.4645\n","Epoch 36/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5349 - accuracy: 0.4384\n","Epoch 36: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5400 - accuracy: 0.4385 - val_loss: 1.5328 - val_accuracy: 0.4538\n","Epoch 37/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5021 - accuracy: 0.4206\n","Epoch 37: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4843 - accuracy: 0.4264 - val_loss: 1.6030 - val_accuracy: 0.4480\n","Epoch 38/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.6090 - accuracy: 0.4238\n","Epoch 38: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6050 - accuracy: 0.4214 - val_loss: 1.5155 - val_accuracy: 0.3596\n","Epoch 39/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4256 - accuracy: 0.4481\n","Epoch 39: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4330 - accuracy: 0.4469 - val_loss: 1.3666 - val_accuracy: 0.3819\n","46/46 [==============================] - 0s 3ms/step\n","0.5068027210884354\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["63/75 [========================>.....] - ETA: 0s - loss: 3.1337 - accuracy: 0.2376\n","Epoch 1: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 2s 11ms/step - loss: 2.9355 - accuracy: 0.2622 - val_loss: 1.8901 - val_accuracy: 0.3946\n","Epoch 2/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.7558 - accuracy: 0.4080\n","Epoch 2: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.7437 - accuracy: 0.4089 - val_loss: 1.5876 - val_accuracy: 0.3936\n","Epoch 3/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.5810 - accuracy: 0.4071\n","Epoch 3: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5757 - accuracy: 0.4102 - val_loss: 1.6486 - val_accuracy: 0.3839\n","Epoch 4/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5850 - accuracy: 0.4053\n","Epoch 4: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5531 - accuracy: 0.4185 - val_loss: 1.5513 - val_accuracy: 0.4130\n","Epoch 5/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5515 - accuracy: 0.4475\n","Epoch 5: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5533 - accuracy: 0.4469 - val_loss: 1.5517 - val_accuracy: 0.4052\n","Epoch 6/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5421 - accuracy: 0.4268\n","Epoch 6: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5421 - accuracy: 0.4268 - val_loss: 1.6732 - val_accuracy: 0.4023\n","Epoch 7/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5625 - accuracy: 0.4345\n","Epoch 7: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5624 - accuracy: 0.4331 - val_loss: 1.6323 - val_accuracy: 0.4082\n","Epoch 8/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.4969 - accuracy: 0.4405\n","Epoch 8: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5018 - accuracy: 0.4398 - val_loss: 1.5379 - val_accuracy: 0.4344\n","Epoch 9/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.5118 - accuracy: 0.4313\n","Epoch 9: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5246 - accuracy: 0.4314 - val_loss: 1.4025 - val_accuracy: 0.3771\n","Epoch 10/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.5203 - accuracy: 0.4144\n","Epoch 10: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4917 - accuracy: 0.4223 - val_loss: 1.8344 - val_accuracy: 0.3800\n","Epoch 11/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.5292 - accuracy: 0.4299\n","Epoch 11: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5372 - accuracy: 0.4327 - val_loss: 1.8378 - val_accuracy: 0.3246\n","Epoch 12/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5653 - accuracy: 0.4299\n","Epoch 12: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5620 - accuracy: 0.4302 - val_loss: 1.7424 - val_accuracy: 0.3907\n","Epoch 13/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5875 - accuracy: 0.4196\n","Epoch 13: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5593 - accuracy: 0.4293 - val_loss: 1.5077 - val_accuracy: 0.4198\n","Epoch 14/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.6471 - accuracy: 0.4221\n","Epoch 14: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6545 - accuracy: 0.4223 - val_loss: 1.6810 - val_accuracy: 0.4470\n","Epoch 15/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.7864 - accuracy: 0.4072\n","Epoch 15: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.7389 - accuracy: 0.4152 - val_loss: 1.6724 - val_accuracy: 0.4704\n","Epoch 16/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.6086 - accuracy: 0.4408\n","Epoch 16: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5801 - accuracy: 0.4439 - val_loss: 1.6185 - val_accuracy: 0.4295\n","Epoch 17/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5973 - accuracy: 0.4379\n","Epoch 17: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6172 - accuracy: 0.4339 - val_loss: 2.3121 - val_accuracy: 0.3392\n","Epoch 18/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.6651 - accuracy: 0.4385\n","Epoch 18: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6610 - accuracy: 0.4389 - val_loss: 1.5873 - val_accuracy: 0.4266\n","Epoch 19/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5401 - accuracy: 0.4274\n","Epoch 19: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 5ms/step - loss: 1.5487 - accuracy: 0.4264 - val_loss: 1.3456 - val_accuracy: 0.4325\n","Epoch 20/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5746 - accuracy: 0.4273\n","Epoch 20: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5746 - accuracy: 0.4273 - val_loss: 1.5965 - val_accuracy: 0.4091\n","Epoch 21/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.5953 - accuracy: 0.4309\n","Epoch 21: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5863 - accuracy: 0.4298 - val_loss: 1.3077 - val_accuracy: 0.4597\n","Epoch 22/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.6002 - accuracy: 0.4243\n","Epoch 22: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6049 - accuracy: 0.4227 - val_loss: 1.8732 - val_accuracy: 0.4636\n","Epoch 23/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.5905 - accuracy: 0.4409\n","Epoch 23: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5882 - accuracy: 0.4423 - val_loss: 1.4359 - val_accuracy: 0.4431\n","Epoch 24/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5324 - accuracy: 0.4293\n","Epoch 24: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5439 - accuracy: 0.4298 - val_loss: 2.1823 - val_accuracy: 0.3246\n","Epoch 25/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5534 - accuracy: 0.4335\n","Epoch 25: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5534 - accuracy: 0.4335 - val_loss: 1.8464 - val_accuracy: 0.4121\n","Epoch 26/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.6047 - accuracy: 0.4278\n","Epoch 26: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6213 - accuracy: 0.4298 - val_loss: 1.5288 - val_accuracy: 0.4752\n","Epoch 27/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5854 - accuracy: 0.4265\n","Epoch 27: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5875 - accuracy: 0.4264 - val_loss: 1.7212 - val_accuracy: 0.4645\n","Epoch 28/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.5237 - accuracy: 0.4482\n","Epoch 28: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5260 - accuracy: 0.4473 - val_loss: 1.4268 - val_accuracy: 0.4684\n","Epoch 29/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.5203 - accuracy: 0.4491\n","Epoch 29: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5528 - accuracy: 0.4485 - val_loss: 1.5201 - val_accuracy: 0.4645\n","Epoch 30/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5526 - accuracy: 0.4510\n","Epoch 30: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5562 - accuracy: 0.4527 - val_loss: 1.8868 - val_accuracy: 0.4558\n","Epoch 31/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.5191 - accuracy: 0.4563\n","Epoch 31: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.5227 - accuracy: 0.4548 - val_loss: 1.3243 - val_accuracy: 0.4713\n","Epoch 32/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.4247 - accuracy: 0.4580\n","Epoch 32: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4381 - accuracy: 0.4564 - val_loss: 1.5568 - val_accuracy: 0.4451\n","Epoch 33/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5197 - accuracy: 0.4431\n","Epoch 33: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5197 - accuracy: 0.4431 - val_loss: 1.7927 - val_accuracy: 0.4810\n","Epoch 34/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5587 - accuracy: 0.4336\n","Epoch 34: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 9ms/step - loss: 1.5585 - accuracy: 0.4356 - val_loss: 1.6007 - val_accuracy: 0.4082\n","Epoch 35/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.5618 - accuracy: 0.4445\n","Epoch 35: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5846 - accuracy: 0.4456 - val_loss: 1.6151 - val_accuracy: 0.4121\n","Epoch 36/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5584 - accuracy: 0.4460\n","Epoch 36: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5584 - accuracy: 0.4460 - val_loss: 1.7014 - val_accuracy: 0.3800\n","Epoch 37/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5733 - accuracy: 0.4423\n","Epoch 37: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 9ms/step - loss: 1.5733 - accuracy: 0.4423 - val_loss: 1.4301 - val_accuracy: 0.4509\n","Epoch 38/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.5707 - accuracy: 0.4416\n","Epoch 38: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5585 - accuracy: 0.4385 - val_loss: 1.4083 - val_accuracy: 0.4577\n","Epoch 39/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.6250 - accuracy: 0.4262\n","Epoch 39: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.6325 - accuracy: 0.4235 - val_loss: 1.5128 - val_accuracy: 0.3780\n","Epoch 40/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.6107 - accuracy: 0.4319\n","Epoch 40: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6120 - accuracy: 0.4343 - val_loss: 1.8166 - val_accuracy: 0.3654\n","Epoch 41/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.6701 - accuracy: 0.4420\n","Epoch 41: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6472 - accuracy: 0.4448 - val_loss: 1.5456 - val_accuracy: 0.4121\n","Epoch 42/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.5794 - accuracy: 0.4223\n","Epoch 42: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5863 - accuracy: 0.4206 - val_loss: 1.7119 - val_accuracy: 0.4480\n","Epoch 43/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.5341 - accuracy: 0.4375\n","Epoch 43: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.5563 - accuracy: 0.4364 - val_loss: 1.6539 - val_accuracy: 0.4879\n","Epoch 44/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.6970 - accuracy: 0.4216\n","Epoch 44: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6750 - accuracy: 0.4277 - val_loss: 1.5977 - val_accuracy: 0.4665\n","Epoch 45/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.5986 - accuracy: 0.4286\n","Epoch 45: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5883 - accuracy: 0.4281 - val_loss: 1.5815 - val_accuracy: 0.4305\n","Epoch 46/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5101 - accuracy: 0.4493\n","Epoch 46: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5194 - accuracy: 0.4489 - val_loss: 1.8638 - val_accuracy: 0.3333\n","Epoch 47/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.6732 - accuracy: 0.4384\n","Epoch 47: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6753 - accuracy: 0.4381 - val_loss: 1.4983 - val_accuracy: 0.4704\n","Epoch 48/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.7568 - accuracy: 0.4110\n","Epoch 48: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.7435 - accuracy: 0.4131 - val_loss: 2.0229 - val_accuracy: 0.3003\n","Epoch 49/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.5808 - accuracy: 0.4464\n","Epoch 49: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5825 - accuracy: 0.4481 - val_loss: 1.7999 - val_accuracy: 0.2614\n","Epoch 50/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.5876 - accuracy: 0.4331\n","Epoch 50: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5833 - accuracy: 0.4343 - val_loss: 2.1081 - val_accuracy: 0.4509\n","Epoch 51/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.7270 - accuracy: 0.4125\n","Epoch 51: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.7408 - accuracy: 0.4152 - val_loss: 1.6589 - val_accuracy: 0.4286\n","Epoch 52/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5251 - accuracy: 0.4514\n","Epoch 52: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5282 - accuracy: 0.4464 - val_loss: 1.9071 - val_accuracy: 0.3625\n","Epoch 53/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5955 - accuracy: 0.4134\n","Epoch 53: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.6087 - accuracy: 0.4110 - val_loss: 1.6559 - val_accuracy: 0.3878\n","Epoch 54/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5211 - accuracy: 0.4452\n","Epoch 54: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5211 - accuracy: 0.4452 - val_loss: 1.7833 - val_accuracy: 0.3362\n","Epoch 55/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5543 - accuracy: 0.4290\n","Epoch 55: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5894 - accuracy: 0.4285 - val_loss: 1.9513 - val_accuracy: 0.4402\n","Epoch 56/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.6171 - accuracy: 0.4197\n","Epoch 56: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6044 - accuracy: 0.4181 - val_loss: 1.5173 - val_accuracy: 0.4500\n","Epoch 57/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.6387 - accuracy: 0.4512\n","Epoch 57: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.6317 - accuracy: 0.4489 - val_loss: 1.5078 - val_accuracy: 0.4519\n","Epoch 58/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.6557 - accuracy: 0.4291\n","Epoch 58: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6357 - accuracy: 0.4368 - val_loss: 1.7438 - val_accuracy: 0.4606\n","Epoch 59/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5295 - accuracy: 0.4569\n","Epoch 59: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5166 - accuracy: 0.4569 - val_loss: 1.5809 - val_accuracy: 0.3741\n","Epoch 60/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.5520 - accuracy: 0.4344\n","Epoch 60: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5486 - accuracy: 0.4385 - val_loss: 1.4067 - val_accuracy: 0.4393\n","Epoch 61/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.6418 - accuracy: 0.4362\n","Epoch 61: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.6429 - accuracy: 0.4339 - val_loss: 1.9510 - val_accuracy: 0.3800\n","Epoch 62/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.6039 - accuracy: 0.4510\n","Epoch 62: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.6065 - accuracy: 0.4473 - val_loss: 1.3896 - val_accuracy: 0.4995\n","Epoch 63/100\n","69/75 [==========================>...] - ETA: 0s - loss: 1.5377 - accuracy: 0.4543\n","Epoch 63: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5264 - accuracy: 0.4577 - val_loss: 1.5256 - val_accuracy: 0.4597\n","Epoch 64/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.5588 - accuracy: 0.4254\n","Epoch 64: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.5410 - accuracy: 0.4335 - val_loss: 1.8953 - val_accuracy: 0.3440\n","Epoch 65/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5851 - accuracy: 0.4265\n","Epoch 65: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 10ms/step - loss: 1.5810 - accuracy: 0.4273 - val_loss: 1.3705 - val_accuracy: 0.4451\n","Epoch 66/100\n","75/75 [==============================] - ETA: 0s - loss: 1.7452 - accuracy: 0.4243\n","Epoch 66: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.7452 - accuracy: 0.4243 - val_loss: 2.3741 - val_accuracy: 0.3683\n","Epoch 67/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.6296 - accuracy: 0.4311\n","Epoch 67: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6223 - accuracy: 0.4302 - val_loss: 1.4392 - val_accuracy: 0.4393\n","Epoch 68/100\n","62/75 [=======================>......] - ETA: 0s - loss: 1.5974 - accuracy: 0.4315\n","Epoch 68: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5676 - accuracy: 0.4360 - val_loss: 1.6360 - val_accuracy: 0.4587\n","Epoch 69/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.6150 - accuracy: 0.4307\n","Epoch 69: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6214 - accuracy: 0.4289 - val_loss: 1.9330 - val_accuracy: 0.4509\n","Epoch 70/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.6229 - accuracy: 0.4256\n","Epoch 70: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6197 - accuracy: 0.4189 - val_loss: 1.7345 - val_accuracy: 0.3946\n","Epoch 71/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.6903 - accuracy: 0.4454\n","Epoch 71: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.6885 - accuracy: 0.4456 - val_loss: 1.9359 - val_accuracy: 0.4441\n","Epoch 72/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.8866 - accuracy: 0.4122\n","Epoch 72: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.8685 - accuracy: 0.4135 - val_loss: 1.6193 - val_accuracy: 0.4684\n","Epoch 73/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.5356 - accuracy: 0.4274\n","Epoch 73: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5391 - accuracy: 0.4231 - val_loss: 1.6117 - val_accuracy: 0.4742\n","Epoch 74/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.6954 - accuracy: 0.4404\n","Epoch 74: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6895 - accuracy: 0.4381 - val_loss: 1.4174 - val_accuracy: 0.3586\n","Epoch 75/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.5724 - accuracy: 0.4263\n","Epoch 75: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5883 - accuracy: 0.4310 - val_loss: 1.8106 - val_accuracy: 0.3984\n","Epoch 76/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.5534 - accuracy: 0.4541\n","Epoch 76: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5498 - accuracy: 0.4444 - val_loss: 1.7830 - val_accuracy: 0.3226\n","Epoch 77/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.5082 - accuracy: 0.4322\n","Epoch 77: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5048 - accuracy: 0.4335 - val_loss: 1.4780 - val_accuracy: 0.4295\n","Epoch 78/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.6337 - accuracy: 0.4191\n","Epoch 78: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6294 - accuracy: 0.4189 - val_loss: 1.5842 - val_accuracy: 0.4431\n","Epoch 79/100\n","75/75 [==============================] - ETA: 0s - loss: 1.5196 - accuracy: 0.4264\n","Epoch 79: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.5196 - accuracy: 0.4264 - val_loss: 1.5409 - val_accuracy: 0.4684\n","Epoch 80/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.5401 - accuracy: 0.4462\n","Epoch 80: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 5ms/step - loss: 1.5425 - accuracy: 0.4414 - val_loss: 1.4419 - val_accuracy: 0.4208\n","Epoch 81/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5739 - accuracy: 0.4316\n","Epoch 81: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5741 - accuracy: 0.4306 - val_loss: 1.4856 - val_accuracy: 0.3819\n","Epoch 82/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.4799 - accuracy: 0.4546\n","Epoch 82: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4742 - accuracy: 0.4556 - val_loss: 1.5054 - val_accuracy: 0.4179\n","46/46 [==============================] - 0s 3ms/step\n","0.48095238095238096\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["73/75 [============================>.] - ETA: 0s - loss: 3.4488 - accuracy: 0.2658\n","Epoch 1: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 2s 12ms/step - loss: 3.4102 - accuracy: 0.2705 - val_loss: 2.0801 - val_accuracy: 0.3294\n","Epoch 2/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.8945 - accuracy: 0.3982\n","Epoch 2: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.8957 - accuracy: 0.3972 - val_loss: 1.7721 - val_accuracy: 0.3858\n","Epoch 3/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.7140 - accuracy: 0.4039\n","Epoch 3: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.7106 - accuracy: 0.4014 - val_loss: 2.0183 - val_accuracy: 0.3197\n","Epoch 4/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.7344 - accuracy: 0.4302\n","Epoch 4: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.7355 - accuracy: 0.4260 - val_loss: 1.9384 - val_accuracy: 0.4383\n","Epoch 5/100\n","72/75 [===========================>..] - ETA: 0s - loss: 1.6354 - accuracy: 0.4366\n","Epoch 5: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.6428 - accuracy: 0.4348 - val_loss: 1.7704 - val_accuracy: 0.4772\n","Epoch 6/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.5777 - accuracy: 0.4418\n","Epoch 6: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 7ms/step - loss: 1.5786 - accuracy: 0.4398 - val_loss: 1.7447 - val_accuracy: 0.2983\n","Epoch 7/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5014 - accuracy: 0.4324\n","Epoch 7: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5027 - accuracy: 0.4327 - val_loss: 1.9280 - val_accuracy: 0.4529\n","Epoch 8/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4145 - accuracy: 0.4473\n","Epoch 8: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4187 - accuracy: 0.4481 - val_loss: 1.3977 - val_accuracy: 0.4655\n","Epoch 9/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.4874 - accuracy: 0.4251\n","Epoch 9: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4743 - accuracy: 0.4293 - val_loss: 1.3874 - val_accuracy: 0.4315\n","Epoch 10/100\n","63/75 [========================>.....] - ETA: 0s - loss: 1.5282 - accuracy: 0.4355\n","Epoch 10: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5204 - accuracy: 0.4335 - val_loss: 1.4108 - val_accuracy: 0.3907\n","Epoch 11/100\n","71/75 [===========================>..] - ETA: 0s - loss: 1.4975 - accuracy: 0.4278\n","Epoch 11: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.4936 - accuracy: 0.4264 - val_loss: 1.9241 - val_accuracy: 0.4694\n","Epoch 12/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4425 - accuracy: 0.4346\n","Epoch 12: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4424 - accuracy: 0.4368 - val_loss: 1.4539 - val_accuracy: 0.4237\n","Epoch 13/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4817 - accuracy: 0.4409\n","Epoch 13: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4625 - accuracy: 0.4464 - val_loss: 1.7228 - val_accuracy: 0.3042\n","Epoch 14/100\n","64/75 [========================>.....] - ETA: 0s - loss: 1.4507 - accuracy: 0.4546\n","Epoch 14: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4673 - accuracy: 0.4481 - val_loss: 1.5272 - val_accuracy: 0.4354\n","Epoch 15/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.4343 - accuracy: 0.4447\n","Epoch 15: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.4378 - accuracy: 0.4427 - val_loss: 1.4085 - val_accuracy: 0.4344\n","Epoch 16/100\n","67/75 [=========================>....] - ETA: 0s - loss: 1.4130 - accuracy: 0.4529\n","Epoch 16: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4113 - accuracy: 0.4544 - val_loss: 1.7723 - val_accuracy: 0.3625\n","Epoch 17/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.5036 - accuracy: 0.4304\n","Epoch 17: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 9ms/step - loss: 1.4975 - accuracy: 0.4348 - val_loss: 1.4594 - val_accuracy: 0.4189\n","Epoch 18/100\n","73/75 [============================>.] - ETA: 0s - loss: 1.4818 - accuracy: 0.4396\n","Epoch 18: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 8ms/step - loss: 1.4871 - accuracy: 0.4389 - val_loss: 1.4005 - val_accuracy: 0.4130\n","Epoch 19/100\n","68/75 [==========================>...] - ETA: 0s - loss: 1.5801 - accuracy: 0.4210\n","Epoch 19: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 9ms/step - loss: 1.5694 - accuracy: 0.4193 - val_loss: 1.4398 - val_accuracy: 0.4665\n","Epoch 20/100\n","70/75 [===========================>..] - ETA: 0s - loss: 1.5218 - accuracy: 0.4442\n","Epoch 20: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 11ms/step - loss: 1.5093 - accuracy: 0.4460 - val_loss: 1.3965 - val_accuracy: 0.4014\n","Epoch 21/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.4920 - accuracy: 0.4490\n","Epoch 21: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.4793 - accuracy: 0.4456 - val_loss: 1.4746 - val_accuracy: 0.4431\n","Epoch 22/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.4248 - accuracy: 0.4413\n","Epoch 22: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.4269 - accuracy: 0.4377 - val_loss: 1.3954 - val_accuracy: 0.4227\n","Epoch 23/100\n","74/75 [============================>.] - ETA: 0s - loss: 1.5969 - accuracy: 0.4329\n","Epoch 23: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 1s 7ms/step - loss: 1.5997 - accuracy: 0.4310 - val_loss: 1.3812 - val_accuracy: 0.4354\n","Epoch 24/100\n","66/75 [=========================>....] - ETA: 0s - loss: 1.5041 - accuracy: 0.4261\n","Epoch 24: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5078 - accuracy: 0.4293 - val_loss: 2.2227 - val_accuracy: 0.4704\n","Epoch 25/100\n","65/75 [=========================>....] - ETA: 0s - loss: 1.5216 - accuracy: 0.4433\n","Epoch 25: val_accuracy did not improve from 0.51020\n","75/75 [==============================] - 0s 6ms/step - loss: 1.5180 - accuracy: 0.4364 - val_loss: 1.4226 - val_accuracy: 0.3926\n","46/46 [==============================] - 0s 3ms/step\n","0.47619047619047616\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - 1s 4ms/step - loss: 1.3477 - accuracy: 0.5122\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["23/25 [==========================>...] - ETA: 0s - loss: 3.4376 - accuracy: 0.1970\n","Epoch 1: val_accuracy improved from -inf to 0.38690, saving model to winered_tnn2.h5\n","25/25 [==============================] - 2s 23ms/step - loss: 3.3806 - accuracy: 0.2056 - val_loss: 2.5294 - val_accuracy: 0.3869\n","Epoch 2/100\n","13/25 [==============>...............] - ETA: 0s - loss: 2.6503 - accuracy: 0.3293\n","Epoch 2: val_accuracy improved from 0.38690 to 0.39286, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 8ms/step - loss: 2.4125 - accuracy: 0.3487 - val_loss: 2.1116 - val_accuracy: 0.3929\n","Epoch 3/100\n","13/25 [==============>...............] - ETA: 0s - loss: 2.0865 - accuracy: 0.3798\n","Epoch 3: val_accuracy improved from 0.39286 to 0.45238, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 7ms/step - loss: 1.9507 - accuracy: 0.4010 - val_loss: 1.7343 - val_accuracy: 0.4524\n","Epoch 4/100\n","12/25 [=============>................] - ETA: 0s - loss: 1.8353 - accuracy: 0.4245\n","Epoch 4: val_accuracy did not improve from 0.45238\n","25/25 [==============================] - 0s 6ms/step - loss: 1.7412 - accuracy: 0.4521 - val_loss: 1.5706 - val_accuracy: 0.4405\n","Epoch 5/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.5542 - accuracy: 0.4973\n","Epoch 5: val_accuracy improved from 0.45238 to 0.45833, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 8ms/step - loss: 1.5642 - accuracy: 0.4930 - val_loss: 1.5761 - val_accuracy: 0.4583\n","Epoch 6/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.5508 - accuracy: 0.4792\n","Epoch 6: val_accuracy improved from 0.45833 to 0.47917, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 9ms/step - loss: 1.5437 - accuracy: 0.4828 - val_loss: 1.7316 - val_accuracy: 0.4792\n","Epoch 7/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.5889 - accuracy: 0.4922\n","Epoch 7: val_accuracy did not improve from 0.47917\n","25/25 [==============================] - 0s 8ms/step - loss: 1.5997 - accuracy: 0.4866 - val_loss: 1.5331 - val_accuracy: 0.4018\n","Epoch 8/100\n","25/25 [==============================] - ETA: 0s - loss: 1.5336 - accuracy: 0.4687\n","Epoch 8: val_accuracy did not improve from 0.47917\n","25/25 [==============================] - 0s 8ms/step - loss: 1.5336 - accuracy: 0.4687 - val_loss: 1.4610 - val_accuracy: 0.4732\n","Epoch 9/100\n","25/25 [==============================] - ETA: 0s - loss: 1.5010 - accuracy: 0.4955\n","Epoch 9: val_accuracy did not improve from 0.47917\n","25/25 [==============================] - 0s 9ms/step - loss: 1.5010 - accuracy: 0.4955 - val_loss: 1.5072 - val_accuracy: 0.4286\n","Epoch 10/100\n","25/25 [==============================] - ETA: 0s - loss: 1.4920 - accuracy: 0.4943\n","Epoch 10: val_accuracy did not improve from 0.47917\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4920 - accuracy: 0.4943 - val_loss: 1.5221 - val_accuracy: 0.4315\n","Epoch 11/100\n","25/25 [==============================] - ETA: 0s - loss: 1.4733 - accuracy: 0.5109\n","Epoch 11: val_accuracy did not improve from 0.47917\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4733 - accuracy: 0.5109 - val_loss: 1.4731 - val_accuracy: 0.4702\n","Epoch 12/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.4488 - accuracy: 0.4987\n","Epoch 12: val_accuracy did not improve from 0.47917\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4425 - accuracy: 0.5006 - val_loss: 1.4947 - val_accuracy: 0.3929\n","Epoch 13/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3974 - accuracy: 0.5275\n","Epoch 13: val_accuracy did not improve from 0.47917\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3974 - accuracy: 0.5275 - val_loss: 1.4463 - val_accuracy: 0.4613\n","Epoch 14/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.4470 - accuracy: 0.4701\n","Epoch 14: val_accuracy did not improve from 0.47917\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4445 - accuracy: 0.4687 - val_loss: 1.7241 - val_accuracy: 0.3542\n","Epoch 15/100\n","12/25 [=============>................] - ETA: 0s - loss: 1.4531 - accuracy: 0.5391\n","Epoch 15: val_accuracy did not improve from 0.47917\n","25/25 [==============================] - 0s 6ms/step - loss: 1.4171 - accuracy: 0.5236 - val_loss: 1.3341 - val_accuracy: 0.4792\n","Epoch 16/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.4512 - accuracy: 0.4957\n","Epoch 16: val_accuracy improved from 0.47917 to 0.49702, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4155 - accuracy: 0.4943 - val_loss: 1.2098 - val_accuracy: 0.4970\n","Epoch 17/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2642 - accuracy: 0.4952\n","Epoch 17: val_accuracy did not improve from 0.49702\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3422 - accuracy: 0.4866 - val_loss: 1.7530 - val_accuracy: 0.4940\n","Epoch 18/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.1880 - accuracy: 0.5333\n","Epoch 18: val_accuracy did not improve from 0.49702\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4570 - accuracy: 0.5121 - val_loss: 1.8112 - val_accuracy: 0.4881\n","Epoch 19/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.5229 - accuracy: 0.4880\n","Epoch 19: val_accuracy improved from 0.49702 to 0.50595, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 7ms/step - loss: 1.5083 - accuracy: 0.4828 - val_loss: 1.3604 - val_accuracy: 0.5060\n","Epoch 20/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.2737 - accuracy: 0.5188\n","Epoch 20: val_accuracy improved from 0.50595 to 0.50893, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3804 - accuracy: 0.4879 - val_loss: 1.2724 - val_accuracy: 0.5089\n","Epoch 21/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2629 - accuracy: 0.5208\n","Epoch 21: val_accuracy did not improve from 0.50893\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2603 - accuracy: 0.5236 - val_loss: 1.9773 - val_accuracy: 0.4524\n","Epoch 22/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3432 - accuracy: 0.5326\n","Epoch 22: val_accuracy improved from 0.50893 to 0.51786, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3432 - accuracy: 0.5326 - val_loss: 1.4284 - val_accuracy: 0.5179\n","Epoch 23/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3009 - accuracy: 0.5390\n","Epoch 23: val_accuracy did not improve from 0.51786\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3009 - accuracy: 0.5390 - val_loss: 1.6726 - val_accuracy: 0.4970\n","Epoch 24/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.4230 - accuracy: 0.5256\n","Epoch 24: val_accuracy improved from 0.51786 to 0.55060, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 10ms/step - loss: 1.4549 - accuracy: 0.5185 - val_loss: 1.5140 - val_accuracy: 0.5506\n","Epoch 25/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.5367 - accuracy: 0.4819\n","Epoch 25: val_accuracy did not improve from 0.55060\n","25/25 [==============================] - 0s 10ms/step - loss: 1.4695 - accuracy: 0.4968 - val_loss: 1.2375 - val_accuracy: 0.5327\n","Epoch 26/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3555 - accuracy: 0.4891\n","Epoch 26: val_accuracy did not improve from 0.55060\n","25/25 [==============================] - 0s 11ms/step - loss: 1.3555 - accuracy: 0.4891 - val_loss: 1.3323 - val_accuracy: 0.5327\n","Epoch 27/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.3383 - accuracy: 0.5181\n","Epoch 27: val_accuracy did not improve from 0.55060\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3600 - accuracy: 0.5160 - val_loss: 1.4540 - val_accuracy: 0.4643\n","Epoch 28/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2427 - accuracy: 0.5096\n","Epoch 28: val_accuracy did not improve from 0.55060\n","25/25 [==============================] - 0s 11ms/step - loss: 1.2427 - accuracy: 0.5096 - val_loss: 1.3594 - val_accuracy: 0.4375\n","Epoch 29/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.5032 - accuracy: 0.5247\n","Epoch 29: val_accuracy did not improve from 0.55060\n","25/25 [==============================] - 0s 9ms/step - loss: 1.4756 - accuracy: 0.5147 - val_loss: 1.5547 - val_accuracy: 0.4940\n","Epoch 30/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.3667 - accuracy: 0.5219\n","Epoch 30: val_accuracy did not improve from 0.55060\n","25/25 [==============================] - 0s 9ms/step - loss: 1.4126 - accuracy: 0.5109 - val_loss: 1.6826 - val_accuracy: 0.3988\n","Epoch 31/100\n","17/25 [===================>..........] - ETA: 0s - loss: 1.2633 - accuracy: 0.5441\n","Epoch 31: val_accuracy did not improve from 0.55060\n","25/25 [==============================] - 0s 11ms/step - loss: 1.2625 - accuracy: 0.5338 - val_loss: 1.5333 - val_accuracy: 0.4732\n","Epoch 32/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.3716 - accuracy: 0.5355\n","Epoch 32: val_accuracy did not improve from 0.55060\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3575 - accuracy: 0.5351 - val_loss: 1.2802 - val_accuracy: 0.5149\n","Epoch 33/100\n","17/25 [===================>..........] - ETA: 0s - loss: 1.2606 - accuracy: 0.5533\n","Epoch 33: val_accuracy did not improve from 0.55060\n","25/25 [==============================] - 0s 11ms/step - loss: 1.2435 - accuracy: 0.5390 - val_loss: 1.4865 - val_accuracy: 0.4613\n","Epoch 34/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.4826 - accuracy: 0.4931\n","Epoch 34: val_accuracy improved from 0.55060 to 0.55357, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 11ms/step - loss: 1.4394 - accuracy: 0.5006 - val_loss: 1.2732 - val_accuracy: 0.5536\n","Epoch 35/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.4021 - accuracy: 0.5214\n","Epoch 35: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3834 - accuracy: 0.5121 - val_loss: 1.4673 - val_accuracy: 0.4911\n","Epoch 36/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.2183 - accuracy: 0.5682\n","Epoch 36: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2342 - accuracy: 0.5709 - val_loss: 1.3429 - val_accuracy: 0.5357\n","Epoch 37/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.3279 - accuracy: 0.5117\n","Epoch 37: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2703 - accuracy: 0.5287 - val_loss: 1.2932 - val_accuracy: 0.5476\n","Epoch 38/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.2171 - accuracy: 0.5506\n","Epoch 38: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2174 - accuracy: 0.5530 - val_loss: 1.6680 - val_accuracy: 0.4732\n","Epoch 39/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.2833 - accuracy: 0.5757\n","Epoch 39: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2851 - accuracy: 0.5594 - val_loss: 1.8454 - val_accuracy: 0.4673\n","Epoch 40/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3250 - accuracy: 0.5168\n","Epoch 40: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3126 - accuracy: 0.5262 - val_loss: 1.5195 - val_accuracy: 0.4911\n","Epoch 41/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.4557 - accuracy: 0.4888\n","Epoch 41: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3788 - accuracy: 0.4955 - val_loss: 1.3561 - val_accuracy: 0.5208\n","Epoch 42/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.1291 - accuracy: 0.5647\n","Epoch 42: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 6ms/step - loss: 1.1864 - accuracy: 0.5466 - val_loss: 1.2007 - val_accuracy: 0.5030\n","Epoch 43/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2220 - accuracy: 0.5581\n","Epoch 43: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2220 - accuracy: 0.5581 - val_loss: 1.3413 - val_accuracy: 0.5149\n","Epoch 44/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2559 - accuracy: 0.5377\n","Epoch 44: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2559 - accuracy: 0.5377 - val_loss: 1.3601 - val_accuracy: 0.4583\n","Epoch 45/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3939 - accuracy: 0.5377\n","Epoch 45: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3939 - accuracy: 0.5377 - val_loss: 1.5060 - val_accuracy: 0.4821\n","Epoch 46/100\n","12/25 [=============>................] - ETA: 0s - loss: 1.2992 - accuracy: 0.5495\n","Epoch 46: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2822 - accuracy: 0.5543 - val_loss: 1.6264 - val_accuracy: 0.5387\n","Epoch 47/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.3205 - accuracy: 0.5580\n","Epoch 47: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3807 - accuracy: 0.5172 - val_loss: 1.3068 - val_accuracy: 0.5089\n","Epoch 48/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2124 - accuracy: 0.5492\n","Epoch 48: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2124 - accuracy: 0.5492 - val_loss: 1.2303 - val_accuracy: 0.5268\n","Epoch 49/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.1511 - accuracy: 0.5742\n","Epoch 49: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.1531 - accuracy: 0.5747 - val_loss: 1.6990 - val_accuracy: 0.4435\n","Epoch 50/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2169 - accuracy: 0.5543\n","Epoch 50: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2169 - accuracy: 0.5543 - val_loss: 1.3732 - val_accuracy: 0.4435\n","Epoch 51/100\n","25/25 [==============================] - ETA: 0s - loss: 1.1691 - accuracy: 0.5517\n","Epoch 51: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 8ms/step - loss: 1.1691 - accuracy: 0.5517 - val_loss: 1.4264 - val_accuracy: 0.4940\n","Epoch 52/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.2393 - accuracy: 0.5250\n","Epoch 52: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2392 - accuracy: 0.5287 - val_loss: 1.6147 - val_accuracy: 0.4940\n","Epoch 53/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2891 - accuracy: 0.5234\n","Epoch 53: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2784 - accuracy: 0.5249 - val_loss: 1.2417 - val_accuracy: 0.5179\n","Epoch 54/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2700 - accuracy: 0.5326\n","Epoch 54: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2700 - accuracy: 0.5326 - val_loss: 2.1490 - val_accuracy: 0.4554\n","15/15 [==============================] - 0s 3ms/step\n","0.5479166666666667\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["14/25 [===============>..............] - ETA: 0s - loss: 4.9425 - accuracy: 0.2165 \n","Epoch 1: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 1s 22ms/step - loss: 4.2139 - accuracy: 0.2580 - val_loss: 2.2101 - val_accuracy: 0.4345\n","Epoch 2/100\n","23/25 [==========================>...] - ETA: 0s - loss: 2.0997 - accuracy: 0.4742\n","Epoch 2: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 2.0836 - accuracy: 0.4751 - val_loss: 1.6890 - val_accuracy: 0.4970\n","Epoch 3/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.6051 - accuracy: 0.4821\n","Epoch 3: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 6ms/step - loss: 1.6860 - accuracy: 0.4674 - val_loss: 1.6866 - val_accuracy: 0.4851\n","Epoch 4/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.4960 - accuracy: 0.5201\n","Epoch 4: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 6ms/step - loss: 1.5867 - accuracy: 0.4891 - val_loss: 1.7186 - val_accuracy: 0.4077\n","Epoch 5/100\n","12/25 [=============>................] - ETA: 0s - loss: 1.5781 - accuracy: 0.4505\n","Epoch 5: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 6ms/step - loss: 1.5466 - accuracy: 0.4687 - val_loss: 1.6071 - val_accuracy: 0.4494\n","Epoch 6/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.5606 - accuracy: 0.4777\n","Epoch 6: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.5993 - accuracy: 0.4725 - val_loss: 1.5897 - val_accuracy: 0.4702\n","Epoch 7/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.4850 - accuracy: 0.4821\n","Epoch 7: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 8ms/step - loss: 1.5195 - accuracy: 0.5057 - val_loss: 1.5066 - val_accuracy: 0.5238\n","Epoch 8/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.4703 - accuracy: 0.5260\n","Epoch 8: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4719 - accuracy: 0.5236 - val_loss: 1.4992 - val_accuracy: 0.4702\n","Epoch 9/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3761 - accuracy: 0.4994\n","Epoch 9: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3761 - accuracy: 0.4994 - val_loss: 1.4637 - val_accuracy: 0.4821\n","Epoch 10/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.4242 - accuracy: 0.4766\n","Epoch 10: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4099 - accuracy: 0.4789 - val_loss: 1.5576 - val_accuracy: 0.4524\n","Epoch 11/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.5096 - accuracy: 0.4742\n","Epoch 11: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 9ms/step - loss: 1.4956 - accuracy: 0.4802 - val_loss: 1.2168 - val_accuracy: 0.5327\n","Epoch 12/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2735 - accuracy: 0.5082\n","Epoch 12: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2794 - accuracy: 0.5109 - val_loss: 1.2405 - val_accuracy: 0.5030\n","Epoch 13/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3284 - accuracy: 0.4955\n","Epoch 13: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3284 - accuracy: 0.4955 - val_loss: 1.3198 - val_accuracy: 0.4524\n","Epoch 14/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3117 - accuracy: 0.5014\n","Epoch 14: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3172 - accuracy: 0.5006 - val_loss: 1.2448 - val_accuracy: 0.5238\n","Epoch 15/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2647 - accuracy: 0.5195\n","Epoch 15: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2574 - accuracy: 0.5223 - val_loss: 1.3501 - val_accuracy: 0.5238\n","Epoch 16/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3658 - accuracy: 0.4880\n","Epoch 16: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3085 - accuracy: 0.4994 - val_loss: 1.3845 - val_accuracy: 0.4375\n","Epoch 17/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2590 - accuracy: 0.5091\n","Epoch 17: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2638 - accuracy: 0.5070 - val_loss: 1.3397 - val_accuracy: 0.4911\n","Epoch 18/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.4125 - accuracy: 0.4702\n","Epoch 18: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3916 - accuracy: 0.4840 - val_loss: 1.2154 - val_accuracy: 0.5268\n","Epoch 19/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2878 - accuracy: 0.4543\n","Epoch 19: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2977 - accuracy: 0.5032 - val_loss: 1.6719 - val_accuracy: 0.3839\n","Epoch 20/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.1784 - accuracy: 0.5721\n","Epoch 20: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2430 - accuracy: 0.5160 - val_loss: 1.3136 - val_accuracy: 0.5417\n","Epoch 21/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3937 - accuracy: 0.4736\n","Epoch 21: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3761 - accuracy: 0.4674 - val_loss: 1.2427 - val_accuracy: 0.5476\n","Epoch 22/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3395 - accuracy: 0.4930\n","Epoch 22: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3395 - accuracy: 0.4930 - val_loss: 1.1663 - val_accuracy: 0.4643\n","Epoch 23/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2468 - accuracy: 0.4853\n","Epoch 23: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2468 - accuracy: 0.4853 - val_loss: 1.3232 - val_accuracy: 0.4435\n","Epoch 24/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.4141 - accuracy: 0.4948\n","Epoch 24: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4170 - accuracy: 0.4943 - val_loss: 1.2445 - val_accuracy: 0.5268\n","Epoch 25/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2172 - accuracy: 0.5198\n","Epoch 25: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2172 - accuracy: 0.5198 - val_loss: 1.3175 - val_accuracy: 0.4315\n","Epoch 26/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2504 - accuracy: 0.5198\n","Epoch 26: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2504 - accuracy: 0.5198 - val_loss: 1.3258 - val_accuracy: 0.5179\n","Epoch 27/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.2086 - accuracy: 0.5312\n","Epoch 27: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 10ms/step - loss: 1.1959 - accuracy: 0.5466 - val_loss: 1.3318 - val_accuracy: 0.5238\n","Epoch 28/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.1755 - accuracy: 0.5208\n","Epoch 28: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2889 - accuracy: 0.5121 - val_loss: 1.3056 - val_accuracy: 0.4792\n","Epoch 29/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3219 - accuracy: 0.4981\n","Epoch 29: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 12ms/step - loss: 1.3219 - accuracy: 0.4981 - val_loss: 1.8141 - val_accuracy: 0.3929\n","Epoch 30/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.3177 - accuracy: 0.5230\n","Epoch 30: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2975 - accuracy: 0.5160 - val_loss: 1.3067 - val_accuracy: 0.4345\n","Epoch 31/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.3437 - accuracy: 0.5016\n","Epoch 31: val_accuracy did not improve from 0.55357\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3267 - accuracy: 0.4955 - val_loss: 1.3085 - val_accuracy: 0.4940\n","Epoch 32/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.4387 - accuracy: 0.5013\n","Epoch 32: val_accuracy improved from 0.55357 to 0.56548, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 12ms/step - loss: 1.4320 - accuracy: 0.5006 - val_loss: 1.1368 - val_accuracy: 0.5655\n","Epoch 33/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2371 - accuracy: 0.5443\n","Epoch 33: val_accuracy did not improve from 0.56548\n","25/25 [==============================] - 0s 11ms/step - loss: 1.2329 - accuracy: 0.5466 - val_loss: 1.3028 - val_accuracy: 0.5030\n","Epoch 34/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.2991 - accuracy: 0.5134\n","Epoch 34: val_accuracy did not improve from 0.56548\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3318 - accuracy: 0.4955 - val_loss: 1.3326 - val_accuracy: 0.5625\n","Epoch 35/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.3183 - accuracy: 0.5078\n","Epoch 35: val_accuracy improved from 0.56548 to 0.59226, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2798 - accuracy: 0.5109 - val_loss: 1.3989 - val_accuracy: 0.5923\n","Epoch 36/100\n","17/25 [===================>..........] - ETA: 0s - loss: 1.2258 - accuracy: 0.5460\n","Epoch 36: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2148 - accuracy: 0.5377 - val_loss: 1.3042 - val_accuracy: 0.4911\n","Epoch 37/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.1894 - accuracy: 0.5266\n","Epoch 37: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2023 - accuracy: 0.5249 - val_loss: 1.1739 - val_accuracy: 0.5446\n","Epoch 38/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.1899 - accuracy: 0.5164\n","Epoch 38: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.1946 - accuracy: 0.5198 - val_loss: 1.3421 - val_accuracy: 0.5446\n","Epoch 39/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2677 - accuracy: 0.4959\n","Epoch 39: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 12ms/step - loss: 1.2979 - accuracy: 0.4955 - val_loss: 1.2971 - val_accuracy: 0.5149\n","Epoch 40/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.2690 - accuracy: 0.5312\n","Epoch 40: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2808 - accuracy: 0.5083 - val_loss: 1.5743 - val_accuracy: 0.4673\n","Epoch 41/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.2487 - accuracy: 0.5278\n","Epoch 41: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2352 - accuracy: 0.5262 - val_loss: 1.1679 - val_accuracy: 0.5417\n","Epoch 42/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.2480 - accuracy: 0.4844\n","Epoch 42: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2655 - accuracy: 0.4930 - val_loss: 1.3892 - val_accuracy: 0.5506\n","Epoch 43/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.1916 - accuracy: 0.5326\n","Epoch 43: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.1842 - accuracy: 0.5326 - val_loss: 1.1411 - val_accuracy: 0.5238\n","Epoch 44/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2912 - accuracy: 0.5169\n","Epoch 44: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2891 - accuracy: 0.5160 - val_loss: 1.2749 - val_accuracy: 0.5506\n","Epoch 45/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2787 - accuracy: 0.4981\n","Epoch 45: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2787 - accuracy: 0.4981 - val_loss: 1.2449 - val_accuracy: 0.5268\n","Epoch 46/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.1417 - accuracy: 0.5817\n","Epoch 46: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2870 - accuracy: 0.5338 - val_loss: 1.2720 - val_accuracy: 0.4792\n","Epoch 47/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2582 - accuracy: 0.5380\n","Epoch 47: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2525 - accuracy: 0.5377 - val_loss: 1.5028 - val_accuracy: 0.4702\n","Epoch 48/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2271 - accuracy: 0.5234\n","Epoch 48: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2271 - accuracy: 0.5236 - val_loss: 1.4772 - val_accuracy: 0.5565\n","Epoch 49/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.3171 - accuracy: 0.5057\n","Epoch 49: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3093 - accuracy: 0.5070 - val_loss: 1.4067 - val_accuracy: 0.5417\n","Epoch 50/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3228 - accuracy: 0.4935\n","Epoch 50: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3109 - accuracy: 0.4968 - val_loss: 1.4308 - val_accuracy: 0.5655\n","Epoch 51/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2701 - accuracy: 0.5082\n","Epoch 51: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2729 - accuracy: 0.5109 - val_loss: 1.3362 - val_accuracy: 0.4940\n","Epoch 52/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2740 - accuracy: 0.5469\n","Epoch 52: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2660 - accuracy: 0.5492 - val_loss: 1.2973 - val_accuracy: 0.4107\n","Epoch 53/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3285 - accuracy: 0.5134\n","Epoch 53: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3285 - accuracy: 0.5134 - val_loss: 1.2009 - val_accuracy: 0.4970\n","Epoch 54/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2098 - accuracy: 0.5503\n","Epoch 54: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2197 - accuracy: 0.5402 - val_loss: 1.1688 - val_accuracy: 0.5774\n","Epoch 55/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2454 - accuracy: 0.5568\n","Epoch 55: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2454 - accuracy: 0.5568 - val_loss: 1.2553 - val_accuracy: 0.4792\n","15/15 [==============================] - 0s 3ms/step\n","0.51875\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["25/25 [==============================] - ETA: 0s - loss: 2.6208 - accuracy: 0.2644\n","Epoch 1: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 1s 21ms/step - loss: 2.6208 - accuracy: 0.2644 - val_loss: 1.8071 - val_accuracy: 0.4167\n","Epoch 2/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.8383 - accuracy: 0.4519\n","Epoch 2: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.7481 - accuracy: 0.4457 - val_loss: 1.5844 - val_accuracy: 0.4256\n","Epoch 3/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.6555 - accuracy: 0.4554\n","Epoch 3: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.7032 - accuracy: 0.4547 - val_loss: 1.6243 - val_accuracy: 0.4702\n","Epoch 4/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.5884 - accuracy: 0.4760\n","Epoch 4: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.5242 - accuracy: 0.5172 - val_loss: 1.5918 - val_accuracy: 0.5060\n","Epoch 5/100\n","12/25 [=============>................] - ETA: 0s - loss: 1.6448 - accuracy: 0.4635\n","Epoch 5: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.5270 - accuracy: 0.5032 - val_loss: 1.5488 - val_accuracy: 0.4345\n","Epoch 6/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3826 - accuracy: 0.4808\n","Epoch 6: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4925 - accuracy: 0.4840 - val_loss: 1.4657 - val_accuracy: 0.3839\n","Epoch 7/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.4087 - accuracy: 0.4856\n","Epoch 7: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.4424 - accuracy: 0.4904 - val_loss: 1.3849 - val_accuracy: 0.4940\n","Epoch 8/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.6247 - accuracy: 0.4442\n","Epoch 8: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.5651 - accuracy: 0.4994 - val_loss: 1.5812 - val_accuracy: 0.4821\n","Epoch 9/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.2786 - accuracy: 0.5915\n","Epoch 9: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4250 - accuracy: 0.5517 - val_loss: 1.5866 - val_accuracy: 0.4762\n","Epoch 10/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3380 - accuracy: 0.5273\n","Epoch 10: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3342 - accuracy: 0.5275 - val_loss: 1.2505 - val_accuracy: 0.4673\n","Epoch 11/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3735 - accuracy: 0.4688\n","Epoch 11: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3132 - accuracy: 0.5096 - val_loss: 1.2959 - val_accuracy: 0.5089\n","Epoch 12/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2913 - accuracy: 0.5136\n","Epoch 12: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2990 - accuracy: 0.5134 - val_loss: 1.2529 - val_accuracy: 0.5536\n","Epoch 13/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2659 - accuracy: 0.5083\n","Epoch 13: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2659 - accuracy: 0.5083 - val_loss: 1.2508 - val_accuracy: 0.4940\n","Epoch 14/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3409 - accuracy: 0.5249\n","Epoch 14: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3409 - accuracy: 0.5249 - val_loss: 1.2449 - val_accuracy: 0.5000\n","Epoch 15/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3339 - accuracy: 0.5072\n","Epoch 15: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3224 - accuracy: 0.5172 - val_loss: 1.8166 - val_accuracy: 0.4107\n","Epoch 16/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.2983 - accuracy: 0.5402\n","Epoch 16: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3432 - accuracy: 0.5096 - val_loss: 1.3037 - val_accuracy: 0.5089\n","Epoch 17/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2961 - accuracy: 0.4815\n","Epoch 17: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2961 - accuracy: 0.4815 - val_loss: 1.6308 - val_accuracy: 0.4762\n","Epoch 18/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3400 - accuracy: 0.5024\n","Epoch 18: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3213 - accuracy: 0.5109 - val_loss: 1.4166 - val_accuracy: 0.4226\n","Epoch 19/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.4334 - accuracy: 0.4777\n","Epoch 19: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3999 - accuracy: 0.5019 - val_loss: 1.4065 - val_accuracy: 0.5119\n","Epoch 20/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3211 - accuracy: 0.4879\n","Epoch 20: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3211 - accuracy: 0.4879 - val_loss: 1.2856 - val_accuracy: 0.5089\n","Epoch 21/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3938 - accuracy: 0.5147\n","Epoch 21: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3938 - accuracy: 0.5147 - val_loss: 1.2764 - val_accuracy: 0.5327\n","Epoch 22/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.4479 - accuracy: 0.4736\n","Epoch 22: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4119 - accuracy: 0.4955 - val_loss: 1.3140 - val_accuracy: 0.5387\n","Epoch 23/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.2816 - accuracy: 0.5417\n","Epoch 23: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2966 - accuracy: 0.5326 - val_loss: 1.2426 - val_accuracy: 0.5417\n","Epoch 24/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.4736 - accuracy: 0.5385\n","Epoch 24: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.5587 - accuracy: 0.4930 - val_loss: 1.4664 - val_accuracy: 0.4821\n","Epoch 25/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.3967 - accuracy: 0.5112\n","Epoch 25: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4320 - accuracy: 0.4917 - val_loss: 1.3030 - val_accuracy: 0.5119\n","Epoch 26/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.4498 - accuracy: 0.5096\n","Epoch 26: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.4400 - accuracy: 0.5032 - val_loss: 1.5279 - val_accuracy: 0.5536\n","Epoch 27/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2790 - accuracy: 0.5240\n","Epoch 27: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3102 - accuracy: 0.5134 - val_loss: 1.6332 - val_accuracy: 0.4464\n","Epoch 28/100\n","12/25 [=============>................] - ETA: 0s - loss: 1.3851 - accuracy: 0.5339\n","Epoch 28: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3616 - accuracy: 0.5185 - val_loss: 1.5627 - val_accuracy: 0.4583\n","Epoch 29/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.2285 - accuracy: 0.5214\n","Epoch 29: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2023 - accuracy: 0.5275 - val_loss: 1.1223 - val_accuracy: 0.5208\n","Epoch 30/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.2650 - accuracy: 0.5219\n","Epoch 30: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2428 - accuracy: 0.5249 - val_loss: 1.2503 - val_accuracy: 0.5208\n","Epoch 31/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3622 - accuracy: 0.5408\n","Epoch 31: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3643 - accuracy: 0.5364 - val_loss: 1.2802 - val_accuracy: 0.4970\n","Epoch 32/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.2862 - accuracy: 0.5284\n","Epoch 32: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3050 - accuracy: 0.5147 - val_loss: 1.3999 - val_accuracy: 0.5298\n","15/15 [==============================] - 0s 3ms/step\n","0.5208333333333334\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["25/25 [==============================] - ETA: 0s - loss: 5.3282 - accuracy: 0.2005\n","Epoch 1: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 1s 22ms/step - loss: 5.3282 - accuracy: 0.2005 - val_loss: 3.8166 - val_accuracy: 0.3304\n","Epoch 2/100\n","15/25 [=================>............] - ETA: 0s - loss: 3.0222 - accuracy: 0.3063\n","Epoch 2: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 2.7597 - accuracy: 0.3614 - val_loss: 2.1846 - val_accuracy: 0.4464\n","Epoch 3/100\n","13/25 [==============>...............] - ETA: 0s - loss: 2.0455 - accuracy: 0.5048\n","Epoch 3: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.9818 - accuracy: 0.5019 - val_loss: 2.0626 - val_accuracy: 0.4345\n","Epoch 4/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.7936 - accuracy: 0.4883\n","Epoch 4: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.7960 - accuracy: 0.4879 - val_loss: 1.6380 - val_accuracy: 0.4732\n","Epoch 5/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.6938 - accuracy: 0.5082\n","Epoch 5: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.6851 - accuracy: 0.5019 - val_loss: 1.8418 - val_accuracy: 0.4613\n","Epoch 6/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.6304 - accuracy: 0.5078\n","Epoch 6: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.6306 - accuracy: 0.5070 - val_loss: 1.4837 - val_accuracy: 0.5000\n","Epoch 7/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.5268 - accuracy: 0.5221\n","Epoch 7: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.5186 - accuracy: 0.5223 - val_loss: 1.4035 - val_accuracy: 0.5387\n","Epoch 8/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.4380 - accuracy: 0.5128\n","Epoch 8: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4533 - accuracy: 0.5172 - val_loss: 1.4993 - val_accuracy: 0.5387\n","Epoch 9/100\n","12/25 [=============>................] - ETA: 0s - loss: 1.4882 - accuracy: 0.5339\n","Epoch 9: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.4549 - accuracy: 0.5211 - val_loss: 1.3848 - val_accuracy: 0.5000\n","Epoch 10/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3650 - accuracy: 0.5144\n","Epoch 10: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3883 - accuracy: 0.5045 - val_loss: 1.5197 - val_accuracy: 0.5089\n","Epoch 11/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3476 - accuracy: 0.5249\n","Epoch 11: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3476 - accuracy: 0.5249 - val_loss: 1.4000 - val_accuracy: 0.4940\n","Epoch 12/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.4262 - accuracy: 0.5072\n","Epoch 12: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.4481 - accuracy: 0.4930 - val_loss: 1.3384 - val_accuracy: 0.4732\n","Epoch 13/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.2937 - accuracy: 0.5491\n","Epoch 13: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3939 - accuracy: 0.5530 - val_loss: 1.3826 - val_accuracy: 0.4762\n","Epoch 14/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2747 - accuracy: 0.5264\n","Epoch 14: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2962 - accuracy: 0.5313 - val_loss: 1.5362 - val_accuracy: 0.5238\n","Epoch 15/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3331 - accuracy: 0.5415\n","Epoch 15: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3331 - accuracy: 0.5415 - val_loss: 1.3606 - val_accuracy: 0.5327\n","Epoch 16/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2861 - accuracy: 0.5577\n","Epoch 16: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3232 - accuracy: 0.5338 - val_loss: 1.2987 - val_accuracy: 0.5268\n","Epoch 17/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3655 - accuracy: 0.4976\n","Epoch 17: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3350 - accuracy: 0.5236 - val_loss: 1.2898 - val_accuracy: 0.5268\n","Epoch 18/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.3158 - accuracy: 0.5335\n","Epoch 18: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3535 - accuracy: 0.5198 - val_loss: 1.4093 - val_accuracy: 0.4940\n","Epoch 19/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3282 - accuracy: 0.5236\n","Epoch 19: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3282 - accuracy: 0.5236 - val_loss: 1.5109 - val_accuracy: 0.4226\n","Epoch 20/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.2616 - accuracy: 0.5297\n","Epoch 20: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3004 - accuracy: 0.5109 - val_loss: 1.2134 - val_accuracy: 0.5804\n","Epoch 21/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.2496 - accuracy: 0.5536\n","Epoch 21: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3533 - accuracy: 0.5121 - val_loss: 1.3275 - val_accuracy: 0.5476\n","Epoch 22/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3335 - accuracy: 0.5313\n","Epoch 22: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3335 - accuracy: 0.5313 - val_loss: 1.3584 - val_accuracy: 0.5804\n","Epoch 23/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2903 - accuracy: 0.5247\n","Epoch 23: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2932 - accuracy: 0.5249 - val_loss: 1.3155 - val_accuracy: 0.4464\n","Epoch 24/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3221 - accuracy: 0.5236\n","Epoch 24: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3221 - accuracy: 0.5236 - val_loss: 1.3103 - val_accuracy: 0.5327\n","Epoch 25/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2193 - accuracy: 0.4832\n","Epoch 25: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2456 - accuracy: 0.5006 - val_loss: 1.4573 - val_accuracy: 0.5565\n","Epoch 26/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.2765 - accuracy: 0.4933\n","Epoch 26: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2537 - accuracy: 0.5109 - val_loss: 1.4041 - val_accuracy: 0.4821\n","Epoch 27/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3846 - accuracy: 0.5156\n","Epoch 27: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3744 - accuracy: 0.5185 - val_loss: 1.2418 - val_accuracy: 0.5446\n","Epoch 28/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2787 - accuracy: 0.5019\n","Epoch 28: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2787 - accuracy: 0.5019 - val_loss: 1.3537 - val_accuracy: 0.5089\n","Epoch 29/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2371 - accuracy: 0.5221\n","Epoch 29: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2311 - accuracy: 0.5262 - val_loss: 1.1891 - val_accuracy: 0.5357\n","Epoch 30/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3127 - accuracy: 0.4760\n","Epoch 30: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2865 - accuracy: 0.4943 - val_loss: 1.4601 - val_accuracy: 0.5089\n","Epoch 31/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3198 - accuracy: 0.5264\n","Epoch 31: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3504 - accuracy: 0.5198 - val_loss: 1.2347 - val_accuracy: 0.5536\n","Epoch 32/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2170 - accuracy: 0.5258\n","Epoch 32: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2099 - accuracy: 0.5249 - val_loss: 1.4120 - val_accuracy: 0.4881\n","Epoch 33/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2234 - accuracy: 0.5337\n","Epoch 33: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2273 - accuracy: 0.5326 - val_loss: 1.3568 - val_accuracy: 0.5595\n","Epoch 34/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2028 - accuracy: 0.5543\n","Epoch 34: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2281 - accuracy: 0.5568 - val_loss: 1.1582 - val_accuracy: 0.5506\n","Epoch 35/100\n","17/25 [===================>..........] - ETA: 0s - loss: 1.1978 - accuracy: 0.5349\n","Epoch 35: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2534 - accuracy: 0.5313 - val_loss: 1.7387 - val_accuracy: 0.5060\n","Epoch 36/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.3034 - accuracy: 0.5296\n","Epoch 36: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3140 - accuracy: 0.5134 - val_loss: 1.2092 - val_accuracy: 0.5357\n","Epoch 37/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.1971 - accuracy: 0.5526\n","Epoch 37: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.1970 - accuracy: 0.5492 - val_loss: 1.2553 - val_accuracy: 0.4583\n","Epoch 38/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.2508 - accuracy: 0.5446\n","Epoch 38: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2340 - accuracy: 0.5466 - val_loss: 1.2481 - val_accuracy: 0.4881\n","Epoch 39/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.1854 - accuracy: 0.5119\n","Epoch 39: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2044 - accuracy: 0.5198 - val_loss: 1.5168 - val_accuracy: 0.4732\n","Epoch 40/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.3703 - accuracy: 0.4913\n","Epoch 40: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3193 - accuracy: 0.5032 - val_loss: 1.3440 - val_accuracy: 0.5179\n","15/15 [==============================] - 0s 3ms/step\n","0.525\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["14/25 [===============>..............] - ETA: 0s - loss: 8.2308 - accuracy: 0.4085 \n","Epoch 1: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 1s 22ms/step - loss: 6.9978 - accuracy: 0.3831 - val_loss: 3.5435 - val_accuracy: 0.3214\n","Epoch 2/100\n","25/25 [==============================] - ETA: 0s - loss: 2.8679 - accuracy: 0.2720\n","Epoch 2: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 2.8679 - accuracy: 0.2720 - val_loss: 2.1452 - val_accuracy: 0.3631\n","Epoch 3/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.9987 - accuracy: 0.4089\n","Epoch 3: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.9970 - accuracy: 0.4061 - val_loss: 2.0122 - val_accuracy: 0.3452\n","Epoch 4/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.9078 - accuracy: 0.4740\n","Epoch 4: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.9328 - accuracy: 0.4713 - val_loss: 1.8244 - val_accuracy: 0.4226\n","Epoch 5/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.6776 - accuracy: 0.4891\n","Epoch 5: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.7001 - accuracy: 0.4904 - val_loss: 1.7594 - val_accuracy: 0.4256\n","Epoch 6/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.5215 - accuracy: 0.5156\n","Epoch 6: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.5175 - accuracy: 0.5134 - val_loss: 1.5310 - val_accuracy: 0.4286\n","Epoch 7/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.4393 - accuracy: 0.5299\n","Epoch 7: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4619 - accuracy: 0.5249 - val_loss: 1.7635 - val_accuracy: 0.4732\n","Epoch 8/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.5014 - accuracy: 0.4935\n","Epoch 8: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.5035 - accuracy: 0.4917 - val_loss: 1.5165 - val_accuracy: 0.4613\n","Epoch 9/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.4686 - accuracy: 0.4987\n","Epoch 9: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4627 - accuracy: 0.4994 - val_loss: 1.5087 - val_accuracy: 0.4673\n","Epoch 10/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3890 - accuracy: 0.5245\n","Epoch 10: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4126 - accuracy: 0.5223 - val_loss: 1.3353 - val_accuracy: 0.4673\n","Epoch 11/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3221 - accuracy: 0.5457\n","Epoch 11: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3379 - accuracy: 0.5262 - val_loss: 1.3217 - val_accuracy: 0.5387\n","Epoch 12/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3228 - accuracy: 0.5163\n","Epoch 12: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3287 - accuracy: 0.5134 - val_loss: 1.2498 - val_accuracy: 0.4583\n","Epoch 13/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.2791 - accuracy: 0.5028\n","Epoch 13: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3381 - accuracy: 0.4930 - val_loss: 1.3241 - val_accuracy: 0.5268\n","Epoch 14/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2822 - accuracy: 0.4986\n","Epoch 14: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2676 - accuracy: 0.5096 - val_loss: 1.2553 - val_accuracy: 0.5060\n","Epoch 15/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3340 - accuracy: 0.4974\n","Epoch 15: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3428 - accuracy: 0.4943 - val_loss: 1.4665 - val_accuracy: 0.3690\n","Epoch 16/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3778 - accuracy: 0.4994\n","Epoch 16: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3778 - accuracy: 0.4994 - val_loss: 1.3134 - val_accuracy: 0.5119\n","Epoch 17/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3596 - accuracy: 0.5120\n","Epoch 17: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.4558 - accuracy: 0.5019 - val_loss: 1.2644 - val_accuracy: 0.5179\n","Epoch 18/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.2437 - accuracy: 0.5379\n","Epoch 18: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2720 - accuracy: 0.5326 - val_loss: 1.2772 - val_accuracy: 0.5089\n","Epoch 19/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.2920 - accuracy: 0.5201\n","Epoch 19: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2263 - accuracy: 0.5466 - val_loss: 1.1748 - val_accuracy: 0.5417\n","Epoch 20/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2023 - accuracy: 0.5469\n","Epoch 20: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2173 - accuracy: 0.5453 - val_loss: 1.1771 - val_accuracy: 0.5536\n","Epoch 21/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.2403 - accuracy: 0.5625\n","Epoch 21: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2679 - accuracy: 0.5556 - val_loss: 1.3462 - val_accuracy: 0.5149\n","Epoch 22/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3838 - accuracy: 0.4891\n","Epoch 22: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3838 - accuracy: 0.4891 - val_loss: 1.3893 - val_accuracy: 0.5030\n","Epoch 23/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2554 - accuracy: 0.5160\n","Epoch 23: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2554 - accuracy: 0.5160 - val_loss: 1.2863 - val_accuracy: 0.5089\n","Epoch 24/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2655 - accuracy: 0.5078\n","Epoch 24: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2731 - accuracy: 0.5096 - val_loss: 1.4946 - val_accuracy: 0.4554\n","Epoch 25/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3432 - accuracy: 0.5147\n","Epoch 25: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3432 - accuracy: 0.5147 - val_loss: 1.4231 - val_accuracy: 0.5268\n","Epoch 26/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3130 - accuracy: 0.5495\n","Epoch 26: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3168 - accuracy: 0.5492 - val_loss: 1.3026 - val_accuracy: 0.5119\n","Epoch 27/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2953 - accuracy: 0.5481\n","Epoch 27: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2740 - accuracy: 0.5390 - val_loss: 1.2487 - val_accuracy: 0.4821\n","Epoch 28/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3621 - accuracy: 0.4928\n","Epoch 28: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2753 - accuracy: 0.5428 - val_loss: 1.3302 - val_accuracy: 0.4881\n","Epoch 29/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2183 - accuracy: 0.5683\n","Epoch 29: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2183 - accuracy: 0.5683 - val_loss: 1.3931 - val_accuracy: 0.4821\n","Epoch 30/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2752 - accuracy: 0.5352\n","Epoch 30: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2677 - accuracy: 0.5377 - val_loss: 1.1871 - val_accuracy: 0.5119\n","Epoch 31/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3936 - accuracy: 0.5361\n","Epoch 31: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3431 - accuracy: 0.5351 - val_loss: 1.3046 - val_accuracy: 0.4851\n","Epoch 32/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.4059 - accuracy: 0.4979\n","Epoch 32: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3377 - accuracy: 0.5070 - val_loss: 1.4158 - val_accuracy: 0.4048\n","Epoch 33/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2976 - accuracy: 0.4760\n","Epoch 33: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3412 - accuracy: 0.4789 - val_loss: 1.2940 - val_accuracy: 0.5476\n","Epoch 34/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.1109 - accuracy: 0.5601\n","Epoch 34: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.1465 - accuracy: 0.5658 - val_loss: 1.4157 - val_accuracy: 0.5327\n","Epoch 35/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2623 - accuracy: 0.5466\n","Epoch 35: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2623 - accuracy: 0.5466 - val_loss: 1.2502 - val_accuracy: 0.5298\n","Epoch 36/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2006 - accuracy: 0.5453\n","Epoch 36: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2006 - accuracy: 0.5453 - val_loss: 1.5126 - val_accuracy: 0.5000\n","Epoch 37/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.2713 - accuracy: 0.5483\n","Epoch 37: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3122 - accuracy: 0.5441 - val_loss: 1.4079 - val_accuracy: 0.5030\n","Epoch 38/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.5098 - accuracy: 0.4583\n","Epoch 38: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 11ms/step - loss: 1.4981 - accuracy: 0.4610 - val_loss: 1.2136 - val_accuracy: 0.5238\n","Epoch 39/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.2891 - accuracy: 0.4951\n","Epoch 39: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3306 - accuracy: 0.4828 - val_loss: 1.4764 - val_accuracy: 0.5208\n","Epoch 40/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.3474 - accuracy: 0.5253\n","Epoch 40: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3029 - accuracy: 0.5275 - val_loss: 1.2959 - val_accuracy: 0.5089\n","15/15 [==============================] - 0s 3ms/step\n","0.5270833333333333\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["25/25 [==============================] - ETA: 0s - loss: 2.3928 - accuracy: 0.3180\n","Epoch 1: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 1s 20ms/step - loss: 2.3928 - accuracy: 0.3180 - val_loss: 1.9895 - val_accuracy: 0.3690\n","Epoch 2/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.8705 - accuracy: 0.3973\n","Epoch 2: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.8275 - accuracy: 0.4112 - val_loss: 1.6297 - val_accuracy: 0.4613\n","Epoch 3/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.6292 - accuracy: 0.4740\n","Epoch 3: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.6219 - accuracy: 0.4777 - val_loss: 1.6806 - val_accuracy: 0.4732\n","Epoch 4/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.3688 - accuracy: 0.4911\n","Epoch 4: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.5296 - accuracy: 0.4610 - val_loss: 1.4388 - val_accuracy: 0.4494\n","Epoch 5/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.4077 - accuracy: 0.4974\n","Epoch 5: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4062 - accuracy: 0.4981 - val_loss: 1.3444 - val_accuracy: 0.4762\n","Epoch 6/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3516 - accuracy: 0.5045\n","Epoch 6: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3516 - accuracy: 0.5045 - val_loss: 1.5658 - val_accuracy: 0.4881\n","Epoch 7/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.4089 - accuracy: 0.5024\n","Epoch 7: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4083 - accuracy: 0.5096 - val_loss: 1.3560 - val_accuracy: 0.4851\n","Epoch 8/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2710 - accuracy: 0.5096\n","Epoch 8: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3248 - accuracy: 0.5070 - val_loss: 1.4395 - val_accuracy: 0.5357\n","Epoch 9/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3483 - accuracy: 0.5063\n","Epoch 9: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3474 - accuracy: 0.5109 - val_loss: 1.5384 - val_accuracy: 0.3423\n","Epoch 10/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3852 - accuracy: 0.4604\n","Epoch 10: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3588 - accuracy: 0.4751 - val_loss: 1.4590 - val_accuracy: 0.5298\n","Epoch 11/100\n","25/25 [==============================] - ETA: 0s - loss: 1.5866 - accuracy: 0.4725\n","Epoch 11: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.5866 - accuracy: 0.4725 - val_loss: 1.2907 - val_accuracy: 0.5060\n","Epoch 12/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3568 - accuracy: 0.5014\n","Epoch 12: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3397 - accuracy: 0.5045 - val_loss: 1.2875 - val_accuracy: 0.5565\n","Epoch 13/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.6106 - accuracy: 0.4754\n","Epoch 13: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.5609 - accuracy: 0.4764 - val_loss: 1.3008 - val_accuracy: 0.5000\n","Epoch 14/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2456 - accuracy: 0.5024\n","Epoch 14: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3080 - accuracy: 0.4943 - val_loss: 1.9105 - val_accuracy: 0.5030\n","Epoch 15/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.5402 - accuracy: 0.5091\n","Epoch 15: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.5373 - accuracy: 0.5070 - val_loss: 1.2308 - val_accuracy: 0.5298\n","Epoch 16/100\n","25/25 [==============================] - ETA: 0s - loss: 1.4195 - accuracy: 0.4930\n","Epoch 16: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4195 - accuracy: 0.4930 - val_loss: 1.3858 - val_accuracy: 0.4881\n","Epoch 17/100\n","12/25 [=============>................] - ETA: 0s - loss: 1.3354 - accuracy: 0.5417\n","Epoch 17: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3392 - accuracy: 0.4904 - val_loss: 1.2521 - val_accuracy: 0.4792\n","Epoch 18/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.3141 - accuracy: 0.5156\n","Epoch 18: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3164 - accuracy: 0.5006 - val_loss: 1.2293 - val_accuracy: 0.4673\n","Epoch 19/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2971 - accuracy: 0.5221\n","Epoch 19: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3179 - accuracy: 0.5185 - val_loss: 1.1852 - val_accuracy: 0.5030\n","Epoch 20/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3880 - accuracy: 0.5000\n","Epoch 20: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3959 - accuracy: 0.4955 - val_loss: 1.2742 - val_accuracy: 0.4940\n","Epoch 21/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.2537 - accuracy: 0.5179\n","Epoch 21: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2474 - accuracy: 0.5057 - val_loss: 1.2671 - val_accuracy: 0.5357\n","Epoch 22/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.4058 - accuracy: 0.4531\n","Epoch 22: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3903 - accuracy: 0.4828 - val_loss: 1.2388 - val_accuracy: 0.4821\n","Epoch 23/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3373 - accuracy: 0.4812\n","Epoch 23: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3310 - accuracy: 0.4968 - val_loss: 1.2527 - val_accuracy: 0.4940\n","Epoch 24/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2246 - accuracy: 0.5312\n","Epoch 24: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3821 - accuracy: 0.5198 - val_loss: 1.3223 - val_accuracy: 0.4911\n","Epoch 25/100\n","12/25 [=============>................] - ETA: 0s - loss: 1.3933 - accuracy: 0.4974\n","Epoch 25: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.5335 - accuracy: 0.4815 - val_loss: 1.5731 - val_accuracy: 0.4524\n","Epoch 26/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.4834 - accuracy: 0.5067\n","Epoch 26: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3636 - accuracy: 0.5198 - val_loss: 1.4008 - val_accuracy: 0.4732\n","Epoch 27/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.3097 - accuracy: 0.5112\n","Epoch 27: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2857 - accuracy: 0.4994 - val_loss: 1.5863 - val_accuracy: 0.4137\n","Epoch 28/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.4300 - accuracy: 0.4336\n","Epoch 28: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4280 - accuracy: 0.4368 - val_loss: 1.8539 - val_accuracy: 0.4643\n","Epoch 29/100\n","12/25 [=============>................] - ETA: 0s - loss: 1.4789 - accuracy: 0.4427\n","Epoch 29: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3844 - accuracy: 0.4700 - val_loss: 1.2823 - val_accuracy: 0.5060\n","Epoch 30/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3318 - accuracy: 0.4946\n","Epoch 30: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3291 - accuracy: 0.4981 - val_loss: 1.5179 - val_accuracy: 0.4702\n","Epoch 31/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2844 - accuracy: 0.5489\n","Epoch 31: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2750 - accuracy: 0.5543 - val_loss: 1.2875 - val_accuracy: 0.4970\n","Epoch 32/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.4321 - accuracy: 0.4857\n","Epoch 32: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.4328 - accuracy: 0.4891 - val_loss: 1.5322 - val_accuracy: 0.4821\n","15/15 [==============================] - 0s 4ms/step\n","0.5020833333333333\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["25/25 [==============================] - ETA: 0s - loss: 3.9414 - accuracy: 0.1507\n","Epoch 1: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 1s 21ms/step - loss: 3.9414 - accuracy: 0.1507 - val_loss: 2.7005 - val_accuracy: 0.2857\n","Epoch 2/100\n","24/25 [===========================>..] - ETA: 0s - loss: 2.4136 - accuracy: 0.3047\n","Epoch 2: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 2.4230 - accuracy: 0.3014 - val_loss: 2.1985 - val_accuracy: 0.2619\n","Epoch 3/100\n","14/25 [===============>..............] - ETA: 0s - loss: 2.0772 - accuracy: 0.3504\n","Epoch 3: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.9844 - accuracy: 0.3550 - val_loss: 1.7542 - val_accuracy: 0.3750\n","Epoch 4/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.7409 - accuracy: 0.4107\n","Epoch 4: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.6116 - accuracy: 0.4368 - val_loss: 1.5238 - val_accuracy: 0.4524\n","Epoch 5/100\n","25/25 [==============================] - ETA: 0s - loss: 1.5695 - accuracy: 0.4598\n","Epoch 5: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.5695 - accuracy: 0.4598 - val_loss: 1.3691 - val_accuracy: 0.4970\n","Epoch 6/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.4607 - accuracy: 0.4375\n","Epoch 6: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.4382 - accuracy: 0.4534 - val_loss: 1.4002 - val_accuracy: 0.4494\n","Epoch 7/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3895 - accuracy: 0.4351\n","Epoch 7: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4658 - accuracy: 0.4278 - val_loss: 1.3108 - val_accuracy: 0.4851\n","Epoch 8/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3361 - accuracy: 0.4375\n","Epoch 8: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3804 - accuracy: 0.4444 - val_loss: 1.3902 - val_accuracy: 0.4792\n","Epoch 9/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.5229 - accuracy: 0.4576\n","Epoch 9: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4780 - accuracy: 0.4572 - val_loss: 1.5123 - val_accuracy: 0.4077\n","Epoch 10/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.4366 - accuracy: 0.4297\n","Epoch 10: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3819 - accuracy: 0.4483 - val_loss: 1.4281 - val_accuracy: 0.5000\n","Epoch 11/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3628 - accuracy: 0.4928\n","Epoch 11: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3760 - accuracy: 0.4738 - val_loss: 1.2579 - val_accuracy: 0.4881\n","Epoch 12/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.3265 - accuracy: 0.5022\n","Epoch 12: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3450 - accuracy: 0.4955 - val_loss: 1.4449 - val_accuracy: 0.4375\n","Epoch 13/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3599 - accuracy: 0.4917\n","Epoch 13: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3620 - accuracy: 0.4713 - val_loss: 1.3237 - val_accuracy: 0.5238\n","Epoch 14/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.4985 - accuracy: 0.4621\n","Epoch 14: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.4138 - accuracy: 0.4917 - val_loss: 1.6300 - val_accuracy: 0.4851\n","Epoch 15/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.4129 - accuracy: 0.5067\n","Epoch 15: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4188 - accuracy: 0.4968 - val_loss: 1.3340 - val_accuracy: 0.4137\n","Epoch 16/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3508 - accuracy: 0.4961\n","Epoch 16: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3519 - accuracy: 0.4943 - val_loss: 1.3303 - val_accuracy: 0.4940\n","Epoch 17/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2849 - accuracy: 0.5177\n","Epoch 17: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2892 - accuracy: 0.5185 - val_loss: 1.5494 - val_accuracy: 0.5000\n","Epoch 18/100\n","25/25 [==============================] - ETA: 0s - loss: 1.5213 - accuracy: 0.4777\n","Epoch 18: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.5213 - accuracy: 0.4777 - val_loss: 1.4886 - val_accuracy: 0.4226\n","Epoch 19/100\n","25/25 [==============================] - ETA: 0s - loss: 1.4491 - accuracy: 0.4751\n","Epoch 19: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4491 - accuracy: 0.4751 - val_loss: 1.3389 - val_accuracy: 0.4643\n","Epoch 20/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3714 - accuracy: 0.5096\n","Epoch 20: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3714 - accuracy: 0.5096 - val_loss: 1.5334 - val_accuracy: 0.4732\n","Epoch 21/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.4441 - accuracy: 0.5068\n","Epoch 21: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4682 - accuracy: 0.5032 - val_loss: 1.5774 - val_accuracy: 0.4881\n","Epoch 22/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3355 - accuracy: 0.5172\n","Epoch 22: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3355 - accuracy: 0.5172 - val_loss: 1.4949 - val_accuracy: 0.4673\n","Epoch 23/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3009 - accuracy: 0.5109\n","Epoch 23: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2995 - accuracy: 0.5109 - val_loss: 1.2234 - val_accuracy: 0.5327\n","Epoch 24/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.4258 - accuracy: 0.4888\n","Epoch 24: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.4179 - accuracy: 0.4955 - val_loss: 1.5428 - val_accuracy: 0.4613\n","Epoch 25/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.5115 - accuracy: 0.4437\n","Epoch 25: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.5719 - accuracy: 0.4521 - val_loss: 1.3919 - val_accuracy: 0.4762\n","Epoch 26/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3213 - accuracy: 0.4792\n","Epoch 26: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3344 - accuracy: 0.4764 - val_loss: 1.2869 - val_accuracy: 0.5119\n","Epoch 27/100\n","25/25 [==============================] - ETA: 0s - loss: 1.4763 - accuracy: 0.4917\n","Epoch 27: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4763 - accuracy: 0.4917 - val_loss: 1.3910 - val_accuracy: 0.4821\n","Epoch 28/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3045 - accuracy: 0.4891\n","Epoch 28: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3045 - accuracy: 0.4891 - val_loss: 1.4933 - val_accuracy: 0.3750\n","Epoch 29/100\n","25/25 [==============================] - ETA: 0s - loss: 1.4146 - accuracy: 0.4738\n","Epoch 29: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4146 - accuracy: 0.4738 - val_loss: 1.4043 - val_accuracy: 0.4524\n","Epoch 30/100\n","25/25 [==============================] - ETA: 0s - loss: 1.4811 - accuracy: 0.4904\n","Epoch 30: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4811 - accuracy: 0.4904 - val_loss: 1.2804 - val_accuracy: 0.4494\n","Epoch 31/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3181 - accuracy: 0.5109\n","Epoch 31: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3303 - accuracy: 0.5070 - val_loss: 1.2968 - val_accuracy: 0.5089\n","Epoch 32/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.4236 - accuracy: 0.4787\n","Epoch 32: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4537 - accuracy: 0.4815 - val_loss: 1.3673 - val_accuracy: 0.4315\n","Epoch 33/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3648 - accuracy: 0.5045\n","Epoch 33: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3648 - accuracy: 0.5045 - val_loss: 1.2933 - val_accuracy: 0.4315\n","Epoch 34/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3226 - accuracy: 0.4736\n","Epoch 34: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3151 - accuracy: 0.4777 - val_loss: 1.3156 - val_accuracy: 0.4613\n","Epoch 35/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2369 - accuracy: 0.5096\n","Epoch 35: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2687 - accuracy: 0.5032 - val_loss: 1.1779 - val_accuracy: 0.5595\n","Epoch 36/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3377 - accuracy: 0.5217\n","Epoch 36: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3300 - accuracy: 0.5211 - val_loss: 1.3871 - val_accuracy: 0.5238\n","Epoch 37/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3102 - accuracy: 0.5287\n","Epoch 37: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3102 - accuracy: 0.5287 - val_loss: 1.3170 - val_accuracy: 0.4554\n","Epoch 38/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3080 - accuracy: 0.5109\n","Epoch 38: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3080 - accuracy: 0.5109 - val_loss: 1.2467 - val_accuracy: 0.4702\n","Epoch 39/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.2970 - accuracy: 0.5164\n","Epoch 39: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3205 - accuracy: 0.5070 - val_loss: 1.5437 - val_accuracy: 0.5179\n","Epoch 40/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2656 - accuracy: 0.5351\n","Epoch 40: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2656 - accuracy: 0.5351 - val_loss: 1.2248 - val_accuracy: 0.5774\n","Epoch 41/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2910 - accuracy: 0.4922\n","Epoch 41: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2886 - accuracy: 0.4930 - val_loss: 1.3560 - val_accuracy: 0.5357\n","Epoch 42/100\n","12/25 [=============>................] - ETA: 0s - loss: 1.2541 - accuracy: 0.4844\n","Epoch 42: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3072 - accuracy: 0.4994 - val_loss: 1.3006 - val_accuracy: 0.5565\n","Epoch 43/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3532 - accuracy: 0.4591\n","Epoch 43: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2998 - accuracy: 0.4994 - val_loss: 1.2882 - val_accuracy: 0.5714\n","Epoch 44/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.2570 - accuracy: 0.5085\n","Epoch 44: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2481 - accuracy: 0.5109 - val_loss: 1.5900 - val_accuracy: 0.4524\n","Epoch 45/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.3696 - accuracy: 0.5330\n","Epoch 45: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3480 - accuracy: 0.5185 - val_loss: 1.4405 - val_accuracy: 0.4821\n","Epoch 46/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.2608 - accuracy: 0.5281\n","Epoch 46: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2871 - accuracy: 0.5211 - val_loss: 1.2980 - val_accuracy: 0.5476\n","Epoch 47/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2436 - accuracy: 0.5285\n","Epoch 47: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2466 - accuracy: 0.5300 - val_loss: 1.3436 - val_accuracy: 0.5655\n","Epoch 48/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2940 - accuracy: 0.5095\n","Epoch 48: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3075 - accuracy: 0.5019 - val_loss: 1.2146 - val_accuracy: 0.5089\n","Epoch 49/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.2866 - accuracy: 0.5297\n","Epoch 49: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2537 - accuracy: 0.5300 - val_loss: 1.1917 - val_accuracy: 0.5446\n","Epoch 50/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.2421 - accuracy: 0.5033\n","Epoch 50: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2178 - accuracy: 0.5249 - val_loss: 1.2374 - val_accuracy: 0.5268\n","Epoch 51/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2945 - accuracy: 0.5275\n","Epoch 51: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 11ms/step - loss: 1.2945 - accuracy: 0.5275 - val_loss: 1.2345 - val_accuracy: 0.4762\n","Epoch 52/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.2753 - accuracy: 0.4967\n","Epoch 52: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3131 - accuracy: 0.4968 - val_loss: 1.6376 - val_accuracy: 0.3988\n","Epoch 53/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2858 - accuracy: 0.5247\n","Epoch 53: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2808 - accuracy: 0.5236 - val_loss: 1.3769 - val_accuracy: 0.4762\n","Epoch 54/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2426 - accuracy: 0.5262\n","Epoch 54: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2426 - accuracy: 0.5262 - val_loss: 1.3008 - val_accuracy: 0.5268\n","Epoch 55/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.2970 - accuracy: 0.5296\n","Epoch 55: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2719 - accuracy: 0.5198 - val_loss: 1.3383 - val_accuracy: 0.5357\n","Epoch 56/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.2547 - accuracy: 0.5521\n","Epoch 56: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2322 - accuracy: 0.5492 - val_loss: 1.5943 - val_accuracy: 0.4643\n","Epoch 57/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.1895 - accuracy: 0.5430\n","Epoch 57: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 11ms/step - loss: 1.2002 - accuracy: 0.5441 - val_loss: 1.3486 - val_accuracy: 0.5119\n","Epoch 58/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.3016 - accuracy: 0.5052\n","Epoch 58: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2962 - accuracy: 0.5364 - val_loss: 1.6619 - val_accuracy: 0.5089\n","Epoch 59/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3463 - accuracy: 0.5039\n","Epoch 59: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 11ms/step - loss: 1.3554 - accuracy: 0.5057 - val_loss: 1.3765 - val_accuracy: 0.5387\n","Epoch 60/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.2192 - accuracy: 0.5573\n","Epoch 60: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2123 - accuracy: 0.5466 - val_loss: 1.3167 - val_accuracy: 0.5208\n","15/15 [==============================] - 1s 3ms/step\n","0.5541666666666667\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["23/25 [==========================>...] - ETA: 0s - loss: 3.1061 - accuracy: 0.3560\n","Epoch 1: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 2s 23ms/step - loss: 3.0471 - accuracy: 0.3525 - val_loss: 2.3001 - val_accuracy: 0.3661\n","Epoch 2/100\n","25/25 [==============================] - ETA: 0s - loss: 1.8616 - accuracy: 0.4266\n","Epoch 2: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 11ms/step - loss: 1.8616 - accuracy: 0.4266 - val_loss: 1.7841 - val_accuracy: 0.4286\n","Epoch 3/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.6181 - accuracy: 0.4359\n","Epoch 3: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.6643 - accuracy: 0.4393 - val_loss: 1.6853 - val_accuracy: 0.4643\n","Epoch 4/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.5667 - accuracy: 0.4905\n","Epoch 4: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 12ms/step - loss: 1.5574 - accuracy: 0.4917 - val_loss: 1.4615 - val_accuracy: 0.4911\n","Epoch 5/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.5573 - accuracy: 0.4672\n","Epoch 5: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.5610 - accuracy: 0.4598 - val_loss: 1.5341 - val_accuracy: 0.5030\n","Epoch 6/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.4792 - accuracy: 0.5204\n","Epoch 6: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4968 - accuracy: 0.5211 - val_loss: 1.7250 - val_accuracy: 0.5089\n","Epoch 7/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.4741 - accuracy: 0.5089\n","Epoch 7: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.5401 - accuracy: 0.4981 - val_loss: 1.4124 - val_accuracy: 0.4792\n","Epoch 8/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.4762 - accuracy: 0.4732\n","Epoch 8: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.4848 - accuracy: 0.4764 - val_loss: 1.4757 - val_accuracy: 0.4494\n","Epoch 9/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.5498 - accuracy: 0.4836\n","Epoch 9: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.5502 - accuracy: 0.4738 - val_loss: 1.5816 - val_accuracy: 0.4435\n","Epoch 10/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.4983 - accuracy: 0.4851\n","Epoch 10: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.5277 - accuracy: 0.4777 - val_loss: 1.4267 - val_accuracy: 0.4554\n","Epoch 11/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.4139 - accuracy: 0.5014\n","Epoch 11: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3824 - accuracy: 0.5134 - val_loss: 1.3444 - val_accuracy: 0.4970\n","Epoch 12/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.4038 - accuracy: 0.4828\n","Epoch 12: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3738 - accuracy: 0.4955 - val_loss: 1.5554 - val_accuracy: 0.5149\n","Epoch 13/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.5661 - accuracy: 0.5033\n","Epoch 13: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.5101 - accuracy: 0.5045 - val_loss: 1.3737 - val_accuracy: 0.4970\n","Epoch 14/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.4046 - accuracy: 0.5230\n","Epoch 14: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.4048 - accuracy: 0.5287 - val_loss: 1.4518 - val_accuracy: 0.4613\n","Epoch 15/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.4653 - accuracy: 0.4819\n","Epoch 15: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.4051 - accuracy: 0.4891 - val_loss: 1.4319 - val_accuracy: 0.4435\n","Epoch 16/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.3830 - accuracy: 0.5132\n","Epoch 16: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3472 - accuracy: 0.5160 - val_loss: 1.2206 - val_accuracy: 0.5238\n","Epoch 17/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.3861 - accuracy: 0.4844\n","Epoch 17: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3832 - accuracy: 0.4840 - val_loss: 1.4039 - val_accuracy: 0.4643\n","Epoch 18/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.3499 - accuracy: 0.4747\n","Epoch 18: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3619 - accuracy: 0.4777 - val_loss: 1.2977 - val_accuracy: 0.5089\n","Epoch 19/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.4052 - accuracy: 0.5026\n","Epoch 19: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3937 - accuracy: 0.5057 - val_loss: 1.4618 - val_accuracy: 0.4851\n","Epoch 20/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.4029 - accuracy: 0.4796\n","Epoch 20: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4300 - accuracy: 0.4777 - val_loss: 1.4276 - val_accuracy: 0.4881\n","Epoch 21/100\n","25/25 [==============================] - ETA: 0s - loss: 1.4569 - accuracy: 0.5045\n","Epoch 21: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4569 - accuracy: 0.5045 - val_loss: 1.4511 - val_accuracy: 0.4673\n","Epoch 22/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3331 - accuracy: 0.4823\n","Epoch 22: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3391 - accuracy: 0.4853 - val_loss: 1.3588 - val_accuracy: 0.5506\n","Epoch 23/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.4099 - accuracy: 0.4858\n","Epoch 23: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.4150 - accuracy: 0.4866 - val_loss: 1.4827 - val_accuracy: 0.4613\n","Epoch 24/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3579 - accuracy: 0.5000\n","Epoch 24: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3550 - accuracy: 0.5057 - val_loss: 1.6110 - val_accuracy: 0.4762\n","Epoch 25/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3036 - accuracy: 0.5275\n","Epoch 25: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3036 - accuracy: 0.5275 - val_loss: 1.3778 - val_accuracy: 0.4732\n","Epoch 26/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3652 - accuracy: 0.5095\n","Epoch 26: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3510 - accuracy: 0.5121 - val_loss: 1.3180 - val_accuracy: 0.5238\n","Epoch 27/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.2468 - accuracy: 0.5193\n","Epoch 27: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2394 - accuracy: 0.5160 - val_loss: 1.4228 - val_accuracy: 0.5060\n","Epoch 28/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3408 - accuracy: 0.5247\n","Epoch 28: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3380 - accuracy: 0.5236 - val_loss: 1.4648 - val_accuracy: 0.5089\n","Epoch 29/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3543 - accuracy: 0.5072\n","Epoch 29: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3169 - accuracy: 0.5236 - val_loss: 1.2474 - val_accuracy: 0.4554\n","Epoch 30/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2599 - accuracy: 0.5208\n","Epoch 30: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2639 - accuracy: 0.5223 - val_loss: 1.4698 - val_accuracy: 0.4702\n","Epoch 31/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3627 - accuracy: 0.5109\n","Epoch 31: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3627 - accuracy: 0.5109 - val_loss: 1.2992 - val_accuracy: 0.4286\n","Epoch 32/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.3633 - accuracy: 0.5082\n","Epoch 32: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3075 - accuracy: 0.5096 - val_loss: 1.4083 - val_accuracy: 0.5179\n","Epoch 33/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3495 - accuracy: 0.4879\n","Epoch 33: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3495 - accuracy: 0.4879 - val_loss: 1.3464 - val_accuracy: 0.4762\n","Epoch 34/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2797 - accuracy: 0.4904\n","Epoch 34: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2797 - accuracy: 0.4904 - val_loss: 1.2238 - val_accuracy: 0.5387\n","Epoch 35/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3687 - accuracy: 0.5122\n","Epoch 35: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.4124 - accuracy: 0.5070 - val_loss: 1.6146 - val_accuracy: 0.4375\n","Epoch 36/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3301 - accuracy: 0.5285\n","Epoch 36: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3291 - accuracy: 0.5287 - val_loss: 1.3309 - val_accuracy: 0.4881\n","Epoch 37/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3698 - accuracy: 0.5312\n","Epoch 37: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3837 - accuracy: 0.5275 - val_loss: 1.5524 - val_accuracy: 0.4464\n","Epoch 38/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.4667 - accuracy: 0.4858\n","Epoch 38: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4345 - accuracy: 0.4955 - val_loss: 1.6711 - val_accuracy: 0.5149\n","Epoch 39/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3748 - accuracy: 0.5070\n","Epoch 39: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3748 - accuracy: 0.5070 - val_loss: 1.2101 - val_accuracy: 0.5149\n","Epoch 40/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3349 - accuracy: 0.5096\n","Epoch 40: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3349 - accuracy: 0.5096 - val_loss: 1.5594 - val_accuracy: 0.4256\n","Epoch 41/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.4743 - accuracy: 0.4633\n","Epoch 41: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4594 - accuracy: 0.4687 - val_loss: 1.5961 - val_accuracy: 0.4107\n","Epoch 42/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3573 - accuracy: 0.4946\n","Epoch 42: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3583 - accuracy: 0.4930 - val_loss: 1.3254 - val_accuracy: 0.4881\n","15/15 [==============================] - 0s 3ms/step\n","0.4895833333333333\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["13/25 [==============>...............] - ETA: 0s - loss: 4.3973 - accuracy: 0.1130 \n","Epoch 1: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 1s 22ms/step - loss: 3.4541 - accuracy: 0.2222 - val_loss: 1.9494 - val_accuracy: 0.4196\n","Epoch 2/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.9713 - accuracy: 0.4397\n","Epoch 2: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.8674 - accuracy: 0.4406 - val_loss: 1.7673 - val_accuracy: 0.4554\n","Epoch 3/100\n","25/25 [==============================] - ETA: 0s - loss: 1.6171 - accuracy: 0.4751\n","Epoch 3: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.6171 - accuracy: 0.4751 - val_loss: 1.6135 - val_accuracy: 0.4494\n","Epoch 4/100\n","25/25 [==============================] - ETA: 0s - loss: 1.5297 - accuracy: 0.5109\n","Epoch 4: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.5297 - accuracy: 0.5109 - val_loss: 1.5197 - val_accuracy: 0.4821\n","Epoch 5/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.4938 - accuracy: 0.5091\n","Epoch 5: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4943 - accuracy: 0.5096 - val_loss: 1.5197 - val_accuracy: 0.4911\n","Epoch 6/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.4661 - accuracy: 0.4986\n","Epoch 6: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4659 - accuracy: 0.5032 - val_loss: 1.3736 - val_accuracy: 0.4940\n","Epoch 7/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3762 - accuracy: 0.5172\n","Epoch 7: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3762 - accuracy: 0.5172 - val_loss: 1.4765 - val_accuracy: 0.4464\n","Epoch 8/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3710 - accuracy: 0.5352\n","Epoch 8: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3785 - accuracy: 0.5326 - val_loss: 1.4512 - val_accuracy: 0.4256\n","Epoch 9/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.4501 - accuracy: 0.4760\n","Epoch 9: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 6ms/step - loss: 1.4221 - accuracy: 0.5045 - val_loss: 1.4104 - val_accuracy: 0.3839\n","Epoch 10/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.3669 - accuracy: 0.4955\n","Epoch 10: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4156 - accuracy: 0.4853 - val_loss: 1.3231 - val_accuracy: 0.5089\n","Epoch 11/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.3759 - accuracy: 0.5000\n","Epoch 11: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3517 - accuracy: 0.5083 - val_loss: 1.2265 - val_accuracy: 0.5327\n","Epoch 12/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3320 - accuracy: 0.5211\n","Epoch 12: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3320 - accuracy: 0.5211 - val_loss: 1.2652 - val_accuracy: 0.4940\n","Epoch 13/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3241 - accuracy: 0.4943\n","Epoch 13: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3241 - accuracy: 0.4943 - val_loss: 1.2991 - val_accuracy: 0.4792\n","Epoch 14/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3287 - accuracy: 0.4777\n","Epoch 14: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3287 - accuracy: 0.4777 - val_loss: 1.4310 - val_accuracy: 0.4643\n","Epoch 15/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3794 - accuracy: 0.4968\n","Epoch 15: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3794 - accuracy: 0.4968 - val_loss: 1.2199 - val_accuracy: 0.5149\n","Epoch 16/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3430 - accuracy: 0.5045\n","Epoch 16: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3430 - accuracy: 0.5045 - val_loss: 1.2674 - val_accuracy: 0.5685\n","Epoch 17/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.3576 - accuracy: 0.5122\n","Epoch 17: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3568 - accuracy: 0.5236 - val_loss: 1.5007 - val_accuracy: 0.5149\n","Epoch 18/100\n","17/25 [===================>..........] - ETA: 0s - loss: 1.3599 - accuracy: 0.5147\n","Epoch 18: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3906 - accuracy: 0.5019 - val_loss: 1.3839 - val_accuracy: 0.5238\n","Epoch 19/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.2772 - accuracy: 0.5573\n","Epoch 19: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3113 - accuracy: 0.5377 - val_loss: 1.2485 - val_accuracy: 0.5625\n","Epoch 20/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.3673 - accuracy: 0.5341\n","Epoch 20: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 11ms/step - loss: 1.3711 - accuracy: 0.5300 - val_loss: 1.3515 - val_accuracy: 0.4792\n","Epoch 21/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3421 - accuracy: 0.5083\n","Epoch 21: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 11ms/step - loss: 1.3421 - accuracy: 0.5083 - val_loss: 1.4815 - val_accuracy: 0.5030\n","Epoch 22/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.3744 - accuracy: 0.4948\n","Epoch 22: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 11ms/step - loss: 1.3479 - accuracy: 0.5070 - val_loss: 1.1589 - val_accuracy: 0.5774\n","Epoch 23/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2547 - accuracy: 0.5273\n","Epoch 23: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 11ms/step - loss: 1.2592 - accuracy: 0.5275 - val_loss: 1.2582 - val_accuracy: 0.5000\n","Epoch 24/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.2021 - accuracy: 0.5556\n","Epoch 24: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 11ms/step - loss: 1.2090 - accuracy: 0.5351 - val_loss: 1.2485 - val_accuracy: 0.5030\n","Epoch 25/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.3206 - accuracy: 0.5060\n","Epoch 25: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3495 - accuracy: 0.5096 - val_loss: 1.7827 - val_accuracy: 0.4286\n","Epoch 26/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.3263 - accuracy: 0.5089\n","Epoch 26: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3319 - accuracy: 0.5109 - val_loss: 1.2351 - val_accuracy: 0.5506\n","Epoch 27/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.3130 - accuracy: 0.5156\n","Epoch 27: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3362 - accuracy: 0.5109 - val_loss: 1.3464 - val_accuracy: 0.4345\n","Epoch 28/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.4244 - accuracy: 0.4984\n","Epoch 28: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 9ms/step - loss: 1.4590 - accuracy: 0.4828 - val_loss: 1.2609 - val_accuracy: 0.5357\n","Epoch 29/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.4720 - accuracy: 0.4753\n","Epoch 29: val_accuracy did not improve from 0.59226\n","25/25 [==============================] - 0s 10ms/step - loss: 1.4293 - accuracy: 0.4764 - val_loss: 1.3813 - val_accuracy: 0.5149\n","Epoch 30/100\n","17/25 [===================>..........] - ETA: 0s - loss: 1.4500 - accuracy: 0.4871\n","Epoch 30: val_accuracy improved from 0.59226 to 0.59524, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 12ms/step - loss: 1.3866 - accuracy: 0.4917 - val_loss: 1.2268 - val_accuracy: 0.5952\n","Epoch 31/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.3185 - accuracy: 0.5208\n","Epoch 31: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3222 - accuracy: 0.5147 - val_loss: 1.2078 - val_accuracy: 0.5863\n","Epoch 32/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3330 - accuracy: 0.4805\n","Epoch 32: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3405 - accuracy: 0.4815 - val_loss: 1.4115 - val_accuracy: 0.5179\n","Epoch 33/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2603 - accuracy: 0.5340\n","Epoch 33: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2625 - accuracy: 0.5326 - val_loss: 1.3640 - val_accuracy: 0.3988\n","Epoch 34/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.2622 - accuracy: 0.5089\n","Epoch 34: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3114 - accuracy: 0.5019 - val_loss: 1.2166 - val_accuracy: 0.4911\n","Epoch 35/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2636 - accuracy: 0.5313\n","Epoch 35: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2636 - accuracy: 0.5313 - val_loss: 1.3952 - val_accuracy: 0.4375\n","Epoch 36/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.1368 - accuracy: 0.5769\n","Epoch 36: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2529 - accuracy: 0.5517 - val_loss: 1.3396 - val_accuracy: 0.5060\n","Epoch 37/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2971 - accuracy: 0.5072\n","Epoch 37: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2580 - accuracy: 0.4994 - val_loss: 1.3217 - val_accuracy: 0.5268\n","Epoch 38/100\n","12/25 [=============>................] - ETA: 0s - loss: 1.4578 - accuracy: 0.4818\n","Epoch 38: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4138 - accuracy: 0.4955 - val_loss: 1.3084 - val_accuracy: 0.5208\n","Epoch 39/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3287 - accuracy: 0.5065\n","Epoch 39: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3180 - accuracy: 0.5083 - val_loss: 1.2186 - val_accuracy: 0.5387\n","Epoch 40/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.1867 - accuracy: 0.5529\n","Epoch 40: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2050 - accuracy: 0.5390 - val_loss: 1.1542 - val_accuracy: 0.5327\n","Epoch 41/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2043 - accuracy: 0.5287\n","Epoch 41: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2043 - accuracy: 0.5287 - val_loss: 1.2618 - val_accuracy: 0.5208\n","Epoch 42/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2493 - accuracy: 0.5889\n","Epoch 42: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2823 - accuracy: 0.5479 - val_loss: 1.1987 - val_accuracy: 0.4643\n","Epoch 43/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.2632 - accuracy: 0.4978\n","Epoch 43: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3365 - accuracy: 0.4917 - val_loss: 1.2451 - val_accuracy: 0.5446\n","Epoch 44/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3903 - accuracy: 0.5172\n","Epoch 44: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3903 - accuracy: 0.5172 - val_loss: 1.3202 - val_accuracy: 0.5089\n","Epoch 45/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3989 - accuracy: 0.4968\n","Epoch 45: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3989 - accuracy: 0.4968 - val_loss: 1.4731 - val_accuracy: 0.5149\n","Epoch 46/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3965 - accuracy: 0.4633\n","Epoch 46: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3862 - accuracy: 0.4649 - val_loss: 1.3582 - val_accuracy: 0.5536\n","Epoch 47/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.3214 - accuracy: 0.4904\n","Epoch 47: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2841 - accuracy: 0.5057 - val_loss: 1.4415 - val_accuracy: 0.5119\n","Epoch 48/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2487 - accuracy: 0.5143\n","Epoch 48: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2430 - accuracy: 0.5160 - val_loss: 1.3201 - val_accuracy: 0.5327\n","Epoch 49/100\n","25/25 [==============================] - ETA: 0s - loss: 1.4091 - accuracy: 0.4904\n","Epoch 49: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4091 - accuracy: 0.4904 - val_loss: 1.3401 - val_accuracy: 0.5536\n","Epoch 50/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.2290 - accuracy: 0.5341\n","Epoch 50: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2334 - accuracy: 0.5364 - val_loss: 1.4299 - val_accuracy: 0.5238\n","15/15 [==============================] - 0s 3ms/step\n","0.5041666666666667\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["14/25 [===============>..............] - ETA: 0s - loss: 2.6635 - accuracy: 0.3728 \n","Epoch 1: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 1s 22ms/step - loss: 2.4106 - accuracy: 0.3883 - val_loss: 2.1719 - val_accuracy: 0.4107\n","Epoch 2/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.9984 - accuracy: 0.3862\n","Epoch 2: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.9100 - accuracy: 0.3908 - val_loss: 1.8309 - val_accuracy: 0.4256\n","Epoch 3/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.7820 - accuracy: 0.3661\n","Epoch 3: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 6ms/step - loss: 1.6794 - accuracy: 0.4138 - val_loss: 1.5576 - val_accuracy: 0.4048\n","Epoch 4/100\n","25/25 [==============================] - ETA: 0s - loss: 1.6042 - accuracy: 0.4112\n","Epoch 4: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.6042 - accuracy: 0.4112 - val_loss: 1.6208 - val_accuracy: 0.4196\n","Epoch 5/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.5779 - accuracy: 0.4008\n","Epoch 5: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 9ms/step - loss: 1.5792 - accuracy: 0.4010 - val_loss: 1.4238 - val_accuracy: 0.4643\n","Epoch 6/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.4539 - accuracy: 0.4688\n","Epoch 6: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.5110 - accuracy: 0.4623 - val_loss: 1.3967 - val_accuracy: 0.4970\n","Epoch 7/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.5994 - accuracy: 0.4303\n","Epoch 7: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.5238 - accuracy: 0.4444 - val_loss: 1.3505 - val_accuracy: 0.4940\n","Epoch 8/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.5851 - accuracy: 0.4708\n","Epoch 8: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 6ms/step - loss: 1.4792 - accuracy: 0.4917 - val_loss: 1.2494 - val_accuracy: 0.5179\n","Epoch 9/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.4216 - accuracy: 0.4620\n","Epoch 9: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 9ms/step - loss: 1.4060 - accuracy: 0.4751 - val_loss: 1.2416 - val_accuracy: 0.4613\n","Epoch 10/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3794 - accuracy: 0.4427\n","Epoch 10: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3805 - accuracy: 0.4432 - val_loss: 1.4110 - val_accuracy: 0.4673\n","Epoch 11/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3294 - accuracy: 0.4853\n","Epoch 11: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3294 - accuracy: 0.4853 - val_loss: 1.3787 - val_accuracy: 0.4494\n","Epoch 12/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3120 - accuracy: 0.4864\n","Epoch 12: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2944 - accuracy: 0.4955 - val_loss: 1.4491 - val_accuracy: 0.4375\n","Epoch 13/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3618 - accuracy: 0.4948\n","Epoch 13: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3627 - accuracy: 0.4930 - val_loss: 1.3218 - val_accuracy: 0.5268\n","Epoch 14/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2854 - accuracy: 0.5136\n","Epoch 14: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3005 - accuracy: 0.5083 - val_loss: 1.3562 - val_accuracy: 0.4970\n","Epoch 15/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3679 - accuracy: 0.4810\n","Epoch 15: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3920 - accuracy: 0.4738 - val_loss: 1.4508 - val_accuracy: 0.4494\n","Epoch 16/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.3572 - accuracy: 0.4787\n","Epoch 16: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3487 - accuracy: 0.4751 - val_loss: 1.3424 - val_accuracy: 0.4167\n","Epoch 17/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3541 - accuracy: 0.4738\n","Epoch 17: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3541 - accuracy: 0.4738 - val_loss: 1.2267 - val_accuracy: 0.5327\n","Epoch 18/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2905 - accuracy: 0.4928\n","Epoch 18: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2728 - accuracy: 0.5185 - val_loss: 1.2186 - val_accuracy: 0.5268\n","Epoch 19/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2474 - accuracy: 0.5168\n","Epoch 19: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2642 - accuracy: 0.5045 - val_loss: 1.3157 - val_accuracy: 0.4286\n","Epoch 20/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3671 - accuracy: 0.4943\n","Epoch 20: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3671 - accuracy: 0.4943 - val_loss: 1.3136 - val_accuracy: 0.5089\n","Epoch 21/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.3339 - accuracy: 0.4972\n","Epoch 21: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3249 - accuracy: 0.4968 - val_loss: 1.2971 - val_accuracy: 0.5714\n","Epoch 22/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2809 - accuracy: 0.4760\n","Epoch 22: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2788 - accuracy: 0.4904 - val_loss: 1.1980 - val_accuracy: 0.4792\n","Epoch 23/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2479 - accuracy: 0.5216\n","Epoch 23: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2888 - accuracy: 0.5032 - val_loss: 1.4026 - val_accuracy: 0.4583\n","Epoch 24/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.2673 - accuracy: 0.4985\n","Epoch 24: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3037 - accuracy: 0.4994 - val_loss: 1.3304 - val_accuracy: 0.4792\n","Epoch 25/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3051 - accuracy: 0.4866\n","Epoch 25: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3051 - accuracy: 0.4866 - val_loss: 1.2529 - val_accuracy: 0.5565\n","Epoch 26/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3397 - accuracy: 0.5039\n","Epoch 26: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.3427 - accuracy: 0.5019 - val_loss: 1.2466 - val_accuracy: 0.5357\n","Epoch 27/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2264 - accuracy: 0.5208\n","Epoch 27: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2181 - accuracy: 0.5275 - val_loss: 1.2384 - val_accuracy: 0.5625\n","Epoch 28/100\n","25/25 [==============================] - ETA: 0s - loss: 1.1641 - accuracy: 0.5453\n","Epoch 28: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.1641 - accuracy: 0.5453 - val_loss: 1.3582 - val_accuracy: 0.4643\n","Epoch 29/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.1927 - accuracy: 0.5109\n","Epoch 29: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.1885 - accuracy: 0.5083 - val_loss: 1.2527 - val_accuracy: 0.5000\n","Epoch 30/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2761 - accuracy: 0.5070\n","Epoch 30: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2761 - accuracy: 0.5070 - val_loss: 1.1493 - val_accuracy: 0.5179\n","Epoch 31/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.2010 - accuracy: 0.5177\n","Epoch 31: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.1971 - accuracy: 0.5249 - val_loss: 1.1896 - val_accuracy: 0.5327\n","Epoch 32/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3818 - accuracy: 0.4636\n","Epoch 32: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3818 - accuracy: 0.4636 - val_loss: 1.2632 - val_accuracy: 0.4643\n","Epoch 33/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2774 - accuracy: 0.5121\n","Epoch 33: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2774 - accuracy: 0.5121 - val_loss: 1.3084 - val_accuracy: 0.5774\n","Epoch 34/100\n","23/25 [==========================>...] - ETA: 0s - loss: 1.3494 - accuracy: 0.4918\n","Epoch 34: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3373 - accuracy: 0.4917 - val_loss: 1.3041 - val_accuracy: 0.4762\n","Epoch 35/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3275 - accuracy: 0.4948\n","Epoch 35: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3116 - accuracy: 0.5019 - val_loss: 1.2753 - val_accuracy: 0.4881\n","Epoch 36/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.3188 - accuracy: 0.4747\n","Epoch 36: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3331 - accuracy: 0.4789 - val_loss: 1.6048 - val_accuracy: 0.4286\n","Epoch 37/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.2769 - accuracy: 0.5185\n","Epoch 37: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 9ms/step - loss: 1.2907 - accuracy: 0.5006 - val_loss: 1.3115 - val_accuracy: 0.4792\n","Epoch 38/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.3642 - accuracy: 0.5078\n","Epoch 38: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3404 - accuracy: 0.5083 - val_loss: 1.6053 - val_accuracy: 0.4702\n","Epoch 39/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.3633 - accuracy: 0.4549\n","Epoch 39: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 11ms/step - loss: 1.3674 - accuracy: 0.4521 - val_loss: 1.3713 - val_accuracy: 0.4613\n","Epoch 40/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.3280 - accuracy: 0.4987\n","Epoch 40: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 11ms/step - loss: 1.3205 - accuracy: 0.4994 - val_loss: 1.4114 - val_accuracy: 0.4851\n","Epoch 41/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.2205 - accuracy: 0.5296\n","Epoch 41: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2515 - accuracy: 0.5185 - val_loss: 1.3779 - val_accuracy: 0.4881\n","Epoch 42/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.4036 - accuracy: 0.4702\n","Epoch 42: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 10ms/step - loss: 1.4152 - accuracy: 0.4674 - val_loss: 1.5540 - val_accuracy: 0.5476\n","Epoch 43/100\n","17/25 [===================>..........] - ETA: 0s - loss: 1.4473 - accuracy: 0.4743\n","Epoch 43: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 11ms/step - loss: 1.3707 - accuracy: 0.4981 - val_loss: 1.2234 - val_accuracy: 0.5655\n","Epoch 44/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2321 - accuracy: 0.5052\n","Epoch 44: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 11ms/step - loss: 1.2361 - accuracy: 0.5057 - val_loss: 1.3754 - val_accuracy: 0.5357\n","Epoch 45/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2194 - accuracy: 0.5479\n","Epoch 45: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 12ms/step - loss: 1.2194 - accuracy: 0.5479 - val_loss: 1.2249 - val_accuracy: 0.5625\n","Epoch 46/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.1799 - accuracy: 0.5297\n","Epoch 46: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2041 - accuracy: 0.5287 - val_loss: 1.2575 - val_accuracy: 0.5625\n","Epoch 47/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.1180 - accuracy: 0.5590\n","Epoch 47: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 9ms/step - loss: 1.1414 - accuracy: 0.5504 - val_loss: 1.6325 - val_accuracy: 0.3780\n","Epoch 48/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.5004 - accuracy: 0.4424\n","Epoch 48: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 10ms/step - loss: 1.4952 - accuracy: 0.4623 - val_loss: 1.5887 - val_accuracy: 0.5357\n","Epoch 49/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.3538 - accuracy: 0.5156\n","Epoch 49: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3214 - accuracy: 0.5198 - val_loss: 1.1949 - val_accuracy: 0.5595\n","Epoch 50/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.1603 - accuracy: 0.5493\n","Epoch 50: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 10ms/step - loss: 1.1730 - accuracy: 0.5530 - val_loss: 1.3498 - val_accuracy: 0.5446\n","Epoch 51/100\n","25/25 [==============================] - ETA: 0s - loss: 1.2185 - accuracy: 0.5377\n","Epoch 51: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2185 - accuracy: 0.5377 - val_loss: 1.2573 - val_accuracy: 0.5417\n","Epoch 52/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.2813 - accuracy: 0.5270\n","Epoch 52: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2622 - accuracy: 0.5364 - val_loss: 1.2083 - val_accuracy: 0.4881\n","Epoch 53/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.2891 - accuracy: 0.4880\n","Epoch 53: val_accuracy did not improve from 0.59524\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2148 - accuracy: 0.5223 - val_loss: 1.2101 - val_accuracy: 0.5714\n","15/15 [==============================] - 0s 3ms/step\n","0.5416666666666666\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["15/15 [==============================] - 0s 4ms/step - loss: 1.3489 - accuracy: 0.5042\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - ETA: 0s - loss: 2.7330 - accuracy: 0.2218\n","Epoch 1: val_accuracy improved from -inf to 0.28110, saving model to Har_tnn2.h5\n","46/46 [==============================] - 2s 15ms/step - loss: 2.7330 - accuracy: 0.2218 - val_loss: 2.1902 - val_accuracy: 0.2811\n","Epoch 2/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.7929 - accuracy: 0.3322\n","Epoch 2: val_accuracy improved from 0.28110 to 0.31341, saving model to Har_tnn2.h5\n","46/46 [==============================] - 0s 7ms/step - loss: 1.7589 - accuracy: 0.3264 - val_loss: 1.6017 - val_accuracy: 0.3134\n","Epoch 3/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.5494 - accuracy: 0.3285\n","Epoch 3: val_accuracy improved from 0.31341 to 0.33926, saving model to Har_tnn2.h5\n","46/46 [==============================] - 0s 6ms/step - loss: 1.5283 - accuracy: 0.3347 - val_loss: 1.5697 - val_accuracy: 0.3393\n","Epoch 4/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.3870 - accuracy: 0.3798\n","Epoch 4: val_accuracy improved from 0.33926 to 0.35864, saving model to Har_tnn2.h5\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3851 - accuracy: 0.3825 - val_loss: 1.4713 - val_accuracy: 0.3586\n","Epoch 5/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.3593 - accuracy: 0.3686\n","Epoch 5: val_accuracy improved from 0.35864 to 0.39418, saving model to Har_tnn2.h5\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3554 - accuracy: 0.3708 - val_loss: 1.3009 - val_accuracy: 0.3942\n","Epoch 6/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.3444 - accuracy: 0.3651\n","Epoch 6: val_accuracy did not improve from 0.39418\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3438 - accuracy: 0.3645 - val_loss: 1.3259 - val_accuracy: 0.3910\n","Epoch 7/100\n","42/46 [==========================>...] - ETA: 0s - loss: 1.3251 - accuracy: 0.3884\n","Epoch 7: val_accuracy did not improve from 0.39418\n","46/46 [==============================] - 0s 9ms/step - loss: 1.3304 - accuracy: 0.3805 - val_loss: 1.5016 - val_accuracy: 0.3441\n","Epoch 8/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3247 - accuracy: 0.3490\n","Epoch 8: val_accuracy did not improve from 0.39418\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3189 - accuracy: 0.3534 - val_loss: 1.4638 - val_accuracy: 0.3312\n","Epoch 9/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.4416 - accuracy: 0.3345\n","Epoch 9: val_accuracy did not improve from 0.39418\n","46/46 [==============================] - 0s 6ms/step - loss: 1.4212 - accuracy: 0.3465 - val_loss: 1.4350 - val_accuracy: 0.3409\n","Epoch 10/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.4521 - accuracy: 0.3438\n","Epoch 10: val_accuracy did not improve from 0.39418\n","46/46 [==============================] - 0s 7ms/step - loss: 1.4483 - accuracy: 0.3458 - val_loss: 1.3444 - val_accuracy: 0.3651\n","Epoch 11/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.4367 - accuracy: 0.3668\n","Epoch 11: val_accuracy did not improve from 0.39418\n","46/46 [==============================] - 0s 6ms/step - loss: 1.4282 - accuracy: 0.3742 - val_loss: 1.3181 - val_accuracy: 0.3845\n","Epoch 12/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.3332 - accuracy: 0.3729\n","Epoch 12: val_accuracy did not improve from 0.39418\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3321 - accuracy: 0.3735 - val_loss: 1.3034 - val_accuracy: 0.3942\n","Epoch 13/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2307 - accuracy: 0.3756\n","Epoch 13: val_accuracy did not improve from 0.39418\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2307 - accuracy: 0.3756 - val_loss: 1.2316 - val_accuracy: 0.3522\n","Epoch 14/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3659 - accuracy: 0.3646\n","Epoch 14: val_accuracy did not improve from 0.39418\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3590 - accuracy: 0.3749 - val_loss: 1.4364 - val_accuracy: 0.3376\n","Epoch 15/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.3805 - accuracy: 0.3931\n","Epoch 15: val_accuracy did not improve from 0.39418\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3644 - accuracy: 0.3936 - val_loss: 1.1734 - val_accuracy: 0.3845\n","Epoch 16/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.4200 - accuracy: 0.3651\n","Epoch 16: val_accuracy did not improve from 0.39418\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3959 - accuracy: 0.3701 - val_loss: 1.3596 - val_accuracy: 0.3570\n","Epoch 17/100\n","46/46 [==============================] - ETA: 0s - loss: 1.3271 - accuracy: 0.3624\n","Epoch 17: val_accuracy did not improve from 0.39418\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3271 - accuracy: 0.3624 - val_loss: 1.2686 - val_accuracy: 0.3877\n","Epoch 18/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.3277 - accuracy: 0.3536\n","Epoch 18: val_accuracy improved from 0.39418 to 0.39903, saving model to Har_tnn2.h5\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3169 - accuracy: 0.3562 - val_loss: 1.0997 - val_accuracy: 0.3990\n","Epoch 19/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3834 - accuracy: 0.3724\n","Epoch 19: val_accuracy did not improve from 0.39903\n","46/46 [==============================] - 0s 6ms/step - loss: 1.4107 - accuracy: 0.3611 - val_loss: 1.5390 - val_accuracy: 0.3086\n","Epoch 20/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.5650 - accuracy: 0.3333\n","Epoch 20: val_accuracy did not improve from 0.39903\n","46/46 [==============================] - 0s 6ms/step - loss: 1.5447 - accuracy: 0.3340 - val_loss: 1.2125 - val_accuracy: 0.3796\n","Epoch 21/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2855 - accuracy: 0.3498\n","Epoch 21: val_accuracy did not improve from 0.39903\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2945 - accuracy: 0.3465 - val_loss: 1.2665 - val_accuracy: 0.3651\n","Epoch 22/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.4039 - accuracy: 0.3944\n","Epoch 22: val_accuracy did not improve from 0.39903\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3894 - accuracy: 0.3860 - val_loss: 1.5944 - val_accuracy: 0.3570\n","Epoch 23/100\n","46/46 [==============================] - ETA: 0s - loss: 1.4778 - accuracy: 0.3763\n","Epoch 23: val_accuracy improved from 0.39903 to 0.40226, saving model to Har_tnn2.h5\n","46/46 [==============================] - 0s 11ms/step - loss: 1.4778 - accuracy: 0.3763 - val_loss: 1.3111 - val_accuracy: 0.4023\n","Epoch 24/100\n","43/46 [===========================>..] - ETA: 0s - loss: 1.3117 - accuracy: 0.3881\n","Epoch 24: val_accuracy improved from 0.40226 to 0.42811, saving model to Har_tnn2.h5\n","46/46 [==============================] - 1s 11ms/step - loss: 1.3124 - accuracy: 0.3881 - val_loss: 1.4476 - val_accuracy: 0.4281\n","Epoch 25/100\n","43/46 [===========================>..] - ETA: 0s - loss: 1.2968 - accuracy: 0.3852\n","Epoch 25: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2884 - accuracy: 0.3874 - val_loss: 1.1872 - val_accuracy: 0.3942\n","Epoch 26/100\n","41/46 [=========================>....] - ETA: 0s - loss: 1.2614 - accuracy: 0.3834\n","Epoch 26: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2759 - accuracy: 0.3714 - val_loss: 1.1857 - val_accuracy: 0.3748\n","Epoch 27/100\n","42/46 [==========================>...] - ETA: 0s - loss: 1.2613 - accuracy: 0.3862\n","Epoch 27: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2599 - accuracy: 0.3895 - val_loss: 1.2324 - val_accuracy: 0.3942\n","Epoch 28/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.2932 - accuracy: 0.3852\n","Epoch 28: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 9ms/step - loss: 1.3019 - accuracy: 0.3832 - val_loss: 1.1403 - val_accuracy: 0.4006\n","Epoch 29/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.1777 - accuracy: 0.4069\n","Epoch 29: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 9ms/step - loss: 1.1777 - accuracy: 0.4075 - val_loss: 1.3492 - val_accuracy: 0.3764\n","Epoch 30/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2697 - accuracy: 0.4030\n","Epoch 30: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 10ms/step - loss: 1.2703 - accuracy: 0.3971 - val_loss: 1.1759 - val_accuracy: 0.3732\n","Epoch 31/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2793 - accuracy: 0.3594\n","Epoch 31: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2845 - accuracy: 0.3604 - val_loss: 1.3813 - val_accuracy: 0.3700\n","Epoch 32/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3721 - accuracy: 0.3776\n","Epoch 32: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3731 - accuracy: 0.3853 - val_loss: 1.2546 - val_accuracy: 0.3829\n","Epoch 33/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.3398 - accuracy: 0.3743\n","Epoch 33: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3379 - accuracy: 0.3714 - val_loss: 1.2956 - val_accuracy: 0.3328\n","Epoch 34/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2680 - accuracy: 0.3826\n","Epoch 34: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2598 - accuracy: 0.3825 - val_loss: 1.2411 - val_accuracy: 0.3215\n","Epoch 35/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2564 - accuracy: 0.3701\n","Epoch 35: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2562 - accuracy: 0.3694 - val_loss: 1.1781 - val_accuracy: 0.4087\n","Epoch 36/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2957 - accuracy: 0.3594\n","Epoch 36: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3031 - accuracy: 0.3541 - val_loss: 1.2181 - val_accuracy: 0.3312\n","Epoch 37/100\n","46/46 [==============================] - ETA: 0s - loss: 1.3005 - accuracy: 0.3749\n","Epoch 37: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3005 - accuracy: 0.3749 - val_loss: 1.2324 - val_accuracy: 0.3651\n","Epoch 38/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.1748 - accuracy: 0.4198\n","Epoch 38: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2080 - accuracy: 0.4172 - val_loss: 1.2207 - val_accuracy: 0.3910\n","Epoch 39/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2409 - accuracy: 0.3819\n","Epoch 39: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2556 - accuracy: 0.3812 - val_loss: 1.4755 - val_accuracy: 0.3344\n","Epoch 40/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2727 - accuracy: 0.3889\n","Epoch 40: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2738 - accuracy: 0.3888 - val_loss: 1.4434 - val_accuracy: 0.3231\n","Epoch 41/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2567 - accuracy: 0.3632\n","Epoch 41: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2386 - accuracy: 0.3701 - val_loss: 1.0550 - val_accuracy: 0.4168\n","Epoch 42/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.1992 - accuracy: 0.3826\n","Epoch 42: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1947 - accuracy: 0.3832 - val_loss: 1.3327 - val_accuracy: 0.4006\n","Epoch 43/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2175 - accuracy: 0.3898\n","Epoch 43: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2255 - accuracy: 0.3895 - val_loss: 1.2025 - val_accuracy: 0.3829\n","Epoch 44/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2024 - accuracy: 0.4068\n","Epoch 44: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2024 - accuracy: 0.4068 - val_loss: 1.3103 - val_accuracy: 0.3813\n","28/28 [==============================] - 0s 3ms/step\n","0.3864406779661017\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["40/46 [=========================>....] - ETA: 0s - loss: 3.1520 - accuracy: 0.1750\n","Epoch 1: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 2s 20ms/step - loss: 3.0132 - accuracy: 0.1871 - val_loss: 1.9320 - val_accuracy: 0.2827\n","Epoch 2/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.7211 - accuracy: 0.2556\n","Epoch 2: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 8ms/step - loss: 1.7034 - accuracy: 0.2571 - val_loss: 1.5970 - val_accuracy: 0.1777\n","Epoch 3/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.5044 - accuracy: 0.3061\n","Epoch 3: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 9ms/step - loss: 1.4965 - accuracy: 0.3077 - val_loss: 1.3902 - val_accuracy: 0.3344\n","Epoch 4/100\n","42/46 [==========================>...] - ETA: 0s - loss: 1.4707 - accuracy: 0.3415\n","Epoch 4: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 10ms/step - loss: 1.4727 - accuracy: 0.3444 - val_loss: 1.7365 - val_accuracy: 0.3150\n","Epoch 5/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.4175 - accuracy: 0.3508\n","Epoch 5: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 7ms/step - loss: 1.4053 - accuracy: 0.3507 - val_loss: 1.2345 - val_accuracy: 0.3376\n","Epoch 6/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3565 - accuracy: 0.3819\n","Epoch 6: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3751 - accuracy: 0.3701 - val_loss: 1.9392 - val_accuracy: 0.3554\n","Epoch 7/100\n","46/46 [==============================] - ETA: 0s - loss: 1.3904 - accuracy: 0.3555\n","Epoch 7: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3904 - accuracy: 0.3555 - val_loss: 1.3085 - val_accuracy: 0.3376\n","Epoch 8/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2987 - accuracy: 0.3715\n","Epoch 8: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3187 - accuracy: 0.3597 - val_loss: 1.3058 - val_accuracy: 0.3441\n","Epoch 9/100\n","34/46 [=====================>........] - ETA: 0s - loss: 1.2862 - accuracy: 0.3934\n","Epoch 9: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2694 - accuracy: 0.3735 - val_loss: 1.1361 - val_accuracy: 0.3586\n","Epoch 10/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2265 - accuracy: 0.3500\n","Epoch 10: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2265 - accuracy: 0.3500 - val_loss: 1.1710 - val_accuracy: 0.3118\n","Epoch 11/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.2108 - accuracy: 0.3494\n","Epoch 11: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2060 - accuracy: 0.3493 - val_loss: 1.3407 - val_accuracy: 0.3700\n","Epoch 12/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2292 - accuracy: 0.3708\n","Epoch 12: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2196 - accuracy: 0.3818 - val_loss: 1.2383 - val_accuracy: 0.3328\n","Epoch 13/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2584 - accuracy: 0.3651\n","Epoch 13: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2597 - accuracy: 0.3631 - val_loss: 1.1293 - val_accuracy: 0.3586\n","Epoch 14/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2392 - accuracy: 0.3885\n","Epoch 14: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2507 - accuracy: 0.3902 - val_loss: 1.1140 - val_accuracy: 0.3893\n","Epoch 15/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2949 - accuracy: 0.3728\n","Epoch 15: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2949 - accuracy: 0.3728 - val_loss: 1.2456 - val_accuracy: 0.3279\n","Epoch 16/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2597 - accuracy: 0.3618\n","Epoch 16: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2892 - accuracy: 0.3617 - val_loss: 1.5433 - val_accuracy: 0.3700\n","Epoch 17/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2809 - accuracy: 0.3857\n","Epoch 17: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2673 - accuracy: 0.3867 - val_loss: 1.2847 - val_accuracy: 0.3942\n","Epoch 18/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2281 - accuracy: 0.3961\n","Epoch 18: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2306 - accuracy: 0.3860 - val_loss: 1.2239 - val_accuracy: 0.3586\n","Epoch 19/100\n","34/46 [=====================>........] - ETA: 0s - loss: 1.2557 - accuracy: 0.3778\n","Epoch 19: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2653 - accuracy: 0.3680 - val_loss: 1.3763 - val_accuracy: 0.3279\n","Epoch 20/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.3076 - accuracy: 0.3946\n","Epoch 20: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3323 - accuracy: 0.3791 - val_loss: 1.5347 - val_accuracy: 0.3586\n","Epoch 21/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.3914 - accuracy: 0.3614\n","Epoch 21: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3733 - accuracy: 0.3624 - val_loss: 1.1728 - val_accuracy: 0.3877\n","Epoch 22/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2607 - accuracy: 0.3565\n","Epoch 22: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2564 - accuracy: 0.3604 - val_loss: 1.3525 - val_accuracy: 0.3344\n","Epoch 23/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2273 - accuracy: 0.3514\n","Epoch 23: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2253 - accuracy: 0.3527 - val_loss: 1.2373 - val_accuracy: 0.3393\n","Epoch 24/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2506 - accuracy: 0.3808\n","Epoch 24: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2460 - accuracy: 0.3812 - val_loss: 1.1818 - val_accuracy: 0.3813\n","Epoch 25/100\n","34/46 [=====================>........] - ETA: 0s - loss: 1.2107 - accuracy: 0.3612\n","Epoch 25: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2203 - accuracy: 0.3597 - val_loss: 1.3056 - val_accuracy: 0.3279\n","Epoch 26/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.2774 - accuracy: 0.3470\n","Epoch 26: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2794 - accuracy: 0.3465 - val_loss: 1.4917 - val_accuracy: 0.3635\n","Epoch 27/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2624 - accuracy: 0.3625\n","Epoch 27: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2481 - accuracy: 0.3631 - val_loss: 1.9369 - val_accuracy: 0.3506\n","Epoch 28/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2405 - accuracy: 0.3750\n","Epoch 28: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2411 - accuracy: 0.3749 - val_loss: 1.3298 - val_accuracy: 0.3586\n","Epoch 29/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2379 - accuracy: 0.3758\n","Epoch 29: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2451 - accuracy: 0.3645 - val_loss: 1.2653 - val_accuracy: 0.3570\n","Epoch 30/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2797 - accuracy: 0.4075\n","Epoch 30: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2797 - accuracy: 0.4075 - val_loss: 1.3376 - val_accuracy: 0.3893\n","Epoch 31/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2785 - accuracy: 0.3899\n","Epoch 31: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2756 - accuracy: 0.3915 - val_loss: 1.3346 - val_accuracy: 0.3910\n","Epoch 32/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2203 - accuracy: 0.3950\n","Epoch 32: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2268 - accuracy: 0.3846 - val_loss: 1.3095 - val_accuracy: 0.3247\n","Epoch 33/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2795 - accuracy: 0.3661\n","Epoch 33: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2793 - accuracy: 0.3701 - val_loss: 1.0717 - val_accuracy: 0.4023\n","Epoch 34/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2454 - accuracy: 0.3729\n","Epoch 34: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2465 - accuracy: 0.3721 - val_loss: 1.4233 - val_accuracy: 0.4071\n","Epoch 35/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.3723 - accuracy: 0.3875\n","Epoch 35: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3720 - accuracy: 0.3825 - val_loss: 1.2412 - val_accuracy: 0.4216\n","Epoch 36/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2691 - accuracy: 0.3854\n","Epoch 36: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2654 - accuracy: 0.3832 - val_loss: 1.1386 - val_accuracy: 0.3910\n","Epoch 37/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.2505 - accuracy: 0.3812\n","Epoch 37: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 10ms/step - loss: 1.2836 - accuracy: 0.3763 - val_loss: 1.5955 - val_accuracy: 0.3231\n","Epoch 38/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.3582 - accuracy: 0.3798\n","Epoch 38: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 8ms/step - loss: 1.3322 - accuracy: 0.3943 - val_loss: 1.2258 - val_accuracy: 0.3296\n","Epoch 39/100\n","41/46 [=========================>....] - ETA: 0s - loss: 1.4102 - accuracy: 0.3811\n","Epoch 39: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 9ms/step - loss: 1.3919 - accuracy: 0.3895 - val_loss: 1.2463 - val_accuracy: 0.4023\n","Epoch 40/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2662 - accuracy: 0.4076\n","Epoch 40: val_accuracy did not improve from 0.42811\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2660 - accuracy: 0.4082 - val_loss: 1.5410 - val_accuracy: 0.3425\n","Epoch 41/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.3194 - accuracy: 0.3942\n","Epoch 41: val_accuracy improved from 0.42811 to 0.44426, saving model to Har_tnn2.h5\n","46/46 [==============================] - 0s 9ms/step - loss: 1.3234 - accuracy: 0.3985 - val_loss: 1.6877 - val_accuracy: 0.4443\n","Epoch 42/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.4050 - accuracy: 0.3910\n","Epoch 42: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 9ms/step - loss: 1.3881 - accuracy: 0.3832 - val_loss: 1.7796 - val_accuracy: 0.4006\n","Epoch 43/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.4395 - accuracy: 0.3790\n","Epoch 43: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 10ms/step - loss: 1.4136 - accuracy: 0.3846 - val_loss: 1.2218 - val_accuracy: 0.4200\n","Epoch 44/100\n","43/46 [===========================>..] - ETA: 0s - loss: 1.3183 - accuracy: 0.4092\n","Epoch 44: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 9ms/step - loss: 1.3148 - accuracy: 0.4096 - val_loss: 1.2742 - val_accuracy: 0.3877\n","Epoch 45/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.3120 - accuracy: 0.3894\n","Epoch 45: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 10ms/step - loss: 1.3180 - accuracy: 0.3929 - val_loss: 1.2109 - val_accuracy: 0.4071\n","Epoch 46/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.3533 - accuracy: 0.3786\n","Epoch 46: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3259 - accuracy: 0.3832 - val_loss: 1.2543 - val_accuracy: 0.3780\n","Epoch 47/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.2699 - accuracy: 0.3782\n","Epoch 47: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2676 - accuracy: 0.3708 - val_loss: 1.2316 - val_accuracy: 0.3457\n","Epoch 48/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.1885 - accuracy: 0.3872\n","Epoch 48: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2067 - accuracy: 0.3874 - val_loss: 1.1492 - val_accuracy: 0.3910\n","Epoch 49/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.4220 - accuracy: 0.3775\n","Epoch 49: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.4092 - accuracy: 0.3749 - val_loss: 1.1866 - val_accuracy: 0.3764\n","Epoch 50/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.4191 - accuracy: 0.3663\n","Epoch 50: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.4167 - accuracy: 0.3701 - val_loss: 1.1934 - val_accuracy: 0.4346\n","Epoch 51/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2859 - accuracy: 0.3993\n","Epoch 51: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2840 - accuracy: 0.3992 - val_loss: 1.3727 - val_accuracy: 0.3990\n","Epoch 52/100\n","46/46 [==============================] - ETA: 0s - loss: 1.3111 - accuracy: 0.3957\n","Epoch 52: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3111 - accuracy: 0.3957 - val_loss: 1.1317 - val_accuracy: 0.3700\n","Epoch 53/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2776 - accuracy: 0.3894\n","Epoch 53: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2503 - accuracy: 0.3929 - val_loss: 1.2165 - val_accuracy: 0.4136\n","Epoch 54/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2625 - accuracy: 0.3611\n","Epoch 54: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2728 - accuracy: 0.3666 - val_loss: 1.1406 - val_accuracy: 0.3732\n","Epoch 55/100\n","34/46 [=====================>........] - ETA: 0s - loss: 1.3103 - accuracy: 0.3989\n","Epoch 55: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2679 - accuracy: 0.4109 - val_loss: 1.1370 - val_accuracy: 0.4330\n","Epoch 56/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.2753 - accuracy: 0.4263\n","Epoch 56: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2685 - accuracy: 0.4213 - val_loss: 1.2118 - val_accuracy: 0.3635\n","Epoch 57/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.3746 - accuracy: 0.4071\n","Epoch 57: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3814 - accuracy: 0.4040 - val_loss: 1.3781 - val_accuracy: 0.3780\n","Epoch 58/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2664 - accuracy: 0.4040\n","Epoch 58: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2664 - accuracy: 0.4040 - val_loss: 1.2543 - val_accuracy: 0.3829\n","Epoch 59/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.3285 - accuracy: 0.3819\n","Epoch 59: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3277 - accuracy: 0.3825 - val_loss: 1.2658 - val_accuracy: 0.4378\n","Epoch 60/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2259 - accuracy: 0.4212\n","Epoch 60: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2313 - accuracy: 0.4227 - val_loss: 1.4518 - val_accuracy: 0.3796\n","Epoch 61/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2787 - accuracy: 0.3936\n","Epoch 61: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2635 - accuracy: 0.3950 - val_loss: 1.1473 - val_accuracy: 0.4410\n","28/28 [==============================] - 0s 3ms/step\n","0.43728813559322033\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["39/46 [========================>.....] - ETA: 0s - loss: 4.3430 - accuracy: 0.2412\n","Epoch 1: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 2s 13ms/step - loss: 4.0344 - accuracy: 0.2516 - val_loss: 1.8428 - val_accuracy: 0.3166\n","Epoch 2/100\n","41/46 [=========================>....] - ETA: 0s - loss: 1.4707 - accuracy: 0.3514\n","Epoch 2: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.4550 - accuracy: 0.3576 - val_loss: 1.2726 - val_accuracy: 0.3780\n","Epoch 3/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.3152 - accuracy: 0.3885\n","Epoch 3: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3234 - accuracy: 0.3825 - val_loss: 1.3629 - val_accuracy: 0.3489\n","Epoch 4/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.3080 - accuracy: 0.3830\n","Epoch 4: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3321 - accuracy: 0.3805 - val_loss: 1.2902 - val_accuracy: 0.3893\n","Epoch 5/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.3057 - accuracy: 0.3664\n","Epoch 5: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3152 - accuracy: 0.3742 - val_loss: 1.3107 - val_accuracy: 0.4071\n","Epoch 6/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2719 - accuracy: 0.3691\n","Epoch 6: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2787 - accuracy: 0.3631 - val_loss: 1.3796 - val_accuracy: 0.3554\n","Epoch 7/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2728 - accuracy: 0.3750\n","Epoch 7: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2805 - accuracy: 0.3728 - val_loss: 1.3220 - val_accuracy: 0.3570\n","Epoch 8/100\n","46/46 [==============================] - ETA: 0s - loss: 1.3953 - accuracy: 0.3569\n","Epoch 8: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3953 - accuracy: 0.3569 - val_loss: 1.2089 - val_accuracy: 0.4103\n","Epoch 9/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.2424 - accuracy: 0.3758\n","Epoch 9: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2664 - accuracy: 0.3812 - val_loss: 1.3222 - val_accuracy: 0.3683\n","Epoch 10/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.3128 - accuracy: 0.3821\n","Epoch 10: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3065 - accuracy: 0.3701 - val_loss: 1.5274 - val_accuracy: 0.3926\n","Epoch 11/100\n","46/46 [==============================] - ETA: 0s - loss: 1.3146 - accuracy: 0.3888\n","Epoch 11: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 9ms/step - loss: 1.3146 - accuracy: 0.3888 - val_loss: 1.3307 - val_accuracy: 0.4071\n","Epoch 12/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.2907 - accuracy: 0.3680\n","Epoch 12: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2764 - accuracy: 0.3784 - val_loss: 1.3600 - val_accuracy: 0.3279\n","Epoch 13/100\n","41/46 [=========================>....] - ETA: 0s - loss: 1.2736 - accuracy: 0.3880\n","Epoch 13: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2761 - accuracy: 0.3832 - val_loss: 1.1794 - val_accuracy: 0.3926\n","Epoch 14/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2412 - accuracy: 0.4169\n","Epoch 14: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2488 - accuracy: 0.4123 - val_loss: 1.2934 - val_accuracy: 0.3910\n","Epoch 15/100\n","42/46 [==========================>...] - ETA: 0s - loss: 1.2595 - accuracy: 0.3869\n","Epoch 15: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 10ms/step - loss: 1.2473 - accuracy: 0.3874 - val_loss: 1.1847 - val_accuracy: 0.3700\n","Epoch 16/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.3097 - accuracy: 0.3833\n","Epoch 16: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 10ms/step - loss: 1.3098 - accuracy: 0.3825 - val_loss: 1.2934 - val_accuracy: 0.3974\n","Epoch 17/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2426 - accuracy: 0.3999\n","Epoch 17: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2399 - accuracy: 0.4019 - val_loss: 1.2384 - val_accuracy: 0.3958\n","Epoch 18/100\n","41/46 [=========================>....] - ETA: 0s - loss: 1.2629 - accuracy: 0.3727\n","Epoch 18: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2562 - accuracy: 0.3749 - val_loss: 1.2004 - val_accuracy: 0.3619\n","Epoch 19/100\n","41/46 [=========================>....] - ETA: 0s - loss: 1.2864 - accuracy: 0.3689\n","Epoch 19: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2997 - accuracy: 0.3631 - val_loss: 1.3091 - val_accuracy: 0.3780\n","Epoch 20/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.3738 - accuracy: 0.3715\n","Epoch 20: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3721 - accuracy: 0.3721 - val_loss: 1.3271 - val_accuracy: 0.3910\n","Epoch 21/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.3978 - accuracy: 0.3961\n","Epoch 21: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3987 - accuracy: 0.3853 - val_loss: 1.1020 - val_accuracy: 0.4200\n","Epoch 22/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.2149 - accuracy: 0.4046\n","Epoch 22: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2335 - accuracy: 0.4019 - val_loss: 1.5270 - val_accuracy: 0.3780\n","Epoch 23/100\n","42/46 [==========================>...] - ETA: 0s - loss: 1.3797 - accuracy: 0.3981\n","Epoch 23: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3621 - accuracy: 0.3992 - val_loss: 1.4338 - val_accuracy: 0.3667\n","Epoch 24/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2254 - accuracy: 0.4309\n","Epoch 24: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2281 - accuracy: 0.4283 - val_loss: 1.3248 - val_accuracy: 0.3942\n","Epoch 25/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.3036 - accuracy: 0.4036\n","Epoch 25: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2966 - accuracy: 0.4075 - val_loss: 1.1992 - val_accuracy: 0.4265\n","Epoch 26/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.2138 - accuracy: 0.4078\n","Epoch 26: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2189 - accuracy: 0.4047 - val_loss: 1.2669 - val_accuracy: 0.3393\n","Epoch 27/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3681 - accuracy: 0.3811\n","Epoch 27: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3569 - accuracy: 0.3922 - val_loss: 1.4896 - val_accuracy: 0.3215\n","Epoch 28/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.3774 - accuracy: 0.3726\n","Epoch 28: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3502 - accuracy: 0.3777 - val_loss: 1.3994 - val_accuracy: 0.3893\n","Epoch 29/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2672 - accuracy: 0.4152\n","Epoch 29: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2518 - accuracy: 0.4012 - val_loss: 1.2139 - val_accuracy: 0.3716\n","Epoch 30/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.2136 - accuracy: 0.3984\n","Epoch 30: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2039 - accuracy: 0.4047 - val_loss: 1.1729 - val_accuracy: 0.4200\n","Epoch 31/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.1931 - accuracy: 0.4097\n","Epoch 31: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2270 - accuracy: 0.3999 - val_loss: 1.8244 - val_accuracy: 0.3506\n","Epoch 32/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2583 - accuracy: 0.4285\n","Epoch 32: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2460 - accuracy: 0.4283 - val_loss: 1.1875 - val_accuracy: 0.4055\n","Epoch 33/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2192 - accuracy: 0.4227\n","Epoch 33: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2266 - accuracy: 0.4241 - val_loss: 1.4037 - val_accuracy: 0.4216\n","Epoch 34/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2474 - accuracy: 0.4143\n","Epoch 34: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2489 - accuracy: 0.4019 - val_loss: 1.1648 - val_accuracy: 0.3635\n","Epoch 35/100\n","46/46 [==============================] - ETA: 0s - loss: 1.1790 - accuracy: 0.3992\n","Epoch 35: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 7ms/step - loss: 1.1790 - accuracy: 0.3992 - val_loss: 1.1675 - val_accuracy: 0.4313\n","Epoch 36/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2343 - accuracy: 0.4030\n","Epoch 36: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2444 - accuracy: 0.3985 - val_loss: 1.2342 - val_accuracy: 0.4055\n","Epoch 37/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2446 - accuracy: 0.3950\n","Epoch 37: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2200 - accuracy: 0.4123 - val_loss: 1.2425 - val_accuracy: 0.4330\n","Epoch 38/100\n","46/46 [==============================] - ETA: 0s - loss: 1.1945 - accuracy: 0.4026\n","Epoch 38: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1945 - accuracy: 0.4026 - val_loss: 1.2462 - val_accuracy: 0.3667\n","Epoch 39/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.1774 - accuracy: 0.4245\n","Epoch 39: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1963 - accuracy: 0.4186 - val_loss: 1.3606 - val_accuracy: 0.4006\n","Epoch 40/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.2754 - accuracy: 0.4087\n","Epoch 40: val_accuracy did not improve from 0.44426\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2749 - accuracy: 0.4109 - val_loss: 1.3959 - val_accuracy: 0.3716\n","Epoch 41/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2215 - accuracy: 0.3848\n","Epoch 41: val_accuracy improved from 0.44426 to 0.45073, saving model to Har_tnn2.h5\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2421 - accuracy: 0.3853 - val_loss: 1.1958 - val_accuracy: 0.4507\n","Epoch 42/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.2387 - accuracy: 0.3918\n","Epoch 42: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2454 - accuracy: 0.3846 - val_loss: 1.1970 - val_accuracy: 0.3990\n","Epoch 43/100\n","42/46 [==========================>...] - ETA: 0s - loss: 1.2500 - accuracy: 0.3832\n","Epoch 43: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2526 - accuracy: 0.3825 - val_loss: 1.2046 - val_accuracy: 0.4039\n","Epoch 44/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2287 - accuracy: 0.3929\n","Epoch 44: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2198 - accuracy: 0.3978 - val_loss: 1.0569 - val_accuracy: 0.3942\n","Epoch 45/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2682 - accuracy: 0.4020\n","Epoch 45: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2639 - accuracy: 0.4040 - val_loss: 1.3332 - val_accuracy: 0.3554\n","Epoch 46/100\n","42/46 [==========================>...] - ETA: 0s - loss: 1.3477 - accuracy: 0.3527\n","Epoch 46: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3519 - accuracy: 0.3548 - val_loss: 1.4163 - val_accuracy: 0.3538\n","Epoch 47/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3325 - accuracy: 0.3707\n","Epoch 47: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2947 - accuracy: 0.3867 - val_loss: 1.4352 - val_accuracy: 0.3554\n","Epoch 48/100\n","34/46 [=====================>........] - ETA: 0s - loss: 1.2458 - accuracy: 0.4173\n","Epoch 48: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2470 - accuracy: 0.4137 - val_loss: 1.3222 - val_accuracy: 0.3829\n","Epoch 49/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2267 - accuracy: 0.4183\n","Epoch 49: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2306 - accuracy: 0.4179 - val_loss: 1.2592 - val_accuracy: 0.4249\n","Epoch 50/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2146 - accuracy: 0.3882\n","Epoch 50: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2145 - accuracy: 0.3881 - val_loss: 1.1925 - val_accuracy: 0.4087\n","Epoch 51/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.1915 - accuracy: 0.4274\n","Epoch 51: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 8ms/step - loss: 1.1944 - accuracy: 0.4241 - val_loss: 1.1548 - val_accuracy: 0.3522\n","Epoch 52/100\n","41/46 [=========================>....] - ETA: 0s - loss: 1.1616 - accuracy: 0.4230\n","Epoch 52: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 10ms/step - loss: 1.1810 - accuracy: 0.4179 - val_loss: 1.1240 - val_accuracy: 0.3877\n","Epoch 53/100\n","42/46 [==========================>...] - ETA: 0s - loss: 1.3204 - accuracy: 0.3824\n","Epoch 53: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 10ms/step - loss: 1.3094 - accuracy: 0.3805 - val_loss: 1.2292 - val_accuracy: 0.3328\n","Epoch 54/100\n","46/46 [==============================] - ETA: 0s - loss: 1.3644 - accuracy: 0.3839\n","Epoch 54: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 10ms/step - loss: 1.3644 - accuracy: 0.3839 - val_loss: 1.4608 - val_accuracy: 0.3263\n","Epoch 55/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.4093 - accuracy: 0.3764\n","Epoch 55: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 9ms/step - loss: 1.4087 - accuracy: 0.3763 - val_loss: 1.2993 - val_accuracy: 0.3635\n","Epoch 56/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2821 - accuracy: 0.4013\n","Epoch 56: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2789 - accuracy: 0.4019 - val_loss: 1.1282 - val_accuracy: 0.4136\n","Epoch 57/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.1649 - accuracy: 0.4079\n","Epoch 57: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 10ms/step - loss: 1.1699 - accuracy: 0.4019 - val_loss: 1.2545 - val_accuracy: 0.4443\n","Epoch 58/100\n","46/46 [==============================] - ETA: 0s - loss: 1.1988 - accuracy: 0.3936\n","Epoch 58: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 10ms/step - loss: 1.1988 - accuracy: 0.3936 - val_loss: 1.1709 - val_accuracy: 0.3877\n","Epoch 59/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.3025 - accuracy: 0.4000\n","Epoch 59: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 10ms/step - loss: 1.3159 - accuracy: 0.3853 - val_loss: 1.3151 - val_accuracy: 0.3958\n","Epoch 60/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.1899 - accuracy: 0.3734\n","Epoch 60: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2069 - accuracy: 0.3791 - val_loss: 1.3818 - val_accuracy: 0.4426\n","Epoch 61/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2541 - accuracy: 0.4019\n","Epoch 61: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2613 - accuracy: 0.4026 - val_loss: 1.1377 - val_accuracy: 0.3861\n","28/28 [==============================] - 0s 3ms/step\n","0.4542372881355932\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["35/46 [=====================>........] - ETA: 0s - loss: 5.2387 - accuracy: 0.1411\n","Epoch 1: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 2s 13ms/step - loss: 4.7514 - accuracy: 0.1733 - val_loss: 3.2315 - val_accuracy: 0.3086\n","Epoch 2/100\n","35/46 [=====================>........] - ETA: 0s - loss: 2.6058 - accuracy: 0.2714\n","Epoch 2: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 2.4301 - accuracy: 0.2911 - val_loss: 1.4079 - val_accuracy: 0.3683\n","Epoch 3/100\n","41/46 [=========================>....] - ETA: 0s - loss: 1.5428 - accuracy: 0.3415\n","Epoch 3: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.5274 - accuracy: 0.3416 - val_loss: 2.2014 - val_accuracy: 0.3360\n","Epoch 4/100\n","41/46 [=========================>....] - ETA: 0s - loss: 1.4047 - accuracy: 0.3712\n","Epoch 4: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3946 - accuracy: 0.3735 - val_loss: 1.2640 - val_accuracy: 0.3877\n","Epoch 5/100\n","46/46 [==============================] - ETA: 0s - loss: 1.3082 - accuracy: 0.3680\n","Epoch 5: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3082 - accuracy: 0.3680 - val_loss: 1.2094 - val_accuracy: 0.3813\n","Epoch 6/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3024 - accuracy: 0.3655\n","Epoch 6: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2730 - accuracy: 0.3701 - val_loss: 1.2568 - val_accuracy: 0.4168\n","Epoch 7/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2213 - accuracy: 0.3607\n","Epoch 7: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.3784 - val_loss: 1.2465 - val_accuracy: 0.3942\n","Epoch 8/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2794 - accuracy: 0.3857\n","Epoch 8: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2787 - accuracy: 0.3881 - val_loss: 1.4114 - val_accuracy: 0.3619\n","Epoch 9/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2238 - accuracy: 0.3698\n","Epoch 9: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2306 - accuracy: 0.3749 - val_loss: 1.1940 - val_accuracy: 0.3683\n","Epoch 10/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.3232 - accuracy: 0.4009\n","Epoch 10: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3095 - accuracy: 0.3964 - val_loss: 1.2377 - val_accuracy: 0.4103\n","Epoch 11/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2404 - accuracy: 0.3799\n","Epoch 11: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2763 - accuracy: 0.3798 - val_loss: 1.2406 - val_accuracy: 0.3877\n","Epoch 12/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2204 - accuracy: 0.3993\n","Epoch 12: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2049 - accuracy: 0.4040 - val_loss: 1.4055 - val_accuracy: 0.3877\n","Epoch 13/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.1691 - accuracy: 0.3758\n","Epoch 13: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1765 - accuracy: 0.3735 - val_loss: 1.2032 - val_accuracy: 0.3409\n","Epoch 14/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2019 - accuracy: 0.3734\n","Epoch 14: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2074 - accuracy: 0.3701 - val_loss: 1.1293 - val_accuracy: 0.3910\n","Epoch 15/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.1679 - accuracy: 0.4062\n","Epoch 15: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1766 - accuracy: 0.4061 - val_loss: 1.1900 - val_accuracy: 0.3409\n","Epoch 16/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.1915 - accuracy: 0.3824\n","Epoch 16: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1793 - accuracy: 0.3895 - val_loss: 1.1620 - val_accuracy: 0.3376\n","Epoch 17/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.1791 - accuracy: 0.4030\n","Epoch 17: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1778 - accuracy: 0.4054 - val_loss: 1.1895 - val_accuracy: 0.3473\n","Epoch 18/100\n","34/46 [=====================>........] - ETA: 0s - loss: 1.1689 - accuracy: 0.4164\n","Epoch 18: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1805 - accuracy: 0.4012 - val_loss: 1.3313 - val_accuracy: 0.3441\n","Epoch 19/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.1786 - accuracy: 0.3778\n","Epoch 19: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 7ms/step - loss: 1.1781 - accuracy: 0.3784 - val_loss: 1.3789 - val_accuracy: 0.4184\n","Epoch 20/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2640 - accuracy: 0.3767\n","Epoch 20: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2650 - accuracy: 0.3708 - val_loss: 1.2552 - val_accuracy: 0.3473\n","Epoch 21/100\n","34/46 [=====================>........] - ETA: 0s - loss: 1.2640 - accuracy: 0.3842\n","Epoch 21: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2736 - accuracy: 0.3846 - val_loss: 1.3015 - val_accuracy: 0.3861\n","Epoch 22/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.4135 - accuracy: 0.3598\n","Epoch 22: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.4185 - accuracy: 0.3548 - val_loss: 1.5564 - val_accuracy: 0.3877\n","Epoch 23/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.2819 - accuracy: 0.3812\n","Epoch 23: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2618 - accuracy: 0.3763 - val_loss: 1.2808 - val_accuracy: 0.3441\n","Epoch 24/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.1741 - accuracy: 0.3972\n","Epoch 24: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1665 - accuracy: 0.3971 - val_loss: 1.1727 - val_accuracy: 0.3716\n","Epoch 25/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2314 - accuracy: 0.3717\n","Epoch 25: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2230 - accuracy: 0.3818 - val_loss: 1.1443 - val_accuracy: 0.4200\n","Epoch 26/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.1643 - accuracy: 0.4358\n","Epoch 26: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 8ms/step - loss: 1.1638 - accuracy: 0.4359 - val_loss: 1.3239 - val_accuracy: 0.4071\n","Epoch 27/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2106 - accuracy: 0.3972\n","Epoch 27: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2096 - accuracy: 0.3971 - val_loss: 1.3066 - val_accuracy: 0.3974\n","Epoch 28/100\n","41/46 [=========================>....] - ETA: 0s - loss: 1.2066 - accuracy: 0.4002\n","Epoch 28: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 11ms/step - loss: 1.2122 - accuracy: 0.3978 - val_loss: 1.1017 - val_accuracy: 0.4071\n","Epoch 29/100\n","42/46 [==========================>...] - ETA: 0s - loss: 1.1757 - accuracy: 0.3876\n","Epoch 29: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 11ms/step - loss: 1.1821 - accuracy: 0.3832 - val_loss: 1.2252 - val_accuracy: 0.3748\n","Epoch 30/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.1477 - accuracy: 0.4006\n","Epoch 30: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 8ms/step - loss: 1.1477 - accuracy: 0.4012 - val_loss: 1.1160 - val_accuracy: 0.4346\n","Epoch 31/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.1654 - accuracy: 0.4158\n","Epoch 31: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 8ms/step - loss: 1.1639 - accuracy: 0.4262 - val_loss: 1.2081 - val_accuracy: 0.4443\n","Epoch 32/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.1934 - accuracy: 0.4276\n","Epoch 32: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 9ms/step - loss: 1.1884 - accuracy: 0.4255 - val_loss: 1.2124 - val_accuracy: 0.3667\n","Epoch 33/100\n","42/46 [==========================>...] - ETA: 0s - loss: 1.2028 - accuracy: 0.3824\n","Epoch 33: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 10ms/step - loss: 1.1883 - accuracy: 0.3881 - val_loss: 1.3596 - val_accuracy: 0.3473\n","Epoch 34/100\n","42/46 [==========================>...] - ETA: 0s - loss: 1.2124 - accuracy: 0.3943\n","Epoch 34: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 9ms/step - loss: 1.1976 - accuracy: 0.3985 - val_loss: 1.2435 - val_accuracy: 0.4330\n","Epoch 35/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.2149 - accuracy: 0.4038\n","Epoch 35: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2072 - accuracy: 0.3999 - val_loss: 1.3676 - val_accuracy: 0.4039\n","Epoch 36/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2179 - accuracy: 0.3696\n","Epoch 36: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1996 - accuracy: 0.3749 - val_loss: 1.2521 - val_accuracy: 0.3845\n","Epoch 37/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.1921 - accuracy: 0.3759\n","Epoch 37: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1683 - accuracy: 0.3735 - val_loss: 1.1267 - val_accuracy: 0.3603\n","Epoch 38/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.1916 - accuracy: 0.3882\n","Epoch 38: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2116 - accuracy: 0.3881 - val_loss: 1.3385 - val_accuracy: 0.3199\n","Epoch 39/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.1582 - accuracy: 0.3911\n","Epoch 39: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1628 - accuracy: 0.3936 - val_loss: 1.1088 - val_accuracy: 0.3748\n","Epoch 40/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2080 - accuracy: 0.3941\n","Epoch 40: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2003 - accuracy: 0.3950 - val_loss: 1.1586 - val_accuracy: 0.3215\n","Epoch 41/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.1550 - accuracy: 0.3944\n","Epoch 41: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1484 - accuracy: 0.3978 - val_loss: 1.2951 - val_accuracy: 0.3845\n","Epoch 42/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2276 - accuracy: 0.4132\n","Epoch 42: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2492 - accuracy: 0.4109 - val_loss: 1.3641 - val_accuracy: 0.4055\n","Epoch 43/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2193 - accuracy: 0.3972\n","Epoch 43: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2195 - accuracy: 0.3971 - val_loss: 1.0878 - val_accuracy: 0.3716\n","Epoch 44/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2374 - accuracy: 0.4009\n","Epoch 44: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2326 - accuracy: 0.4040 - val_loss: 1.3261 - val_accuracy: 0.3312\n","Epoch 45/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2180 - accuracy: 0.3724\n","Epoch 45: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2429 - accuracy: 0.3687 - val_loss: 1.1396 - val_accuracy: 0.3748\n","Epoch 46/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.1888 - accuracy: 0.3875\n","Epoch 46: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 7ms/step - loss: 1.1888 - accuracy: 0.3874 - val_loss: 1.0476 - val_accuracy: 0.3845\n","Epoch 47/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2269 - accuracy: 0.4088\n","Epoch 47: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2240 - accuracy: 0.4006 - val_loss: 1.2699 - val_accuracy: 0.3861\n","Epoch 48/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2442 - accuracy: 0.3893\n","Epoch 48: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2481 - accuracy: 0.3784 - val_loss: 1.2054 - val_accuracy: 0.3926\n","Epoch 49/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2062 - accuracy: 0.3667\n","Epoch 49: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2058 - accuracy: 0.3673 - val_loss: 1.0626 - val_accuracy: 0.3829\n","Epoch 50/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.1035 - accuracy: 0.4089\n","Epoch 50: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1217 - accuracy: 0.4123 - val_loss: 1.2090 - val_accuracy: 0.3990\n","Epoch 51/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.3119 - accuracy: 0.3534\n","Epoch 51: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2949 - accuracy: 0.3604 - val_loss: 1.2072 - val_accuracy: 0.4297\n","28/28 [==============================] - 0s 3ms/step\n","0.4542372881355932\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["42/46 [==========================>...] - ETA: 0s - loss: 2.1917 - accuracy: 0.2760\n","Epoch 1: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 2s 21ms/step - loss: 2.1473 - accuracy: 0.2814 - val_loss: 1.6635 - val_accuracy: 0.3279\n","Epoch 2/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.5791 - accuracy: 0.3205\n","Epoch 2: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 8ms/step - loss: 1.5821 - accuracy: 0.3285 - val_loss: 1.4019 - val_accuracy: 0.3328\n","Epoch 3/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.5812 - accuracy: 0.3438\n","Epoch 3: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 10ms/step - loss: 1.5374 - accuracy: 0.3500 - val_loss: 1.6034 - val_accuracy: 0.3700\n","Epoch 4/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.3920 - accuracy: 0.3842\n","Epoch 4: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 9ms/step - loss: 1.4030 - accuracy: 0.3798 - val_loss: 1.3329 - val_accuracy: 0.3893\n","Epoch 5/100\n","46/46 [==============================] - ETA: 0s - loss: 1.3781 - accuracy: 0.3943\n","Epoch 5: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 10ms/step - loss: 1.3781 - accuracy: 0.3943 - val_loss: 1.3894 - val_accuracy: 0.4039\n","Epoch 6/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.4292 - accuracy: 0.4155\n","Epoch 6: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 8ms/step - loss: 1.4048 - accuracy: 0.4109 - val_loss: 1.2331 - val_accuracy: 0.4297\n","Epoch 7/100\n","46/46 [==============================] - ETA: 0s - loss: 1.3014 - accuracy: 0.4019\n","Epoch 7: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3014 - accuracy: 0.4019 - val_loss: 1.2791 - val_accuracy: 0.4297\n","Epoch 8/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3225 - accuracy: 0.3898\n","Epoch 8: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3122 - accuracy: 0.3957 - val_loss: 1.2822 - val_accuracy: 0.4216\n","Epoch 9/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.3750 - accuracy: 0.3982\n","Epoch 9: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3596 - accuracy: 0.3978 - val_loss: 1.2672 - val_accuracy: 0.3861\n","Epoch 10/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.4094 - accuracy: 0.3674\n","Epoch 10: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3969 - accuracy: 0.3742 - val_loss: 1.3392 - val_accuracy: 0.3651\n","Epoch 11/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2685 - accuracy: 0.4223\n","Epoch 11: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2936 - accuracy: 0.4137 - val_loss: 1.2310 - val_accuracy: 0.4039\n","Epoch 12/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3305 - accuracy: 0.3750\n","Epoch 12: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3263 - accuracy: 0.3839 - val_loss: 1.2828 - val_accuracy: 0.4297\n","Epoch 13/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2571 - accuracy: 0.4071\n","Epoch 13: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2884 - accuracy: 0.3943 - val_loss: 1.2759 - val_accuracy: 0.3716\n","Epoch 14/100\n","43/46 [===========================>..] - ETA: 0s - loss: 1.2459 - accuracy: 0.4215\n","Epoch 14: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2399 - accuracy: 0.4207 - val_loss: 1.1244 - val_accuracy: 0.3716\n","Epoch 15/100\n","34/46 [=====================>........] - ETA: 0s - loss: 1.1665 - accuracy: 0.3961\n","Epoch 15: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 7ms/step - loss: 1.1691 - accuracy: 0.3825 - val_loss: 1.3339 - val_accuracy: 0.4378\n","Epoch 16/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.1685 - accuracy: 0.4268\n","Epoch 16: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1750 - accuracy: 0.4089 - val_loss: 1.4640 - val_accuracy: 0.3700\n","Epoch 17/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.3917 - accuracy: 0.4005\n","Epoch 17: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3856 - accuracy: 0.3902 - val_loss: 1.2635 - val_accuracy: 0.3716\n","Epoch 18/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2847 - accuracy: 0.3708\n","Epoch 18: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2847 - accuracy: 0.3708 - val_loss: 1.2284 - val_accuracy: 0.4281\n","Epoch 19/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.1099 - accuracy: 0.4279\n","Epoch 19: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1306 - accuracy: 0.4248 - val_loss: 1.2051 - val_accuracy: 0.3522\n","Epoch 20/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2507 - accuracy: 0.3793\n","Epoch 20: val_accuracy did not improve from 0.45073\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2364 - accuracy: 0.3860 - val_loss: 1.1741 - val_accuracy: 0.3603\n","Epoch 21/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2248 - accuracy: 0.3929\n","Epoch 21: val_accuracy improved from 0.45073 to 0.45396, saving model to Har_tnn2.h5\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2248 - accuracy: 0.3929 - val_loss: 1.1964 - val_accuracy: 0.4540\n","Epoch 22/100\n","34/46 [=====================>........] - ETA: 0s - loss: 1.2284 - accuracy: 0.4044\n","Epoch 22: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2246 - accuracy: 0.3929 - val_loss: 1.1772 - val_accuracy: 0.3700\n","Epoch 23/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2123 - accuracy: 0.3970\n","Epoch 23: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2330 - accuracy: 0.3922 - val_loss: 1.3709 - val_accuracy: 0.4023\n","Epoch 24/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2952 - accuracy: 0.4020\n","Epoch 24: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3123 - accuracy: 0.3915 - val_loss: 1.2333 - val_accuracy: 0.4055\n","Epoch 25/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2762 - accuracy: 0.3816\n","Epoch 25: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2563 - accuracy: 0.3867 - val_loss: 1.1120 - val_accuracy: 0.4039\n","Epoch 26/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.1948 - accuracy: 0.3927\n","Epoch 26: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2063 - accuracy: 0.3915 - val_loss: 1.1335 - val_accuracy: 0.4297\n","Epoch 27/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.2659 - accuracy: 0.3734\n","Epoch 27: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2586 - accuracy: 0.3749 - val_loss: 1.2491 - val_accuracy: 0.3764\n","Epoch 28/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2487 - accuracy: 0.3741\n","Epoch 28: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2384 - accuracy: 0.3874 - val_loss: 1.4961 - val_accuracy: 0.3700\n","Epoch 29/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2885 - accuracy: 0.3853\n","Epoch 29: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2885 - accuracy: 0.3853 - val_loss: 1.3393 - val_accuracy: 0.3603\n","Epoch 30/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.3264 - accuracy: 0.4000\n","Epoch 30: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3190 - accuracy: 0.3964 - val_loss: 1.4214 - val_accuracy: 0.3247\n","Epoch 31/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2738 - accuracy: 0.3777\n","Epoch 31: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2877 - accuracy: 0.3763 - val_loss: 1.1514 - val_accuracy: 0.3360\n","Epoch 32/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2713 - accuracy: 0.3611\n","Epoch 32: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2713 - accuracy: 0.3611 - val_loss: 1.2390 - val_accuracy: 0.3926\n","Epoch 33/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2508 - accuracy: 0.3732\n","Epoch 33: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2490 - accuracy: 0.3784 - val_loss: 1.2538 - val_accuracy: 0.3700\n","Epoch 34/100\n","46/46 [==============================] - ETA: 0s - loss: 1.3003 - accuracy: 0.3909\n","Epoch 34: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3003 - accuracy: 0.3909 - val_loss: 1.1583 - val_accuracy: 0.3570\n","Epoch 35/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2094 - accuracy: 0.3722\n","Epoch 35: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2087 - accuracy: 0.3721 - val_loss: 1.1638 - val_accuracy: 0.4023\n","Epoch 36/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.4018 - accuracy: 0.3732\n","Epoch 36: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3627 - accuracy: 0.3742 - val_loss: 1.2922 - val_accuracy: 0.3764\n","Epoch 37/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2085 - accuracy: 0.3812\n","Epoch 37: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2085 - accuracy: 0.3812 - val_loss: 1.1290 - val_accuracy: 0.3877\n","Epoch 38/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2970 - accuracy: 0.3849\n","Epoch 38: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2930 - accuracy: 0.3825 - val_loss: 1.3553 - val_accuracy: 0.3942\n","Epoch 39/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.3429 - accuracy: 0.3846\n","Epoch 39: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.3367 - accuracy: 0.3874 - val_loss: 1.3996 - val_accuracy: 0.3796\n","Epoch 40/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.2952 - accuracy: 0.3945\n","Epoch 40: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2950 - accuracy: 0.3957 - val_loss: 1.1403 - val_accuracy: 0.3732\n","Epoch 41/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.2167 - accuracy: 0.4062\n","Epoch 41: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 11ms/step - loss: 1.2159 - accuracy: 0.4068 - val_loss: 1.2311 - val_accuracy: 0.3360\n","28/28 [==============================] - 0s 3ms/step\n","0.4090395480225989\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["46/46 [==============================] - ETA: 0s - loss: 2.8228 - accuracy: 0.3008\n","Epoch 1: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 2s 15ms/step - loss: 2.8228 - accuracy: 0.3008 - val_loss: 1.6969 - val_accuracy: 0.3522\n","Epoch 2/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.5362 - accuracy: 0.3607\n","Epoch 2: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.5133 - accuracy: 0.3631 - val_loss: 1.2997 - val_accuracy: 0.3603\n","Epoch 3/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.3766 - accuracy: 0.4046\n","Epoch 3: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3798 - accuracy: 0.4061 - val_loss: 1.3223 - val_accuracy: 0.3974\n","Epoch 4/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.3186 - accuracy: 0.4021\n","Epoch 4: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3176 - accuracy: 0.3929 - val_loss: 1.3467 - val_accuracy: 0.4023\n","Epoch 5/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.3480 - accuracy: 0.3939\n","Epoch 5: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3258 - accuracy: 0.3978 - val_loss: 1.2325 - val_accuracy: 0.4443\n","Epoch 6/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.3008 - accuracy: 0.4304\n","Epoch 6: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3330 - accuracy: 0.4276 - val_loss: 1.4815 - val_accuracy: 0.4313\n","Epoch 7/100\n","34/46 [=====================>........] - ETA: 0s - loss: 1.3623 - accuracy: 0.4210\n","Epoch 7: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3553 - accuracy: 0.4075 - val_loss: 1.1648 - val_accuracy: 0.3845\n","Epoch 8/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.3480 - accuracy: 0.4172\n","Epoch 8: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3693 - accuracy: 0.4172 - val_loss: 1.1439 - val_accuracy: 0.3829\n","Epoch 9/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.3765 - accuracy: 0.3758\n","Epoch 9: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3513 - accuracy: 0.3860 - val_loss: 1.1980 - val_accuracy: 0.3748\n","Epoch 10/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2271 - accuracy: 0.4098\n","Epoch 10: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2324 - accuracy: 0.3992 - val_loss: 1.1528 - val_accuracy: 0.4152\n","Epoch 11/100\n","43/46 [===========================>..] - ETA: 0s - loss: 1.2792 - accuracy: 0.4070\n","Epoch 11: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2724 - accuracy: 0.4103 - val_loss: 1.1214 - val_accuracy: 0.3764\n","Epoch 12/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.2960 - accuracy: 0.3922\n","Epoch 12: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2732 - accuracy: 0.3853 - val_loss: 1.1126 - val_accuracy: 0.3974\n","Epoch 13/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2772 - accuracy: 0.3964\n","Epoch 13: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 10ms/step - loss: 1.2772 - accuracy: 0.3964 - val_loss: 1.3944 - val_accuracy: 0.3845\n","Epoch 14/100\n","42/46 [==========================>...] - ETA: 0s - loss: 1.3273 - accuracy: 0.3906\n","Epoch 14: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 11ms/step - loss: 1.3421 - accuracy: 0.3888 - val_loss: 1.4171 - val_accuracy: 0.4103\n","Epoch 15/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.3456 - accuracy: 0.3934\n","Epoch 15: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 10ms/step - loss: 1.3157 - accuracy: 0.3985 - val_loss: 1.2864 - val_accuracy: 0.3893\n","Epoch 16/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.3133 - accuracy: 0.3998\n","Epoch 16: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 10ms/step - loss: 1.2965 - accuracy: 0.4082 - val_loss: 1.1964 - val_accuracy: 0.3683\n","Epoch 17/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2840 - accuracy: 0.4079\n","Epoch 17: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 10ms/step - loss: 1.3001 - accuracy: 0.4089 - val_loss: 1.1810 - val_accuracy: 0.3926\n","Epoch 18/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2616 - accuracy: 0.3875\n","Epoch 18: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2620 - accuracy: 0.3874 - val_loss: 1.1636 - val_accuracy: 0.3910\n","Epoch 19/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2424 - accuracy: 0.4071\n","Epoch 19: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2490 - accuracy: 0.4033 - val_loss: 1.1939 - val_accuracy: 0.3619\n","Epoch 20/100\n","42/46 [==========================>...] - ETA: 0s - loss: 1.2190 - accuracy: 0.3936\n","Epoch 20: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2211 - accuracy: 0.3950 - val_loss: 1.3137 - val_accuracy: 0.3554\n","Epoch 21/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2054 - accuracy: 0.4089\n","Epoch 21: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2111 - accuracy: 0.4033 - val_loss: 1.1148 - val_accuracy: 0.4184\n","Epoch 22/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2043 - accuracy: 0.4107\n","Epoch 22: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2182 - accuracy: 0.4019 - val_loss: 1.4016 - val_accuracy: 0.3748\n","Epoch 23/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2595 - accuracy: 0.3828\n","Epoch 23: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2518 - accuracy: 0.3867 - val_loss: 1.1625 - val_accuracy: 0.3942\n","Epoch 24/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2955 - accuracy: 0.4206\n","Epoch 24: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2610 - accuracy: 0.4255 - val_loss: 1.1471 - val_accuracy: 0.4394\n","Epoch 25/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2466 - accuracy: 0.3995\n","Epoch 25: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2421 - accuracy: 0.4026 - val_loss: 1.3499 - val_accuracy: 0.4071\n","28/28 [==============================] - 0s 3ms/step\n","0.4497175141242938\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["40/46 [=========================>....] - ETA: 0s - loss: 4.5247 - accuracy: 0.1023\n","Epoch 1: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 2s 15ms/step - loss: 4.2739 - accuracy: 0.1060 - val_loss: 2.4446 - val_accuracy: 0.2342\n","Epoch 2/100\n","36/46 [======================>.......] - ETA: 0s - loss: 2.1516 - accuracy: 0.2839\n","Epoch 2: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 2.1237 - accuracy: 0.2696 - val_loss: 1.6886 - val_accuracy: 0.3376\n","Epoch 3/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.5464 - accuracy: 0.3886\n","Epoch 3: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.5211 - accuracy: 0.3867 - val_loss: 1.3430 - val_accuracy: 0.3748\n","Epoch 4/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.4171 - accuracy: 0.3922\n","Epoch 4: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.4039 - accuracy: 0.3874 - val_loss: 1.3226 - val_accuracy: 0.3796\n","Epoch 5/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.4740 - accuracy: 0.3716\n","Epoch 5: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.4645 - accuracy: 0.3728 - val_loss: 1.3142 - val_accuracy: 0.3780\n","Epoch 6/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.3215 - accuracy: 0.3842\n","Epoch 6: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3197 - accuracy: 0.3832 - val_loss: 1.2412 - val_accuracy: 0.3780\n","Epoch 7/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3058 - accuracy: 0.3672\n","Epoch 7: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3113 - accuracy: 0.3631 - val_loss: 1.4491 - val_accuracy: 0.3683\n","Epoch 8/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.3713 - accuracy: 0.3495\n","Epoch 8: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.3611 - accuracy: 0.3507 - val_loss: 1.4214 - val_accuracy: 0.3586\n","Epoch 9/100\n","46/46 [==============================] - ETA: 0s - loss: 1.3164 - accuracy: 0.3687\n","Epoch 9: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3164 - accuracy: 0.3687 - val_loss: 1.2613 - val_accuracy: 0.3700\n","Epoch 10/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3454 - accuracy: 0.3724\n","Epoch 10: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3462 - accuracy: 0.3742 - val_loss: 1.2226 - val_accuracy: 0.3813\n","Epoch 11/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2794 - accuracy: 0.3843\n","Epoch 11: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2703 - accuracy: 0.3839 - val_loss: 1.3504 - val_accuracy: 0.3651\n","Epoch 12/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.3277 - accuracy: 0.3643\n","Epoch 12: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3124 - accuracy: 0.3770 - val_loss: 1.2924 - val_accuracy: 0.3215\n","Epoch 13/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.3092 - accuracy: 0.3573\n","Epoch 13: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3066 - accuracy: 0.3652 - val_loss: 1.2502 - val_accuracy: 0.3813\n","Epoch 14/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2003 - accuracy: 0.4054\n","Epoch 14: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1826 - accuracy: 0.4109 - val_loss: 1.2206 - val_accuracy: 0.3667\n","Epoch 15/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2506 - accuracy: 0.4141\n","Epoch 15: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2360 - accuracy: 0.4109 - val_loss: 1.3596 - val_accuracy: 0.4055\n","Epoch 16/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2275 - accuracy: 0.3976\n","Epoch 16: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2166 - accuracy: 0.3818 - val_loss: 1.2056 - val_accuracy: 0.4120\n","Epoch 17/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.1707 - accuracy: 0.4038\n","Epoch 17: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1915 - accuracy: 0.3978 - val_loss: 1.3104 - val_accuracy: 0.4120\n","Epoch 18/100\n","41/46 [=========================>....] - ETA: 0s - loss: 1.2064 - accuracy: 0.3918\n","Epoch 18: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2055 - accuracy: 0.3888 - val_loss: 1.2083 - val_accuracy: 0.3764\n","Epoch 19/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.1877 - accuracy: 0.3784\n","Epoch 19: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2079 - accuracy: 0.3812 - val_loss: 1.3554 - val_accuracy: 0.3506\n","Epoch 20/100\n","41/46 [=========================>....] - ETA: 0s - loss: 1.2478 - accuracy: 0.3735\n","Epoch 20: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2395 - accuracy: 0.3770 - val_loss: 1.2415 - val_accuracy: 0.3683\n","Epoch 21/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.1640 - accuracy: 0.3997\n","Epoch 21: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.1558 - accuracy: 0.3950 - val_loss: 1.2144 - val_accuracy: 0.3990\n","Epoch 22/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.1870 - accuracy: 0.3942\n","Epoch 22: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 9ms/step - loss: 1.1892 - accuracy: 0.3915 - val_loss: 1.2172 - val_accuracy: 0.3603\n","Epoch 23/100\n","43/46 [===========================>..] - ETA: 0s - loss: 1.2153 - accuracy: 0.3794\n","Epoch 23: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2150 - accuracy: 0.3784 - val_loss: 1.2022 - val_accuracy: 0.3942\n","Epoch 24/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2083 - accuracy: 0.3771\n","Epoch 24: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 10ms/step - loss: 1.2081 - accuracy: 0.3763 - val_loss: 1.2382 - val_accuracy: 0.4071\n","Epoch 25/100\n","43/46 [===========================>..] - ETA: 0s - loss: 1.1827 - accuracy: 0.3990\n","Epoch 25: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 11ms/step - loss: 1.1865 - accuracy: 0.3978 - val_loss: 1.2643 - val_accuracy: 0.3570\n","Epoch 26/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.1913 - accuracy: 0.3945\n","Epoch 26: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.1972 - accuracy: 0.3985 - val_loss: 1.2325 - val_accuracy: 0.3845\n","Epoch 27/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2384 - accuracy: 0.3957\n","Epoch 27: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 10ms/step - loss: 1.2384 - accuracy: 0.3957 - val_loss: 1.4175 - val_accuracy: 0.3554\n","Epoch 28/100\n","34/46 [=====================>........] - ETA: 0s - loss: 1.2632 - accuracy: 0.3833\n","Epoch 28: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2782 - accuracy: 0.3784 - val_loss: 1.4152 - val_accuracy: 0.3409\n","Epoch 29/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.1903 - accuracy: 0.3801\n","Epoch 29: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.1985 - accuracy: 0.3818 - val_loss: 1.1964 - val_accuracy: 0.3796\n","Epoch 30/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.1966 - accuracy: 0.4205\n","Epoch 30: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2053 - accuracy: 0.4130 - val_loss: 1.1018 - val_accuracy: 0.3877\n","Epoch 31/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2438 - accuracy: 0.3932\n","Epoch 31: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2347 - accuracy: 0.3839 - val_loss: 1.1733 - val_accuracy: 0.3700\n","Epoch 32/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2247 - accuracy: 0.3759\n","Epoch 32: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2383 - accuracy: 0.3728 - val_loss: 1.3223 - val_accuracy: 0.3538\n","Epoch 33/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2477 - accuracy: 0.3770\n","Epoch 33: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2477 - accuracy: 0.3770 - val_loss: 1.2408 - val_accuracy: 0.3942\n","Epoch 34/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2351 - accuracy: 0.4012\n","Epoch 34: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2405 - accuracy: 0.3922 - val_loss: 1.2270 - val_accuracy: 0.3651\n","Epoch 35/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2764 - accuracy: 0.4089\n","Epoch 35: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2764 - accuracy: 0.4089 - val_loss: 1.3652 - val_accuracy: 0.4023\n","Epoch 36/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2622 - accuracy: 0.3854\n","Epoch 36: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2615 - accuracy: 0.3853 - val_loss: 1.1672 - val_accuracy: 0.4055\n","28/28 [==============================] - 0s 4ms/step\n","0.41468926553672314\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["36/46 [======================>.......] - ETA: 0s - loss: 2.4848 - accuracy: 0.1701\n","Epoch 1: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 2s 14ms/step - loss: 2.3627 - accuracy: 0.1913 - val_loss: 1.5815 - val_accuracy: 0.3150\n","Epoch 2/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.5188 - accuracy: 0.3725\n","Epoch 2: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.5449 - accuracy: 0.3673 - val_loss: 1.5403 - val_accuracy: 0.3425\n","Epoch 3/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.5454 - accuracy: 0.3454\n","Epoch 3: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.5326 - accuracy: 0.3479 - val_loss: 1.3735 - val_accuracy: 0.3667\n","Epoch 4/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.4555 - accuracy: 0.3405\n","Epoch 4: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.4401 - accuracy: 0.3354 - val_loss: 1.3475 - val_accuracy: 0.3700\n","Epoch 5/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.4215 - accuracy: 0.3480\n","Epoch 5: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.4645 - accuracy: 0.3403 - val_loss: 1.4985 - val_accuracy: 0.3570\n","Epoch 6/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.3737 - accuracy: 0.3902\n","Epoch 6: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3646 - accuracy: 0.3881 - val_loss: 1.2594 - val_accuracy: 0.3748\n","Epoch 7/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2804 - accuracy: 0.3581\n","Epoch 7: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3136 - accuracy: 0.3479 - val_loss: 1.4154 - val_accuracy: 0.3716\n","Epoch 8/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2506 - accuracy: 0.3643\n","Epoch 8: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2470 - accuracy: 0.3680 - val_loss: 1.1729 - val_accuracy: 0.3845\n","Epoch 9/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.3234 - accuracy: 0.3783\n","Epoch 9: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3210 - accuracy: 0.3742 - val_loss: 1.2616 - val_accuracy: 0.3893\n","Epoch 10/100\n","34/46 [=====================>........] - ETA: 0s - loss: 1.2754 - accuracy: 0.3750\n","Epoch 10: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2504 - accuracy: 0.3777 - val_loss: 1.2486 - val_accuracy: 0.3279\n","Epoch 11/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2859 - accuracy: 0.3576\n","Epoch 11: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2856 - accuracy: 0.3576 - val_loss: 1.2832 - val_accuracy: 0.3457\n","Epoch 12/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2953 - accuracy: 0.3611\n","Epoch 12: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3007 - accuracy: 0.3604 - val_loss: 1.2442 - val_accuracy: 0.3796\n","Epoch 13/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.3099 - accuracy: 0.3618\n","Epoch 13: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.3080 - accuracy: 0.3659 - val_loss: 1.4264 - val_accuracy: 0.3829\n","Epoch 14/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3781 - accuracy: 0.3611\n","Epoch 14: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3361 - accuracy: 0.3624 - val_loss: 1.1844 - val_accuracy: 0.3796\n","Epoch 15/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2894 - accuracy: 0.3819\n","Epoch 15: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2900 - accuracy: 0.3812 - val_loss: 1.2765 - val_accuracy: 0.3667\n","Epoch 16/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.3928 - accuracy: 0.3528\n","Epoch 16: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3660 - accuracy: 0.3562 - val_loss: 1.1448 - val_accuracy: 0.4120\n","Epoch 17/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2979 - accuracy: 0.3420\n","Epoch 17: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2813 - accuracy: 0.3458 - val_loss: 1.3566 - val_accuracy: 0.3247\n","Epoch 18/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2214 - accuracy: 0.3816\n","Epoch 18: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2085 - accuracy: 0.3784 - val_loss: 1.0587 - val_accuracy: 0.3683\n","Epoch 19/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3330 - accuracy: 0.3759\n","Epoch 19: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3070 - accuracy: 0.3791 - val_loss: 1.2133 - val_accuracy: 0.4087\n","Epoch 20/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3632 - accuracy: 0.3802\n","Epoch 20: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.4155 - accuracy: 0.3687 - val_loss: 1.3427 - val_accuracy: 0.3635\n","Epoch 21/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.3931 - accuracy: 0.3742\n","Epoch 21: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3982 - accuracy: 0.3770 - val_loss: 1.3961 - val_accuracy: 0.3910\n","Epoch 22/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2396 - accuracy: 0.3715\n","Epoch 22: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2597 - accuracy: 0.3784 - val_loss: 1.1675 - val_accuracy: 0.3926\n","Epoch 23/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3203 - accuracy: 0.3828\n","Epoch 23: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3141 - accuracy: 0.3784 - val_loss: 1.0966 - val_accuracy: 0.3506\n","Epoch 24/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.1952 - accuracy: 0.3878\n","Epoch 24: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1853 - accuracy: 0.3888 - val_loss: 1.4000 - val_accuracy: 0.3425\n","Epoch 25/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2651 - accuracy: 0.3670\n","Epoch 25: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2629 - accuracy: 0.3624 - val_loss: 1.1998 - val_accuracy: 0.3393\n","Epoch 26/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2712 - accuracy: 0.3564\n","Epoch 26: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2657 - accuracy: 0.3569 - val_loss: 1.2027 - val_accuracy: 0.3538\n","Epoch 27/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2836 - accuracy: 0.3480\n","Epoch 27: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2785 - accuracy: 0.3479 - val_loss: 1.2010 - val_accuracy: 0.3199\n","Epoch 28/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2320 - accuracy: 0.3602\n","Epoch 28: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2164 - accuracy: 0.3666 - val_loss: 1.1505 - val_accuracy: 0.3409\n","Epoch 29/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2593 - accuracy: 0.3889\n","Epoch 29: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2392 - accuracy: 0.3915 - val_loss: 1.1665 - val_accuracy: 0.3344\n","Epoch 30/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2599 - accuracy: 0.3741\n","Epoch 30: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2635 - accuracy: 0.3756 - val_loss: 1.5300 - val_accuracy: 0.3748\n","Epoch 31/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2436 - accuracy: 0.3910\n","Epoch 31: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2214 - accuracy: 0.3999 - val_loss: 1.4133 - val_accuracy: 0.3619\n","Epoch 32/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.2442 - accuracy: 0.4071\n","Epoch 32: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 10ms/step - loss: 1.2752 - accuracy: 0.3909 - val_loss: 1.2198 - val_accuracy: 0.3425\n","Epoch 33/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.3062 - accuracy: 0.3654\n","Epoch 33: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 9ms/step - loss: 1.3146 - accuracy: 0.3555 - val_loss: 1.2240 - val_accuracy: 0.3813\n","Epoch 34/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2375 - accuracy: 0.3909\n","Epoch 34: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 10ms/step - loss: 1.2375 - accuracy: 0.3909 - val_loss: 1.1107 - val_accuracy: 0.3619\n","Epoch 35/100\n","43/46 [===========================>..] - ETA: 0s - loss: 1.2814 - accuracy: 0.3612\n","Epoch 35: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2801 - accuracy: 0.3624 - val_loss: 1.2042 - val_accuracy: 0.3393\n","Epoch 36/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.2751 - accuracy: 0.3910\n","Epoch 36: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2588 - accuracy: 0.3909 - val_loss: 1.2204 - val_accuracy: 0.4039\n","28/28 [==============================] - 0s 3ms/step\n","0.4090395480225989\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["37/46 [=======================>......] - ETA: 0s - loss: 3.5698 - accuracy: 0.2618\n","Epoch 1: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 2s 14ms/step - loss: 3.2666 - accuracy: 0.2779 - val_loss: 1.6879 - val_accuracy: 0.4120\n","Epoch 2/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.5271 - accuracy: 0.3725\n","Epoch 2: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.4909 - accuracy: 0.3714 - val_loss: 1.3829 - val_accuracy: 0.3328\n","Epoch 3/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.3151 - accuracy: 0.3767\n","Epoch 3: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.3127 - accuracy: 0.3666 - val_loss: 1.2247 - val_accuracy: 0.3716\n","Epoch 4/100\n","40/46 [=========================>....] - ETA: 0s - loss: 1.2576 - accuracy: 0.3844\n","Epoch 4: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2472 - accuracy: 0.3929 - val_loss: 1.2101 - val_accuracy: 0.3603\n","Epoch 5/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2087 - accuracy: 0.4172\n","Epoch 5: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2087 - accuracy: 0.4172 - val_loss: 1.2266 - val_accuracy: 0.3651\n","Epoch 6/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2905 - accuracy: 0.3980\n","Epoch 6: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 10ms/step - loss: 1.2671 - accuracy: 0.4068 - val_loss: 1.2282 - val_accuracy: 0.3942\n","Epoch 7/100\n","46/46 [==============================] - ETA: 0s - loss: 1.1699 - accuracy: 0.4047\n","Epoch 7: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 10ms/step - loss: 1.1699 - accuracy: 0.4047 - val_loss: 1.1730 - val_accuracy: 0.4120\n","Epoch 8/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2763 - accuracy: 0.3577\n","Epoch 8: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2760 - accuracy: 0.3590 - val_loss: 1.1697 - val_accuracy: 0.3716\n","Epoch 9/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2506 - accuracy: 0.3807\n","Epoch 9: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2420 - accuracy: 0.3805 - val_loss: 1.1565 - val_accuracy: 0.4281\n","Epoch 10/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2088 - accuracy: 0.3978\n","Epoch 10: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 10ms/step - loss: 1.2088 - accuracy: 0.3978 - val_loss: 1.1606 - val_accuracy: 0.3457\n","Epoch 11/100\n","45/46 [============================>.] - ETA: 0s - loss: 1.2398 - accuracy: 0.3840\n","Epoch 11: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2406 - accuracy: 0.3839 - val_loss: 1.2388 - val_accuracy: 0.3667\n","Epoch 12/100\n","34/46 [=====================>........] - ETA: 0s - loss: 1.3306 - accuracy: 0.3915\n","Epoch 12: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3041 - accuracy: 0.3881 - val_loss: 1.1553 - val_accuracy: 0.4265\n","Epoch 13/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2171 - accuracy: 0.3768\n","Epoch 13: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2084 - accuracy: 0.3763 - val_loss: 1.2238 - val_accuracy: 0.3489\n","Epoch 14/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2128 - accuracy: 0.3750\n","Epoch 14: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2285 - accuracy: 0.3791 - val_loss: 1.6634 - val_accuracy: 0.3910\n","Epoch 15/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.3559 - accuracy: 0.3750\n","Epoch 15: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3680 - accuracy: 0.3694 - val_loss: 1.7850 - val_accuracy: 0.3603\n","Epoch 16/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.3236 - accuracy: 0.3884\n","Epoch 16: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2988 - accuracy: 0.3915 - val_loss: 1.3144 - val_accuracy: 0.3441\n","Epoch 17/100\n","43/46 [===========================>..] - ETA: 0s - loss: 1.3958 - accuracy: 0.3830\n","Epoch 17: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.3900 - accuracy: 0.3818 - val_loss: 1.2143 - val_accuracy: 0.3554\n","Epoch 18/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2334 - accuracy: 0.3943\n","Epoch 18: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2334 - accuracy: 0.3943 - val_loss: 1.2144 - val_accuracy: 0.3942\n","Epoch 19/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2797 - accuracy: 0.3834\n","Epoch 19: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2746 - accuracy: 0.3902 - val_loss: 1.3568 - val_accuracy: 0.3586\n","Epoch 20/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2197 - accuracy: 0.3585\n","Epoch 20: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2098 - accuracy: 0.3659 - val_loss: 1.1531 - val_accuracy: 0.3570\n","Epoch 21/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.1677 - accuracy: 0.3914\n","Epoch 21: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1743 - accuracy: 0.3950 - val_loss: 1.3075 - val_accuracy: 0.3635\n","Epoch 22/100\n","46/46 [==============================] - ETA: 0s - loss: 1.2470 - accuracy: 0.3971\n","Epoch 22: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2470 - accuracy: 0.3971 - val_loss: 1.2852 - val_accuracy: 0.3893\n","Epoch 23/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2589 - accuracy: 0.3679\n","Epoch 23: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2528 - accuracy: 0.3694 - val_loss: 1.1860 - val_accuracy: 0.4249\n","Epoch 24/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.1937 - accuracy: 0.3953\n","Epoch 24: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1919 - accuracy: 0.4040 - val_loss: 1.4539 - val_accuracy: 0.3441\n","Epoch 25/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2175 - accuracy: 0.3843\n","Epoch 25: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2513 - accuracy: 0.3881 - val_loss: 1.2920 - val_accuracy: 0.3667\n","Epoch 26/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2638 - accuracy: 0.3743\n","Epoch 26: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2691 - accuracy: 0.3742 - val_loss: 1.2157 - val_accuracy: 0.3344\n","Epoch 27/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2563 - accuracy: 0.3946\n","Epoch 27: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2336 - accuracy: 0.3978 - val_loss: 1.3198 - val_accuracy: 0.3958\n","Epoch 28/100\n","34/46 [=====================>........] - ETA: 0s - loss: 1.3178 - accuracy: 0.3787\n","Epoch 28: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2713 - accuracy: 0.3936 - val_loss: 1.2137 - val_accuracy: 0.3716\n","Epoch 29/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2984 - accuracy: 0.3967\n","Epoch 29: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3387 - accuracy: 0.3909 - val_loss: 1.2302 - val_accuracy: 0.4087\n","28/28 [==============================] - 0s 3ms/step\n","0.44519774011299434\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["39/46 [========================>.....] - ETA: 0s - loss: 2.4791 - accuracy: 0.3221\n","Epoch 1: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 2s 13ms/step - loss: 2.3764 - accuracy: 0.3278 - val_loss: 1.4988 - val_accuracy: 0.3409\n","Epoch 2/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.5607 - accuracy: 0.3349\n","Epoch 2: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.5221 - accuracy: 0.3423 - val_loss: 1.2747 - val_accuracy: 0.3619\n","Epoch 3/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.3830 - accuracy: 0.3632\n","Epoch 3: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3576 - accuracy: 0.3728 - val_loss: 1.2981 - val_accuracy: 0.4216\n","Epoch 4/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2362 - accuracy: 0.4206\n","Epoch 4: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2302 - accuracy: 0.4220 - val_loss: 1.2406 - val_accuracy: 0.4523\n","Epoch 5/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.4014 - accuracy: 0.4009\n","Epoch 5: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3718 - accuracy: 0.3957 - val_loss: 1.4106 - val_accuracy: 0.3958\n","Epoch 6/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.4045 - accuracy: 0.3530\n","Epoch 6: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.4171 - accuracy: 0.3562 - val_loss: 1.3517 - val_accuracy: 0.4071\n","Epoch 7/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.3150 - accuracy: 0.4054\n","Epoch 7: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2879 - accuracy: 0.4082 - val_loss: 1.1891 - val_accuracy: 0.4087\n","Epoch 8/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2169 - accuracy: 0.3898\n","Epoch 8: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2199 - accuracy: 0.3881 - val_loss: 1.2540 - val_accuracy: 0.3716\n","Epoch 9/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.3122 - accuracy: 0.3714\n","Epoch 9: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2814 - accuracy: 0.3839 - val_loss: 1.1638 - val_accuracy: 0.3974\n","Epoch 10/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.1798 - accuracy: 0.4046\n","Epoch 10: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.1938 - accuracy: 0.3985 - val_loss: 1.2921 - val_accuracy: 0.3748\n","Epoch 11/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.3692 - accuracy: 0.3487\n","Epoch 11: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 9ms/step - loss: 1.3679 - accuracy: 0.3465 - val_loss: 1.2869 - val_accuracy: 0.3522\n","Epoch 12/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2565 - accuracy: 0.3818\n","Epoch 12: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2596 - accuracy: 0.3777 - val_loss: 1.1282 - val_accuracy: 0.3974\n","Epoch 13/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.2856 - accuracy: 0.3988\n","Epoch 13: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.2878 - accuracy: 0.4040 - val_loss: 1.1840 - val_accuracy: 0.3813\n","Epoch 14/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2901 - accuracy: 0.4013\n","Epoch 14: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 7ms/step - loss: 1.2906 - accuracy: 0.4006 - val_loss: 1.1498 - val_accuracy: 0.4346\n","Epoch 15/100\n","44/46 [===========================>..] - ETA: 0s - loss: 1.2832 - accuracy: 0.3935\n","Epoch 15: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2843 - accuracy: 0.3909 - val_loss: 1.1728 - val_accuracy: 0.4103\n","Epoch 16/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.2971 - accuracy: 0.4054\n","Epoch 16: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2770 - accuracy: 0.4144 - val_loss: 1.2392 - val_accuracy: 0.4265\n","Epoch 17/100\n","41/46 [=========================>....] - ETA: 0s - loss: 1.1999 - accuracy: 0.4268\n","Epoch 17: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 9ms/step - loss: 1.1931 - accuracy: 0.4269 - val_loss: 1.1709 - val_accuracy: 0.4378\n","Epoch 18/100\n","36/46 [======================>.......] - ETA: 0s - loss: 1.1734 - accuracy: 0.3976\n","Epoch 18: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 10ms/step - loss: 1.2249 - accuracy: 0.3881 - val_loss: 1.1407 - val_accuracy: 0.4330\n","Epoch 19/100\n","39/46 [========================>.....] - ETA: 0s - loss: 1.2469 - accuracy: 0.3766\n","Epoch 19: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 9ms/step - loss: 1.2608 - accuracy: 0.3805 - val_loss: 1.2593 - val_accuracy: 0.3700\n","Epoch 20/100\n","43/46 [===========================>..] - ETA: 0s - loss: 1.2769 - accuracy: 0.3917\n","Epoch 20: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 10ms/step - loss: 1.2785 - accuracy: 0.3895 - val_loss: 1.2463 - val_accuracy: 0.4168\n","Epoch 21/100\n","38/46 [=======================>......] - ETA: 0s - loss: 1.1964 - accuracy: 0.4087\n","Epoch 21: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2105 - accuracy: 0.4068 - val_loss: 1.6405 - val_accuracy: 0.3376\n","Epoch 22/100\n","42/46 [==========================>...] - ETA: 0s - loss: 1.2826 - accuracy: 0.3862\n","Epoch 22: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 10ms/step - loss: 1.2844 - accuracy: 0.3853 - val_loss: 1.1193 - val_accuracy: 0.4087\n","Epoch 23/100\n","37/46 [=======================>......] - ETA: 0s - loss: 1.2999 - accuracy: 0.3809\n","Epoch 23: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 8ms/step - loss: 1.2675 - accuracy: 0.3867 - val_loss: 1.2897 - val_accuracy: 0.4378\n","Epoch 24/100\n","35/46 [=====================>........] - ETA: 0s - loss: 1.2733 - accuracy: 0.4241\n","Epoch 24: val_accuracy did not improve from 0.45396\n","46/46 [==============================] - 0s 6ms/step - loss: 1.3069 - accuracy: 0.4040 - val_loss: 1.2530 - val_accuracy: 0.4394\n","28/28 [==============================] - 0s 3ms/step\n","0.44519774011299434\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["28/28 [==============================] - 0s 4ms/step - loss: 1.2671 - accuracy: 0.4090\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-d3c39200dee7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_csv_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mquick_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-42-9c0d46910981>\u001b[0m in \u001b[0;36mquick_csv\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mquick_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mearly_stopping2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-d9eff685dfc3>\u001b[0m in \u001b[0;36mget_csv\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    891\u001b[0m               dtype='datetime64[ns]')\n\u001b[1;32m    892\u001b[0m         \"\"\"\n\u001b[0;32m--> 893\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '};this.gbar_=this.gbar_||{};(function(_){var window=this;'"]}]},{"cell_type":"code","source":["quick_csv(\"winered\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"921ab594-9b4b-4b02-fbfa-aaee37f95578","id":"hcdq7H_gQb1w","executionInfo":{"status":"ok","timestamp":1681933789421,"user_tz":-180,"elapsed":21431,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}}},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["21/25 [========================>.....] - ETA: 0s - loss: 2.8845 - accuracy: 0.3259\n","Epoch 1: val_accuracy improved from -inf to 0.35417, saving model to winered_tnn2.h5\n","25/25 [==============================] - 2s 30ms/step - loss: 2.7372 - accuracy: 0.3384 - val_loss: 1.9720 - val_accuracy: 0.3542\n","Epoch 2/100\n","20/25 [=======================>......] - ETA: 0s - loss: 2.1342 - accuracy: 0.3781\n","Epoch 2: val_accuracy improved from 0.35417 to 0.43750, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 10ms/step - loss: 2.0688 - accuracy: 0.3806 - val_loss: 1.8736 - val_accuracy: 0.4375\n","Epoch 3/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.7405 - accuracy: 0.4205\n","Epoch 3: val_accuracy improved from 0.43750 to 0.44940, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 10ms/step - loss: 1.7531 - accuracy: 0.4227 - val_loss: 1.6347 - val_accuracy: 0.4494\n","Epoch 4/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.6495 - accuracy: 0.4360\n","Epoch 4: val_accuracy improved from 0.44940 to 0.51488, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 10ms/step - loss: 1.6556 - accuracy: 0.4330 - val_loss: 1.6215 - val_accuracy: 0.5149\n","Epoch 5/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.4536 - accuracy: 0.4906\n","Epoch 5: val_accuracy did not improve from 0.51488\n","25/25 [==============================] - 0s 10ms/step - loss: 1.4453 - accuracy: 0.4981 - val_loss: 1.4418 - val_accuracy: 0.4315\n","Epoch 6/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.4226 - accuracy: 0.4507\n","Epoch 6: val_accuracy did not improve from 0.51488\n","25/25 [==============================] - 0s 10ms/step - loss: 1.4541 - accuracy: 0.4649 - val_loss: 1.3915 - val_accuracy: 0.4821\n","Epoch 7/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.4865 - accuracy: 0.4753\n","Epoch 7: val_accuracy did not improve from 0.51488\n","25/25 [==============================] - 0s 9ms/step - loss: 1.4587 - accuracy: 0.4828 - val_loss: 1.3085 - val_accuracy: 0.5030\n","Epoch 8/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.4222 - accuracy: 0.4750\n","Epoch 8: val_accuracy did not improve from 0.51488\n","25/25 [==============================] - 0s 9ms/step - loss: 1.4107 - accuracy: 0.4738 - val_loss: 1.3718 - val_accuracy: 0.3988\n","Epoch 9/100\n","22/25 [=========================>....] - ETA: 0s - loss: 1.3883 - accuracy: 0.4872\n","Epoch 9: val_accuracy did not improve from 0.51488\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3729 - accuracy: 0.4968 - val_loss: 1.4012 - val_accuracy: 0.4554\n","Epoch 10/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.3419 - accuracy: 0.5137\n","Epoch 10: val_accuracy improved from 0.51488 to 0.51786, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3815 - accuracy: 0.4917 - val_loss: 1.2098 - val_accuracy: 0.5179\n","Epoch 11/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.3312 - accuracy: 0.5045\n","Epoch 11: val_accuracy did not improve from 0.51786\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3655 - accuracy: 0.5096 - val_loss: 1.4562 - val_accuracy: 0.4583\n","Epoch 12/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.2631 - accuracy: 0.5146\n","Epoch 12: val_accuracy did not improve from 0.51786\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3939 - accuracy: 0.4917 - val_loss: 1.3058 - val_accuracy: 0.4792\n","Epoch 13/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.3724 - accuracy: 0.5000\n","Epoch 13: val_accuracy did not improve from 0.51786\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2891 - accuracy: 0.5428 - val_loss: 1.3425 - val_accuracy: 0.4881\n","Epoch 14/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3162 - accuracy: 0.4729\n","Epoch 14: val_accuracy did not improve from 0.51786\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2850 - accuracy: 0.4994 - val_loss: 1.3684 - val_accuracy: 0.4673\n","Epoch 15/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3875 - accuracy: 0.5229\n","Epoch 15: val_accuracy did not improve from 0.51786\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3297 - accuracy: 0.5287 - val_loss: 1.1890 - val_accuracy: 0.5179\n","Epoch 16/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.2919 - accuracy: 0.4902\n","Epoch 16: val_accuracy did not improve from 0.51786\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3093 - accuracy: 0.4968 - val_loss: 1.1970 - val_accuracy: 0.5089\n","Epoch 17/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3548 - accuracy: 0.5146\n","Epoch 17: val_accuracy did not improve from 0.51786\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3538 - accuracy: 0.5096 - val_loss: 1.3430 - val_accuracy: 0.4673\n","Epoch 18/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.3980 - accuracy: 0.4727\n","Epoch 18: val_accuracy did not improve from 0.51786\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3593 - accuracy: 0.4891 - val_loss: 1.3187 - val_accuracy: 0.4494\n","Epoch 19/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.3328 - accuracy: 0.4727\n","Epoch 19: val_accuracy did not improve from 0.51786\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3045 - accuracy: 0.5006 - val_loss: 1.4843 - val_accuracy: 0.4702\n","Epoch 20/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3049 - accuracy: 0.4979\n","Epoch 20: val_accuracy improved from 0.51786 to 0.52679, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3596 - accuracy: 0.4891 - val_loss: 1.2425 - val_accuracy: 0.5268\n","Epoch 21/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3017 - accuracy: 0.4792\n","Epoch 21: val_accuracy did not improve from 0.52679\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3058 - accuracy: 0.4815 - val_loss: 1.6127 - val_accuracy: 0.4821\n","Epoch 22/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3783 - accuracy: 0.4729\n","Epoch 22: val_accuracy did not improve from 0.52679\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3518 - accuracy: 0.4828 - val_loss: 1.4043 - val_accuracy: 0.4702\n","Epoch 23/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3585 - accuracy: 0.5292\n","Epoch 23: val_accuracy did not improve from 0.52679\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3432 - accuracy: 0.5096 - val_loss: 1.6014 - val_accuracy: 0.5000\n","Epoch 24/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3843 - accuracy: 0.4812\n","Epoch 24: val_accuracy did not improve from 0.52679\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3528 - accuracy: 0.4930 - val_loss: 1.4138 - val_accuracy: 0.5238\n","Epoch 25/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3188 - accuracy: 0.4979\n","Epoch 25: val_accuracy improved from 0.52679 to 0.53274, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2819 - accuracy: 0.5032 - val_loss: 1.3348 - val_accuracy: 0.5327\n","Epoch 26/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3453 - accuracy: 0.4938\n","Epoch 26: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3236 - accuracy: 0.4828 - val_loss: 1.6721 - val_accuracy: 0.4464\n","Epoch 27/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.4049 - accuracy: 0.4941\n","Epoch 27: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3397 - accuracy: 0.4866 - val_loss: 1.3040 - val_accuracy: 0.4256\n","Epoch 28/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.3147 - accuracy: 0.4980\n","Epoch 28: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3306 - accuracy: 0.4725 - val_loss: 1.2912 - val_accuracy: 0.5208\n","Epoch 29/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.3832 - accuracy: 0.4512\n","Epoch 29: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3410 - accuracy: 0.4687 - val_loss: 1.4217 - val_accuracy: 0.5327\n","Epoch 30/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.2838 - accuracy: 0.4875\n","Epoch 30: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2954 - accuracy: 0.4904 - val_loss: 1.3260 - val_accuracy: 0.4435\n","Epoch 31/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.3679 - accuracy: 0.5078\n","Epoch 31: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3690 - accuracy: 0.5019 - val_loss: 1.4565 - val_accuracy: 0.4643\n","Epoch 32/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.3457 - accuracy: 0.5273\n","Epoch 32: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3082 - accuracy: 0.5275 - val_loss: 1.4355 - val_accuracy: 0.4702\n","Epoch 33/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3976 - accuracy: 0.4896\n","Epoch 33: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 6ms/step - loss: 1.4007 - accuracy: 0.4879 - val_loss: 1.1884 - val_accuracy: 0.4851\n","Epoch 34/100\n","13/25 [==============>...............] - ETA: 0s - loss: 1.4053 - accuracy: 0.4904\n","Epoch 34: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4495 - accuracy: 0.4904 - val_loss: 1.4552 - val_accuracy: 0.4881\n","Epoch 35/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.5765 - accuracy: 0.5000\n","Epoch 35: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 6ms/step - loss: 1.5137 - accuracy: 0.5134 - val_loss: 1.3087 - val_accuracy: 0.5149\n","Epoch 36/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.3712 - accuracy: 0.5098\n","Epoch 36: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3450 - accuracy: 0.5160 - val_loss: 1.6154 - val_accuracy: 0.4494\n","Epoch 37/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.4605 - accuracy: 0.4844\n","Epoch 37: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 6ms/step - loss: 1.5029 - accuracy: 0.4828 - val_loss: 1.3856 - val_accuracy: 0.4792\n","Epoch 38/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.3668 - accuracy: 0.4732\n","Epoch 38: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4521 - accuracy: 0.4853 - val_loss: 1.7359 - val_accuracy: 0.4940\n","Epoch 39/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.3690 - accuracy: 0.5000\n","Epoch 39: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3553 - accuracy: 0.4891 - val_loss: 1.5297 - val_accuracy: 0.4970\n","Epoch 40/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.4694 - accuracy: 0.5379\n","Epoch 40: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4463 - accuracy: 0.5070 - val_loss: 1.7536 - val_accuracy: 0.4792\n","Epoch 41/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.5137 - accuracy: 0.4854\n","Epoch 41: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 7ms/step - loss: 1.5141 - accuracy: 0.5019 - val_loss: 1.5479 - val_accuracy: 0.4524\n","Epoch 42/100\n","25/25 [==============================] - ETA: 0s - loss: 1.6263 - accuracy: 0.4674\n","Epoch 42: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 7ms/step - loss: 1.6263 - accuracy: 0.4674 - val_loss: 1.5118 - val_accuracy: 0.4792\n","Epoch 43/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.3867 - accuracy: 0.5089\n","Epoch 43: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3791 - accuracy: 0.5070 - val_loss: 1.8292 - val_accuracy: 0.4613\n","Epoch 44/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.4309 - accuracy: 0.5352\n","Epoch 44: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 6ms/step - loss: 1.4128 - accuracy: 0.5211 - val_loss: 1.4118 - val_accuracy: 0.5149\n","Epoch 45/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3202 - accuracy: 0.5021\n","Epoch 45: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3787 - accuracy: 0.4777 - val_loss: 1.3547 - val_accuracy: 0.4940\n","15/15 [==============================] - 0s 3ms/step\n","0.5104166666666666\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["14/25 [===============>..............] - ETA: 0s - loss: 5.3742 - accuracy: 0.0491     \n","Epoch 1: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 2s 20ms/step - loss: 4.8120 - accuracy: 0.0651 - val_loss: 3.6019 - val_accuracy: 0.0952\n","Epoch 2/100\n","15/25 [=================>............] - ETA: 0s - loss: 2.8724 - accuracy: 0.2292\n","Epoch 2: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 6ms/step - loss: 2.5295 - accuracy: 0.2708 - val_loss: 1.9833 - val_accuracy: 0.3095\n","Epoch 3/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.8240 - accuracy: 0.4043\n","Epoch 3: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 6ms/step - loss: 1.7678 - accuracy: 0.4151 - val_loss: 1.6736 - val_accuracy: 0.4940\n","Epoch 4/100\n","20/25 [=======================>......] - ETA: 0s - loss: 1.6091 - accuracy: 0.4734\n","Epoch 4: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 9ms/step - loss: 1.6531 - accuracy: 0.4585 - val_loss: 1.6791 - val_accuracy: 0.4643\n","Epoch 5/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.6023 - accuracy: 0.4955\n","Epoch 5: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 9ms/step - loss: 1.5961 - accuracy: 0.5019 - val_loss: 1.3426 - val_accuracy: 0.5089\n","Epoch 6/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.3489 - accuracy: 0.5658\n","Epoch 6: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3809 - accuracy: 0.5619 - val_loss: 1.3046 - val_accuracy: 0.5149\n","Epoch 7/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.3308 - accuracy: 0.5372\n","Epoch 7: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3170 - accuracy: 0.5453 - val_loss: 1.2875 - val_accuracy: 0.5149\n","Epoch 8/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.2802 - accuracy: 0.5580\n","Epoch 8: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3327 - accuracy: 0.5338 - val_loss: 1.3577 - val_accuracy: 0.4792\n","Epoch 9/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.3506 - accuracy: 0.4940\n","Epoch 9: val_accuracy did not improve from 0.53274\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3266 - accuracy: 0.5109 - val_loss: 1.3025 - val_accuracy: 0.5179\n","Epoch 10/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.3342 - accuracy: 0.5016\n","Epoch 10: val_accuracy improved from 0.53274 to 0.54762, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 11ms/step - loss: 1.3250 - accuracy: 0.4968 - val_loss: 1.1800 - val_accuracy: 0.5476\n","Epoch 11/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.3322 - accuracy: 0.5641\n","Epoch 11: val_accuracy did not improve from 0.54762\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3245 - accuracy: 0.5709 - val_loss: 1.2743 - val_accuracy: 0.5387\n","Epoch 12/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.2446 - accuracy: 0.5559\n","Epoch 12: val_accuracy did not improve from 0.54762\n","25/25 [==============================] - 0s 10ms/step - loss: 1.2688 - accuracy: 0.5517 - val_loss: 1.4001 - val_accuracy: 0.5030\n","Epoch 13/100\n","18/25 [====================>.........] - ETA: 0s - loss: 1.4437 - accuracy: 0.5156\n","Epoch 13: val_accuracy did not improve from 0.54762\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3982 - accuracy: 0.5415 - val_loss: 1.3506 - val_accuracy: 0.5208\n","Epoch 14/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.3303 - accuracy: 0.5833\n","Epoch 14: val_accuracy did not improve from 0.54762\n","25/25 [==============================] - 0s 9ms/step - loss: 1.3459 - accuracy: 0.5658 - val_loss: 1.5669 - val_accuracy: 0.3720\n","Epoch 15/100\n","19/25 [=====================>........] - ETA: 0s - loss: 1.3949 - accuracy: 0.4885\n","Epoch 15: val_accuracy did not improve from 0.54762\n","25/25 [==============================] - 0s 10ms/step - loss: 1.3556 - accuracy: 0.5134 - val_loss: 1.1651 - val_accuracy: 0.5387\n","Epoch 16/100\n","21/25 [========================>.....] - ETA: 0s - loss: 1.2550 - accuracy: 0.5461\n","Epoch 16: val_accuracy did not improve from 0.54762\n","25/25 [==============================] - 0s 8ms/step - loss: 1.2757 - accuracy: 0.5402 - val_loss: 1.2843 - val_accuracy: 0.5238\n","Epoch 17/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.2689 - accuracy: 0.5562\n","Epoch 17: val_accuracy did not improve from 0.54762\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2765 - accuracy: 0.5632 - val_loss: 1.1653 - val_accuracy: 0.5149\n","Epoch 18/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.2631 - accuracy: 0.5714\n","Epoch 18: val_accuracy did not improve from 0.54762\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2604 - accuracy: 0.5670 - val_loss: 1.3658 - val_accuracy: 0.5298\n","Epoch 19/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.4030 - accuracy: 0.5125\n","Epoch 19: val_accuracy did not improve from 0.54762\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2679 - accuracy: 0.5338 - val_loss: 1.2433 - val_accuracy: 0.5208\n","Epoch 20/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.1553 - accuracy: 0.5604\n","Epoch 20: val_accuracy did not improve from 0.54762\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2130 - accuracy: 0.5453 - val_loss: 1.2740 - val_accuracy: 0.4673\n","Epoch 21/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.2391 - accuracy: 0.5156\n","Epoch 21: val_accuracy did not improve from 0.54762\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2040 - accuracy: 0.5262 - val_loss: 1.2181 - val_accuracy: 0.5417\n","Epoch 22/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.2603 - accuracy: 0.5250\n","Epoch 22: val_accuracy did not improve from 0.54762\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2559 - accuracy: 0.5236 - val_loss: 1.3607 - val_accuracy: 0.4702\n","Epoch 23/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.2731 - accuracy: 0.5234\n","Epoch 23: val_accuracy improved from 0.54762 to 0.56845, saving model to winered_tnn2.h5\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2313 - accuracy: 0.5185 - val_loss: 1.1305 - val_accuracy: 0.5685\n","Epoch 24/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.1577 - accuracy: 0.5458\n","Epoch 24: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 6ms/step - loss: 1.1877 - accuracy: 0.5300 - val_loss: 1.3931 - val_accuracy: 0.3720\n","Epoch 25/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.4379 - accuracy: 0.4978\n","Epoch 25: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3856 - accuracy: 0.4930 - val_loss: 1.4477 - val_accuracy: 0.5149\n","Epoch 26/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3076 - accuracy: 0.4896\n","Epoch 26: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2782 - accuracy: 0.5223 - val_loss: 1.2495 - val_accuracy: 0.5625\n","Epoch 27/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3564 - accuracy: 0.4917\n","Epoch 27: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3060 - accuracy: 0.5134 - val_loss: 1.1722 - val_accuracy: 0.4792\n","Epoch 28/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.2892 - accuracy: 0.4911\n","Epoch 28: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2663 - accuracy: 0.5045 - val_loss: 1.2919 - val_accuracy: 0.5000\n","Epoch 29/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.2722 - accuracy: 0.4590\n","Epoch 29: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2735 - accuracy: 0.4904 - val_loss: 1.2239 - val_accuracy: 0.5119\n","Epoch 30/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.2282 - accuracy: 0.5246\n","Epoch 30: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2419 - accuracy: 0.5223 - val_loss: 1.4354 - val_accuracy: 0.5208\n","Epoch 31/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.2496 - accuracy: 0.5022\n","Epoch 31: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2399 - accuracy: 0.5300 - val_loss: 1.2533 - val_accuracy: 0.5476\n","Epoch 32/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.3023 - accuracy: 0.5410\n","Epoch 32: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2911 - accuracy: 0.5453 - val_loss: 1.4715 - val_accuracy: 0.4643\n","Epoch 33/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.4035 - accuracy: 0.5179\n","Epoch 33: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 8ms/step - loss: 1.4214 - accuracy: 0.4994 - val_loss: 1.4334 - val_accuracy: 0.3244\n","Epoch 34/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.2777 - accuracy: 0.4707\n","Epoch 34: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2570 - accuracy: 0.4623 - val_loss: 1.3053 - val_accuracy: 0.4702\n","Epoch 35/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3636 - accuracy: 0.4917\n","Epoch 35: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3160 - accuracy: 0.5006 - val_loss: 1.5316 - val_accuracy: 0.5268\n","Epoch 36/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.3659 - accuracy: 0.4911\n","Epoch 36: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2853 - accuracy: 0.5057 - val_loss: 1.3709 - val_accuracy: 0.5208\n","Epoch 37/100\n","14/25 [===============>..............] - ETA: 0s - loss: 1.2628 - accuracy: 0.5580\n","Epoch 37: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 6ms/step - loss: 1.3396 - accuracy: 0.5121 - val_loss: 1.5048 - val_accuracy: 0.4345\n","Epoch 38/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.2386 - accuracy: 0.5417\n","Epoch 38: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2786 - accuracy: 0.5300 - val_loss: 1.4274 - val_accuracy: 0.5089\n","Epoch 39/100\n","15/25 [=================>............] - ETA: 0s - loss: 1.3389 - accuracy: 0.5146\n","Epoch 39: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3511 - accuracy: 0.4981 - val_loss: 1.2334 - val_accuracy: 0.5357\n","Epoch 40/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.2216 - accuracy: 0.5371\n","Epoch 40: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 6ms/step - loss: 1.2620 - accuracy: 0.5262 - val_loss: 1.6325 - val_accuracy: 0.4345\n","Epoch 41/100\n","16/25 [==================>...........] - ETA: 0s - loss: 1.3480 - accuracy: 0.5039\n","Epoch 41: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 7ms/step - loss: 1.4083 - accuracy: 0.4981 - val_loss: 1.4020 - val_accuracy: 0.4524\n","Epoch 42/100\n","25/25 [==============================] - ETA: 0s - loss: 1.3788 - accuracy: 0.4891\n","Epoch 42: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 7ms/step - loss: 1.3788 - accuracy: 0.4891 - val_loss: 1.4450 - val_accuracy: 0.4762\n","Epoch 43/100\n","24/25 [===========================>..] - ETA: 0s - loss: 1.2900 - accuracy: 0.5430\n","Epoch 43: val_accuracy did not improve from 0.56845\n","25/25 [==============================] - 0s 7ms/step - loss: 1.2755 - accuracy: 0.5492 - val_loss: 1.2364 - val_accuracy: 0.5625\n","15/15 [==============================] - 0s 2ms/step\n","0.49583333333333335\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["15/15 [==============================] - 0s 4ms/step - loss: 1.3006 - accuracy: 0.4958\n"]}]},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","from keras_tuner import HyperParameters\n","import keras_tuner as kt\n","from tensorflow.keras.utils import to_categorical\n","\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","# data and metric imports\n","import sklearn.model_selection\n","import sklearn.datasets\n","import sklearn.metrics\n","\n","from qkeras import *\n","import qkeras.utils as qutils\n","\n","from scikeras.wrappers import KerasClassifier\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from sklearn.model_selection import StratifiedKFold,StratifiedShuffleSplit\n","\n","from scipy.stats import uniform\n","\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.models import load_model\n"],"metadata":{"id":"3UykpsrmdkUT","executionInfo":{"status":"ok","timestamp":1681932263484,"user_tz":-180,"elapsed":20,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def get_model(meta):\n","    # note that meta is a special argument that will be\n","    # handed a dict containing input metadata\n","    n_features_in_ = meta[\"n_features_in_\"]\n","    X_shape_ = meta[\"X_shape_\"]\n","    n_classes_ = meta[\"n_classes_\"]\n","\n","    model = keras.models.Sequential()\n","    #model.add(QActivation(\"quantized_bits(4, keep_negative=0)\"))\n","    model.add(QDense(units=40,kernel_quantizer=\"ternary\", use_bias=False, input_shape=X_shape_[1:]))\n","    model.add(QActivation(\"binary\"))\n","    model.add(QDense(units=n_classes_, kernel_quantizer=\"ternary(alpha=1)\", use_bias=False))\n","    model.add(layers.Activation('softmax'))\n","    return model"],"metadata":{"id":"aoq5u_VV88WS","executionInfo":{"status":"ok","timestamp":1681931895693,"user_tz":-180,"elapsed":461,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def quart(X):\n","  X = pd.DataFrame(X.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))))\n","  X = np.round(X*16).astype(int)\n","  X = np.minimum(15, X)\n","  return X"],"metadata":{"id":"2Qe1yghdE12V","executionInfo":{"status":"ok","timestamp":1681931899466,"user_tz":-180,"elapsed":6,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def split_up(X,y):\n","  return sklearn.model_selection.train_test_split(X, y, test_size=0.3, random_state=42)"],"metadata":{"id":"7DZuINofHh1-","executionInfo":{"status":"ok","timestamp":1681931901781,"user_tz":-180,"elapsed":9,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def get_csv(fname):\n","  df = pd.read_csv(f\"{fname}.csv\", header=None)\n","  X = df.iloc[:, :-1]\n","  y = df.iloc[:, -1]\n","  y = to_categorical(y, num_classes=y.nunique())\n","  X = quart(X)\n","  return X,y"],"metadata":{"id":"fhCMZQsJ896x","executionInfo":{"status":"ok","timestamp":1681931903789,"user_tz":-180,"elapsed":2,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["clf = KerasClassifier(\n","    get_model,\n","    epochs=100\n",")\n","\n","\n","params = {\n","    \"loss\": [\"categorical_crossentropy\"],\n","    #\"optimizer\": [\"adam\", \"sgd\"],\n","    \"optimizer\": [\"adam\"],\n","    \"optimizer__learning_rate\": [0.001, 0.01, 0.1],\n","    \"optimizer__beta_1\": [0.9, 0.99],\n","    \"optimizer__beta_2\": [0.9, 0.99],\n","}\n","\n","sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n","gs = GridSearchCV(clf, params, refit=False, cv=sss, scoring='accuracy',n_jobs=-1)\n","checkpoint = ModelCheckpoint('best_tmp.h5', monitor='val_accuracy', save_best_only=True)"],"metadata":{"id":"1uXgGi-IBvzx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clf = KerasClassifier(\n","    get_model,\n","    epochs=10\n",")\n","\n","\n","params = {\n","    \"loss\": [\"categorical_crossentropy\"],\n","    \"metrics\":['accuracy'],\n","    #\"optimizer\": [\"adam\", \"sgd\"],\n","    \"optimizer\": [\"adam\"],\n","    \"optimizer__learning_rate\": [0.002],\n","    \"optimizer__beta_1\": [0.9],\n","    \"optimizer__beta_2\": [0.99],\n","}\n","\n","sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n","gs = GridSearchCV(clf, params, refit=False, cv=sss, scoring='accuracy')\n","early_stopping = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n","checkpoint = ModelCheckpoint(f\"best_tnn2.h5\", monitor='val_accuracy', save_best_only=True,verbose=1,)"],"metadata":{"id":"iH2ucMRFLAhs","executionInfo":{"status":"ok","timestamp":1681932050886,"user_tz":-180,"elapsed":466,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["paramsx = {\n","    \"loss\": \"categorical_crossentropy\",\n","    \"metrics\":'accuracy',\n","    #\"optimizer\": [\"adam\", \"sgd\"],\n","    \"optimizer\": \"adam\",\n","    \"optimizer__learning_rate\": 0.002,\n","    \"optimizer__beta_1\": 0.9,\n","    \"optimizer__beta_2\": 0.99,\n","}"],"metadata":{"id":"VeJ7lbhNCztl","executionInfo":{"status":"ok","timestamp":1681933477635,"user_tz":-180,"elapsed":1079,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def retrain(X,y,prm):\n","  X_train, X_test, y_train, y_test = split_up(X,y)\n","  X_train, X_val, y_train, y_val = split_up(X_train,y_train)\n","  \n","  clfx = KerasClassifier(\n","    get_model,\n","    epochs=100,\n","    callbacks=[early_stopping,checkpoint],\n","    **prm\n","  )\n","  clfx.fit(X_train,y_train,validation_data=(X_val, y_val))\n","  print(f\"{clfx.score(X_test,y_test)}\")"],"metadata":{"id":"xCgN60-EEBf1","executionInfo":{"status":"ok","timestamp":1681932912642,"user_tz":-180,"elapsed":1092,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def retrain2(X,y,prm,fname):\n","  X_train, X_test, y_train, y_test = split_up(X,y)\n","  X_train, X_val, y_train, y_val = split_up(X_train,y_train)\n","  early_stopping2 = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n","  checkpoint2 = ModelCheckpoint(f\"{fname}_tnn2.h5\", monitor='val_accuracy', save_best_only=True,verbose=1,)\n","  clfx = KerasClassifier(\n","    get_model,\n","    epochs=100,\n","    callbacks=[early_stopping2,checkpoint2],\n","    **prm\n","  )\n","  clfx.fit(X_train,y_train,validation_data=(X_val, y_val))\n","  print(f\"{clfx.score(X_test,y_test)}\")"],"metadata":{"executionInfo":{"status":"ok","timestamp":1681933498884,"user_tz":-180,"elapsed":5,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}},"id":"MHk3ydaNBXq2"},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["def train_csv(fname):\n","  X,y = get_csv(fname)\n","  X_train, X_test, y_train, y_test = spit_up(X,y)\n","  gs.fit(X, y)\n","  prm = gs.best_params_\n","  retrain(X,y,prm)\n","  scors = f\"{fname}:Test:{gs.score(X_test,y_test)},Train:{gs.best_score_}, {prm}\\n\"\n","  with open('scors.txt', mode='a') as file:\n","    file.write(scors)\n","  model = gs.best_estimator_.model_\n","  qutils.model_save_quantized_weights(model,'weightnn'+fname+'.h5')\n","  model.save(fname+\"tnn.h5\")"],"metadata":{"id":"QULcr5rUsgzb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_csv2(fname):\n","  X,y = get_csv(fname)\n","  gs.fit(X, y)\n","  prm = gs.best_params_\n","  retrain(X,y,prm)"],"metadata":{"id":"HuoeTK_KLczx","executionInfo":{"status":"ok","timestamp":1681932916997,"user_tz":-180,"elapsed":537,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def quick_csv(fname):\n","  X,y = get_csv(fname)\n","  X_train, X_test, y_train, y_test = split_up(X,y)\n","  X_train, X_val, y_train, y_val = split_up(X_train,y_train)\n","  early_stopping2 = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n","  checkpoint2 = ModelCheckpoint(f\"{fname}_tnn2.h5\", monitor='val_accuracy', save_best_only=True,verbose=1,)\n","  clfx = KerasClassifier(\n","    get_model,\n","    epochs=100,\n","    callbacks=[early_stopping2,checkpoint2],\n","    **paramsx\n","  )\n","  for _ in range(10):\n","    clfx.fit(X_train,y_train,validation_data=(X_val, y_val))\n","    print(f\"{clfx.score(X_test,y_test)}\")\n","  with open(f\"{fname}number.txt\",\"w\") as f:\n","    mod = load_model(f\"{fname}_tnn2.h5\", custom_objects={'QActivation': QActivation,'QDense':QDense})\n","    _, accuracy = mod.evaluate(X_test, y_test)\n","    f.write(f\"{fname}: {accuracy=}\")"],"metadata":{"id":"uk5kYuTpLyOq","executionInfo":{"status":"ok","timestamp":1681933884977,"user_tz":-180,"elapsed":9,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["for fname in get_csv_filenames():\n","  train_csv(fname)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sqIS16iLFrV7","outputId":"2c27df3f-1b99-4413-d487-ee2e5819109f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["65/65 [==============================] - 1s 4ms/step - loss: 3.7651\n","Epoch 2/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.9446\n","Epoch 3/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.6857\n","Epoch 4/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.5118\n","Epoch 5/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.4486\n","Epoch 6/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.3498\n","Epoch 7/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.3084\n","Epoch 8/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2951\n","Epoch 9/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.3423\n","Epoch 10/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2974\n","Epoch 11/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.3133\n","Epoch 12/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.3416\n","Epoch 13/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.3346\n","Epoch 14/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2999\n","Epoch 15/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.3917\n","Epoch 16/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.2784\n","Epoch 17/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.3091\n","Epoch 18/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.2580\n","Epoch 19/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.2947\n","Epoch 20/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.3029\n","Epoch 21/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.3174\n","Epoch 22/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.2798\n","Epoch 23/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.2218\n","Epoch 24/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.2303\n","Epoch 25/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.2317\n","Epoch 26/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.2601\n","Epoch 27/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.2468\n","Epoch 28/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2513\n","Epoch 29/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2269\n","Epoch 30/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2329\n","Epoch 31/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2987\n","Epoch 32/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.2625\n","Epoch 33/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.2810\n","Epoch 34/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.3697\n","Epoch 35/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.1837\n","Epoch 36/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.2091\n","Epoch 37/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2173\n","Epoch 38/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2256\n","Epoch 39/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2494\n","Epoch 40/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2986\n","Epoch 41/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2167\n","Epoch 42/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2630\n","Epoch 43/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2463\n","Epoch 44/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2533\n","Epoch 45/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.2258\n","Epoch 46/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2953\n","Epoch 47/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.2671\n","Epoch 48/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.3650\n","Epoch 49/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2613\n","Epoch 50/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2919\n","Epoch 51/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2236\n","Epoch 52/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2197\n","Epoch 53/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2581\n","Epoch 54/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.2834\n","Epoch 55/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2857\n","Epoch 56/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2255\n","Epoch 57/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.3544\n","Epoch 58/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.3279\n","Epoch 59/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2484\n","Epoch 60/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2720\n","Epoch 61/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2257\n","Epoch 62/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2238\n","Epoch 63/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2558\n","Epoch 64/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.3120\n","Epoch 65/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2429\n","Epoch 66/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2139\n","Epoch 67/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.2426\n","Epoch 68/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2092\n","Epoch 69/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2653\n","Epoch 70/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2079\n","Epoch 71/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.2468\n","Epoch 72/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.2677\n","Epoch 73/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.3097\n","Epoch 74/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.2999\n","Epoch 75/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.2349\n","Epoch 76/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.2497\n","Epoch 77/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.2108\n","Epoch 78/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.1698\n","Epoch 79/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.1662\n","Epoch 80/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.2053\n","Epoch 81/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.2159\n","Epoch 82/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.1643\n","Epoch 83/100\n","65/65 [==============================] - 0s 5ms/step - loss: 1.2407\n","Epoch 84/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.2682\n","Epoch 85/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.2328\n","Epoch 86/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2452\n","Epoch 87/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.1920\n","Epoch 88/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2076\n","Epoch 89/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2722\n","Epoch 90/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.2809\n","Epoch 91/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2313\n","Epoch 92/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.1739\n","Epoch 93/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2324\n","Epoch 94/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.2062\n","Epoch 95/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.1864\n","Epoch 96/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2434\n","Epoch 97/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2763\n","Epoch 98/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2083\n","Epoch 99/100\n","65/65 [==============================] - 0s 3ms/step - loss: 1.2737\n","Epoch 100/100\n","65/65 [==============================] - 0s 4ms/step - loss: 1.3016\n","28/28 [==============================] - 0s 2ms/step\n","... quantizing model\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["35/35 [==============================] - 1s 3ms/step - loss: 4.7704\n","Epoch 2/100\n","35/35 [==============================] - 0s 3ms/step - loss: 2.6135\n","Epoch 3/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.9575\n","Epoch 4/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.7661\n","Epoch 5/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.6634\n","Epoch 6/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.6482\n","Epoch 7/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.6271\n","Epoch 8/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.6682\n","Epoch 9/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.6964\n","Epoch 10/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.5854\n","Epoch 11/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.6115\n","Epoch 12/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.5518\n","Epoch 13/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.5505\n","Epoch 14/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.4511\n","Epoch 15/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.4668\n","Epoch 16/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.4338\n","Epoch 17/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.3640\n","Epoch 18/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.3247\n","Epoch 19/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.3577\n","Epoch 20/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.3912\n","Epoch 21/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.3643\n","Epoch 22/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.3202\n","Epoch 23/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2627\n","Epoch 24/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.3098\n","Epoch 25/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2639\n","Epoch 26/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.2690\n","Epoch 27/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2726\n","Epoch 28/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.3077\n","Epoch 29/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.3233\n","Epoch 30/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.3469\n","Epoch 31/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2837\n","Epoch 32/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2780\n","Epoch 33/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2182\n","Epoch 34/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2489\n","Epoch 35/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.3244\n","Epoch 36/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.3162\n","Epoch 37/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.3197\n","Epoch 38/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2760\n","Epoch 39/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2806\n","Epoch 40/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2512\n","Epoch 41/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.3621\n","Epoch 42/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2408\n","Epoch 43/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2414\n","Epoch 44/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2764\n","Epoch 45/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.2717\n","Epoch 46/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.3282\n","Epoch 47/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.2191\n","Epoch 48/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2362\n","Epoch 49/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.3621\n","Epoch 50/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.2740\n","Epoch 51/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.2902\n","Epoch 52/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2826\n","Epoch 53/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.3474\n","Epoch 54/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2448\n","Epoch 55/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2499\n","Epoch 56/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.2913\n","Epoch 57/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2744\n","Epoch 58/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.3354\n","Epoch 59/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.2669\n","Epoch 60/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2621\n","Epoch 61/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2137\n","Epoch 62/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.4047\n","Epoch 63/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2908\n","Epoch 64/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.3563\n","Epoch 65/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.3531\n","Epoch 66/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2912\n","Epoch 67/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.3449\n","Epoch 68/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2862\n","Epoch 69/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.3333\n","Epoch 70/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.3294\n","Epoch 71/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.3958\n","Epoch 72/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.2681\n","Epoch 73/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.2861\n","Epoch 74/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.3211\n","Epoch 75/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.2841\n","Epoch 76/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.4356\n","Epoch 77/100\n","35/35 [==============================] - 0s 3ms/step - loss: 1.4038\n","Epoch 78/100\n","35/35 [==============================] - 0s 4ms/step - loss: 1.3245\n","Epoch 79/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.2966\n","Epoch 80/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.2650\n","Epoch 81/100\n","35/35 [==============================] - 0s 6ms/step - loss: 1.3018\n","Epoch 82/100\n","35/35 [==============================] - 0s 6ms/step - loss: 1.3873\n","Epoch 83/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.3030\n","Epoch 84/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.2521\n","Epoch 85/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.3605\n","Epoch 86/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.3414\n","Epoch 87/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.4510\n","Epoch 88/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.3455\n","Epoch 89/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.3831\n","Epoch 90/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.3558\n","Epoch 91/100\n","35/35 [==============================] - 0s 6ms/step - loss: 1.4077\n","Epoch 92/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.3255\n","Epoch 93/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.3138\n","Epoch 94/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.3085\n","Epoch 95/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.4080\n","Epoch 96/100\n","35/35 [==============================] - 0s 6ms/step - loss: 1.3815\n","Epoch 97/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.3619\n","Epoch 98/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.3257\n","Epoch 99/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.3417\n","Epoch 100/100\n","35/35 [==============================] - 0s 5ms/step - loss: 1.2890\n","15/15 [==============================] - 0s 2ms/step\n","... quantizing model\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["47/47 [==============================] - 1s 4ms/step - loss: 0.9952\n","Epoch 2/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.7110\n","Epoch 3/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.6125\n","Epoch 4/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5410\n","Epoch 5/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5134\n","Epoch 6/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4690\n","Epoch 7/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4567\n","Epoch 8/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4982\n","Epoch 9/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4449\n","Epoch 10/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4403\n","Epoch 11/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4199\n","Epoch 12/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4295\n","Epoch 13/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4230\n","Epoch 14/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3991\n","Epoch 15/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4017\n","Epoch 16/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4008\n","Epoch 17/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4177\n","Epoch 18/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3825\n","Epoch 19/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4070\n","Epoch 20/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3795\n","Epoch 21/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3932\n","Epoch 22/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4399\n","Epoch 23/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4147\n","Epoch 24/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4268\n","Epoch 25/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4424\n","Epoch 26/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4205\n","Epoch 27/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4093\n","Epoch 28/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3889\n","Epoch 29/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3723\n","Epoch 30/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3736\n","Epoch 31/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3876\n","Epoch 32/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4477\n","Epoch 33/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4247\n","Epoch 34/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4089\n","Epoch 35/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4120\n","Epoch 36/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3938\n","Epoch 37/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4230\n","Epoch 38/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.4142\n","Epoch 39/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.4432\n","Epoch 40/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4258\n","Epoch 41/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.3880\n","Epoch 42/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.4037\n","Epoch 43/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.4142\n","Epoch 44/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.4735\n","Epoch 45/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.4301\n","Epoch 46/100\n","47/47 [==============================] - 0s 5ms/step - loss: 0.4588\n","Epoch 47/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3849\n","Epoch 48/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4288\n","Epoch 49/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4679\n","Epoch 50/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4041\n","Epoch 51/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4199\n","Epoch 52/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4637\n","Epoch 53/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4229\n","Epoch 54/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4098\n","Epoch 55/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4198\n","Epoch 56/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4352\n","Epoch 57/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.3943\n","Epoch 58/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4004\n","Epoch 59/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4149\n","Epoch 60/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4072\n","Epoch 61/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3974\n","Epoch 62/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3949\n","Epoch 63/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4558\n","Epoch 64/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3499\n","Epoch 65/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4102\n","Epoch 66/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3417\n","Epoch 67/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4911\n","Epoch 68/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4068\n","Epoch 69/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4600\n","Epoch 70/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4014\n","Epoch 71/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4063\n","Epoch 72/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4296\n","Epoch 73/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3790\n","Epoch 74/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4078\n","Epoch 75/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4585\n","Epoch 76/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4104\n","Epoch 77/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4147\n","Epoch 78/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4256\n","Epoch 79/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3731\n","Epoch 80/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4181\n","Epoch 81/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4493\n","Epoch 82/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4368\n","Epoch 83/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4831\n","Epoch 84/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4927\n","Epoch 85/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5208\n","Epoch 86/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4255\n","Epoch 87/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4104\n","Epoch 88/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4469\n","Epoch 89/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.5092\n","Epoch 90/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4082\n","Epoch 91/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3732\n","Epoch 92/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4269\n","Epoch 93/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4234\n","Epoch 94/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4132\n","Epoch 95/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4158\n","Epoch 96/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3936\n","Epoch 97/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.3808\n","Epoch 98/100\n","47/47 [==============================] - 0s 4ms/step - loss: 0.4285\n","Epoch 99/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4608\n","Epoch 100/100\n","47/47 [==============================] - 0s 3ms/step - loss: 0.4416\n","20/20 [==============================] - 0s 2ms/step\n","... quantizing model\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["108/108 [==============================] - 1s 3ms/step - loss: 2.2323\n","Epoch 2/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8583\n","Epoch 3/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7704\n","Epoch 4/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.5884\n","Epoch 5/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.6514\n","Epoch 6/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.6453\n","Epoch 7/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.6686\n","Epoch 8/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.6463\n","Epoch 9/100\n","108/108 [==============================] - 1s 5ms/step - loss: 1.6309\n","Epoch 10/100\n","108/108 [==============================] - 1s 5ms/step - loss: 1.6302\n","Epoch 11/100\n","108/108 [==============================] - 1s 5ms/step - loss: 1.6864\n","Epoch 12/100\n","108/108 [==============================] - 1s 5ms/step - loss: 1.6589\n","Epoch 13/100\n","108/108 [==============================] - 1s 5ms/step - loss: 1.6894\n","Epoch 14/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.6573\n","Epoch 15/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.6723\n","Epoch 16/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7087\n","Epoch 17/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.6249\n","Epoch 18/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.7673\n","Epoch 19/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.6850\n","Epoch 20/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7012\n","Epoch 21/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7680\n","Epoch 22/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7165\n","Epoch 23/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7203\n","Epoch 24/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8190\n","Epoch 25/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7650\n","Epoch 26/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.6587\n","Epoch 27/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7128\n","Epoch 28/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.6851\n","Epoch 29/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7251\n","Epoch 30/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.6921\n","Epoch 31/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.6736\n","Epoch 32/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8002\n","Epoch 33/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8589\n","Epoch 34/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7272\n","Epoch 35/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7570\n","Epoch 36/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7678\n","Epoch 37/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8614\n","Epoch 38/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7661\n","Epoch 39/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8100\n","Epoch 40/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8693\n","Epoch 41/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.8488\n","Epoch 42/100\n","108/108 [==============================] - 0s 5ms/step - loss: 1.8327\n","Epoch 43/100\n","108/108 [==============================] - 1s 5ms/step - loss: 1.7899\n","Epoch 44/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.7153\n","Epoch 45/100\n","108/108 [==============================] - 1s 5ms/step - loss: 1.7714\n","Epoch 46/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.8746\n","Epoch 47/100\n","108/108 [==============================] - 1s 5ms/step - loss: 1.8845\n","Epoch 48/100\n","108/108 [==============================] - 1s 5ms/step - loss: 1.8632\n","Epoch 49/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.8968\n","Epoch 50/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7790\n","Epoch 51/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7519\n","Epoch 52/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.9074\n","Epoch 53/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.9268\n","Epoch 54/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.9075\n","Epoch 55/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7827\n","Epoch 56/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7945\n","Epoch 57/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.6998\n","Epoch 58/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8237\n","Epoch 59/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8257\n","Epoch 60/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7664\n","Epoch 61/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8146\n","Epoch 62/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7597\n","Epoch 63/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.6699\n","Epoch 64/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.7509\n","Epoch 65/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.7026\n","Epoch 66/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8167\n","Epoch 67/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8441\n","Epoch 68/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7117\n","Epoch 69/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7501\n","Epoch 70/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.6951\n","Epoch 71/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7970\n","Epoch 72/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8112\n","Epoch 73/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7421\n","Epoch 74/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7923\n","Epoch 75/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.7721\n","Epoch 76/100\n","108/108 [==============================] - 1s 5ms/step - loss: 1.7995\n","Epoch 77/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.7682\n","Epoch 78/100\n","108/108 [==============================] - 1s 5ms/step - loss: 1.7180\n","Epoch 79/100\n","108/108 [==============================] - 1s 5ms/step - loss: 1.8128\n","Epoch 80/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.8284\n","Epoch 81/100\n","108/108 [==============================] - 0s 5ms/step - loss: 1.7750\n","Epoch 82/100\n","108/108 [==============================] - 1s 5ms/step - loss: 1.8444\n","Epoch 83/100\n","108/108 [==============================] - 1s 5ms/step - loss: 1.8323\n","Epoch 84/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.8270\n","Epoch 85/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8260\n","Epoch 86/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8076\n","Epoch 87/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7723\n","Epoch 88/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7096\n","Epoch 89/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7918\n","Epoch 90/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.8748\n","Epoch 91/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.8943\n","Epoch 92/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.7688\n","Epoch 93/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7897\n","Epoch 94/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7860\n","Epoch 95/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.8159\n","Epoch 96/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7786\n","Epoch 97/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7563\n","Epoch 98/100\n","108/108 [==============================] - 0s 4ms/step - loss: 1.7931\n","Epoch 99/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7132\n","Epoch 100/100\n","108/108 [==============================] - 0s 3ms/step - loss: 1.7423\n","46/46 [==============================] - 0s 2ms/step\n","... quantizing model\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["305/305 [==============================] - 2s 3ms/step - loss: 1.7590\n","Epoch 2/100\n","305/305 [==============================] - 1s 4ms/step - loss: 1.3954\n","Epoch 3/100\n","305/305 [==============================] - 1s 4ms/step - loss: 1.3671\n","Epoch 4/100\n","305/305 [==============================] - 1s 4ms/step - loss: 1.3597\n","Epoch 5/100\n","305/305 [==============================] - 1s 3ms/step - loss: 1.3546\n","Epoch 6/100\n","305/305 [==============================] - 1s 4ms/step - loss: 1.2598\n","Epoch 7/100\n","305/305 [==============================] - 1s 4ms/step - loss: 1.2786\n","Epoch 8/100\n","305/305 [==============================] - 1s 3ms/step - loss: 1.2306\n","Epoch 9/100\n","305/305 [==============================] - 1s 4ms/step - loss: 1.1848\n","Epoch 10/100\n","305/305 [==============================] - 2s 5ms/step - loss: 1.2375\n","Epoch 11/100\n","305/305 [==============================] - 2s 5ms/step - loss: 1.1854\n","Epoch 12/100\n","305/305 [==============================] - 1s 4ms/step - loss: 1.1751\n","Epoch 13/100\n","305/305 [==============================] - 1s 3ms/step - loss: 1.1547\n","Epoch 14/100\n","305/305 [==============================] - 1s 3ms/step - loss: 1.1670\n","Epoch 15/100\n","305/305 [==============================] - 1s 3ms/step - loss: 1.0705\n","Epoch 16/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9832\n","Epoch 17/100\n","305/305 [==============================] - 1s 3ms/step - loss: 1.0659\n","Epoch 18/100\n","305/305 [==============================] - 1s 3ms/step - loss: 1.1536\n","Epoch 19/100\n","305/305 [==============================] - 1s 3ms/step - loss: 1.0807\n","Epoch 20/100\n","305/305 [==============================] - 1s 3ms/step - loss: 1.0516\n","Epoch 21/100\n","305/305 [==============================] - 1s 4ms/step - loss: 0.9501\n","Epoch 22/100\n","305/305 [==============================] - 1s 5ms/step - loss: 0.9618\n","Epoch 23/100\n","305/305 [==============================] - 1s 5ms/step - loss: 0.9446\n","Epoch 24/100\n","305/305 [==============================] - 1s 4ms/step - loss: 0.9460\n","Epoch 25/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9312\n","Epoch 26/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9288\n","Epoch 27/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9551\n","Epoch 28/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9544\n","Epoch 29/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9294\n","Epoch 30/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8958\n","Epoch 31/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9301\n","Epoch 32/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9006\n","Epoch 33/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9044\n","Epoch 34/100\n","305/305 [==============================] - 1s 5ms/step - loss: 0.9348\n","Epoch 35/100\n","305/305 [==============================] - 1s 5ms/step - loss: 0.9112\n","Epoch 36/100\n","305/305 [==============================] - 1s 5ms/step - loss: 0.8835\n","Epoch 37/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8712\n","Epoch 38/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8531\n","Epoch 39/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9466\n","Epoch 40/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8964\n","Epoch 41/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8334\n","Epoch 42/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9603\n","Epoch 43/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9458\n","Epoch 44/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8979\n","Epoch 45/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8526\n","Epoch 46/100\n","305/305 [==============================] - 1s 4ms/step - loss: 0.8365\n","Epoch 47/100\n","305/305 [==============================] - 1s 5ms/step - loss: 0.8812\n","Epoch 48/100\n","305/305 [==============================] - 1s 5ms/step - loss: 0.8988\n","Epoch 49/100\n","305/305 [==============================] - 1s 4ms/step - loss: 0.8267\n","Epoch 50/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8117\n","Epoch 51/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8657\n","Epoch 52/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8484\n","Epoch 53/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8886\n","Epoch 54/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.7893\n","Epoch 55/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.7763\n","Epoch 56/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.7629\n","Epoch 57/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.7674\n","Epoch 58/100\n","305/305 [==============================] - 1s 4ms/step - loss: 0.8038\n","Epoch 59/100\n","305/305 [==============================] - 1s 5ms/step - loss: 0.9205\n","Epoch 60/100\n","305/305 [==============================] - 1s 5ms/step - loss: 0.8980\n","Epoch 61/100\n","305/305 [==============================] - 1s 4ms/step - loss: 0.9076\n","Epoch 62/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8874\n","Epoch 63/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.7882\n","Epoch 64/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.7935\n","Epoch 65/100\n","305/305 [==============================] - 1s 4ms/step - loss: 0.8189\n","Epoch 66/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8420\n","Epoch 67/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.7953\n","Epoch 68/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8978\n","Epoch 69/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.7944\n","Epoch 70/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.7715\n","Epoch 71/100\n","305/305 [==============================] - 1s 5ms/step - loss: 0.8554\n","Epoch 72/100\n","305/305 [==============================] - 1s 5ms/step - loss: 0.8074\n","Epoch 73/100\n","305/305 [==============================] - 1s 4ms/step - loss: 0.8662\n","Epoch 74/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8773\n","Epoch 75/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9409\n","Epoch 76/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8761\n","Epoch 77/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9066\n","Epoch 78/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9615\n","Epoch 79/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9785\n","Epoch 80/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9778\n","Epoch 81/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9425\n","Epoch 82/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9478\n","Epoch 83/100\n","305/305 [==============================] - 1s 4ms/step - loss: 0.9125\n","Epoch 84/100\n","305/305 [==============================] - 1s 4ms/step - loss: 0.9751\n","Epoch 85/100\n","305/305 [==============================] - 1s 5ms/step - loss: 0.9380\n","Epoch 86/100\n","305/305 [==============================] - 1s 4ms/step - loss: 0.9462\n","Epoch 87/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9077\n","Epoch 88/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8602\n","Epoch 89/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8785\n","Epoch 90/100\n","305/305 [==============================] - 1s 4ms/step - loss: 0.9019\n","Epoch 91/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9558\n","Epoch 92/100\n","305/305 [==============================] - 1s 4ms/step - loss: 0.9235\n","Epoch 93/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8753\n","Epoch 94/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.8894\n","Epoch 95/100\n","305/305 [==============================] - 1s 4ms/step - loss: 0.8800\n","Epoch 96/100\n","305/305 [==============================] - 1s 5ms/step - loss: 0.8652\n","Epoch 97/100\n","305/305 [==============================] - 1s 5ms/step - loss: 0.8886\n","Epoch 98/100\n","305/305 [==============================] - 1s 4ms/step - loss: 0.8799\n","Epoch 99/100\n","305/305 [==============================] - 1s 3ms/step - loss: 0.9364\n","Epoch 100/100\n","305/305 [==============================] - 1s 3ms/step - loss: 1.0084\n","131/131 [==============================] - 1s 2ms/step\n","... quantizing model\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":330},"id":"Oif8RmnA7YQD","executionInfo":{"status":"error","timestamp":1681929526544,"user_tz":-180,"elapsed":34998,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}},"outputId":"409951d6-df43-4bef-972e-910f5d14e13c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","source":["pd.DataFrame(gs.cv_results_)[['param_optimizer__learning_rate','param_optimizer__beta_1','param_optimizer__beta_2','mean_test_score']]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"jK_ZH5fre6Oe","executionInfo":{"status":"ok","timestamp":1681310557489,"user_tz":-180,"elapsed":426,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}},"outputId":"f5114684-4ac6-4c51-fd2c-f601261d04ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  param_optimizer__learning_rate param_optimizer__beta_1  \\\n","0                          0.001                     0.9   \n","1                          0.002                     0.9   \n","2                          0.001                     0.9   \n","3                          0.002                     0.9   \n","\n","  param_optimizer__beta_2  mean_test_score  \n","0                     0.9         0.841169  \n","1                     0.9         0.814168  \n","2                   0.099         0.627065  \n","3                   0.099         0.147395  "],"text/html":["\n","  <div id=\"df-c196a3a1-4592-43d3-ba6f-f7a76e6d8647\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>param_optimizer__learning_rate</th>\n","      <th>param_optimizer__beta_1</th>\n","      <th>param_optimizer__beta_2</th>\n","      <th>mean_test_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.001</td>\n","      <td>0.9</td>\n","      <td>0.9</td>\n","      <td>0.841169</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.002</td>\n","      <td>0.9</td>\n","      <td>0.9</td>\n","      <td>0.814168</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.001</td>\n","      <td>0.9</td>\n","      <td>0.099</td>\n","      <td>0.627065</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.002</td>\n","      <td>0.9</td>\n","      <td>0.099</td>\n","      <td>0.147395</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c196a3a1-4592-43d3-ba6f-f7a76e6d8647')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c196a3a1-4592-43d3-ba6f-f7a76e6d8647 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c196a3a1-4592-43d3-ba6f-f7a76e6d8647');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["bpr={'loss': 'categorical_crossentropy', 'optimizer': 'adam', 'optimizer__beta_1': 0.9, 'optimizer__beta_2': 0.9, 'optimizer__learning_rate': 0.002}\n","clfx = KerasClassifier(\n","    get_model,\n","    epochs=100,\n","    **bpr\n",")\n","clfx.fit(X_train,y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6xXzx5zxi6_Z","executionInfo":{"status":"ok","timestamp":1681304515580,"user_tz":-180,"elapsed":83682,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}},"outputId":"132b04de-cdf7-4d64-9c32-235ecfa146ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["164/164 [==============================] - 1s 3ms/step - loss: 2.8603\n","Epoch 2/100\n","164/164 [==============================] - 1s 3ms/step - loss: 1.0766\n","Epoch 3/100\n","164/164 [==============================] - 1s 4ms/step - loss: 0.8790\n","Epoch 4/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.7852\n","Epoch 5/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.7272\n","Epoch 6/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.6506\n","Epoch 7/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.6188\n","Epoch 8/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.6365\n","Epoch 9/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.6577\n","Epoch 10/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.6760\n","Epoch 11/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.6564\n","Epoch 12/100\n","164/164 [==============================] - 1s 4ms/step - loss: 0.6575\n","Epoch 13/100\n","164/164 [==============================] - 1s 5ms/step - loss: 0.6438\n","Epoch 14/100\n","164/164 [==============================] - 1s 5ms/step - loss: 0.6296\n","Epoch 15/100\n","164/164 [==============================] - 1s 5ms/step - loss: 0.5583\n","Epoch 16/100\n","164/164 [==============================] - 1s 4ms/step - loss: 0.5967\n","Epoch 17/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.5815\n","Epoch 18/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.5351\n","Epoch 19/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.5462\n","Epoch 20/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.5494\n","Epoch 21/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4747\n","Epoch 22/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.5024\n","Epoch 23/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.5256\n","Epoch 24/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.5369\n","Epoch 25/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4544\n","Epoch 26/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4779\n","Epoch 27/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4981\n","Epoch 28/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4809\n","Epoch 29/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4687\n","Epoch 30/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4832\n","Epoch 31/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4378\n","Epoch 32/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4776\n","Epoch 33/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4782\n","Epoch 34/100\n","164/164 [==============================] - 1s 4ms/step - loss: 0.4696\n","Epoch 35/100\n","164/164 [==============================] - 1s 5ms/step - loss: 0.5063\n","Epoch 36/100\n","164/164 [==============================] - 1s 5ms/step - loss: 0.4876\n","Epoch 37/100\n","164/164 [==============================] - 1s 5ms/step - loss: 0.4181\n","Epoch 38/100\n","164/164 [==============================] - 1s 4ms/step - loss: 0.4639\n","Epoch 39/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.5052\n","Epoch 40/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4202\n","Epoch 41/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4494\n","Epoch 42/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4503\n","Epoch 43/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4717\n","Epoch 44/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.5008\n","Epoch 45/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4677\n","Epoch 46/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4607\n","Epoch 47/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.5085\n","Epoch 48/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4906\n","Epoch 49/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4789\n","Epoch 50/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.5213\n","Epoch 51/100\n","164/164 [==============================] - 1s 6ms/step - loss: 0.4576\n","Epoch 52/100\n","164/164 [==============================] - 1s 5ms/step - loss: 0.4755\n","Epoch 53/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4199\n","Epoch 54/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4424\n","Epoch 55/100\n","164/164 [==============================] - 1s 4ms/step - loss: 0.4694\n","Epoch 56/100\n","164/164 [==============================] - 1s 5ms/step - loss: 0.4174\n","Epoch 57/100\n","164/164 [==============================] - 1s 5ms/step - loss: 0.4778\n","Epoch 58/100\n","164/164 [==============================] - 1s 5ms/step - loss: 0.4594\n","Epoch 59/100\n","164/164 [==============================] - 1s 4ms/step - loss: 0.4315\n","Epoch 60/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4980\n","Epoch 61/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.5063\n","Epoch 62/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4996\n","Epoch 63/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4643\n","Epoch 64/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4768\n","Epoch 65/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4429\n","Epoch 66/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4213\n","Epoch 67/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.3701\n","Epoch 68/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4136\n","Epoch 69/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4170\n","Epoch 70/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.3809\n","Epoch 71/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4228\n","Epoch 72/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4407\n","Epoch 73/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4250\n","Epoch 74/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4112\n","Epoch 75/100\n","164/164 [==============================] - 1s 4ms/step - loss: 0.3989\n","Epoch 76/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.3682\n","Epoch 77/100\n","164/164 [==============================] - 1s 4ms/step - loss: 0.4451\n","Epoch 78/100\n","164/164 [==============================] - 1s 5ms/step - loss: 0.3935\n","Epoch 79/100\n","164/164 [==============================] - 1s 5ms/step - loss: 0.3693\n","Epoch 80/100\n","164/164 [==============================] - 1s 5ms/step - loss: 0.4292\n","Epoch 81/100\n","164/164 [==============================] - 1s 4ms/step - loss: 0.3642\n","Epoch 82/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4104\n","Epoch 83/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.3958\n","Epoch 84/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4114\n","Epoch 85/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4059\n","Epoch 86/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4594\n","Epoch 87/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.3643\n","Epoch 88/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.3427\n","Epoch 89/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.3241\n","Epoch 90/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.3287\n","Epoch 91/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.3798\n","Epoch 92/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4216\n","Epoch 93/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4186\n","Epoch 94/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.3881\n","Epoch 95/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.3787\n","Epoch 96/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.3933\n","Epoch 97/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.4452\n","Epoch 98/100\n","164/164 [==============================] - 1s 3ms/step - loss: 0.3831\n","Epoch 99/100\n","164/164 [==============================] - 1s 4ms/step - loss: 0.3766\n","Epoch 100/100\n","164/164 [==============================] - 1s 5ms/step - loss: 0.3611\n"]},{"output_type":"execute_result","data":{"text/plain":["KerasClassifier(\n","\tmodel=<function get_model at 0x7f222024de50>\n","\tbuild_fn=None\n","\twarm_start=False\n","\trandom_state=None\n","\toptimizer=adam\n","\tloss=categorical_crossentropy\n","\tmetrics=None\n","\tbatch_size=None\n","\tvalidation_batch_size=None\n","\tverbose=1\n","\tcallbacks=None\n","\tvalidation_split=0.0\n","\tshuffle=True\n","\trun_eagerly=False\n","\tepochs=100\n","\toptimizer__beta_1=0.9\n","\toptimizer__beta_2=0.9\n","\toptimizer__learning_rate=0.002\n","\tclass_weight=None\n",")"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n","\tmodel=&lt;function get_model at 0x7f222024de50&gt;\n","\tbuild_fn=None\n","\twarm_start=False\n","\trandom_state=None\n","\toptimizer=adam\n","\tloss=categorical_crossentropy\n","\tmetrics=None\n","\tbatch_size=None\n","\tvalidation_batch_size=None\n","\tverbose=1\n","\tcallbacks=None\n","\tvalidation_split=0.0\n","\tshuffle=True\n","\trun_eagerly=False\n","\tepochs=100\n","\toptimizer__beta_1=0.9\n","\toptimizer__beta_2=0.9\n","\toptimizer__learning_rate=0.002\n","\tclass_weight=None\n",")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n","\tmodel=&lt;function get_model at 0x7f222024de50&gt;\n","\tbuild_fn=None\n","\twarm_start=False\n","\trandom_state=None\n","\toptimizer=adam\n","\tloss=categorical_crossentropy\n","\tmetrics=None\n","\tbatch_size=None\n","\tvalidation_batch_size=None\n","\tverbose=1\n","\tcallbacks=None\n","\tvalidation_split=0.0\n","\tshuffle=True\n","\trun_eagerly=False\n","\tepochs=100\n","\toptimizer__beta_1=0.9\n","\toptimizer__beta_2=0.9\n","\toptimizer__learning_rate=0.002\n","\tclass_weight=None\n",")</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["clfx.score(X_test,y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZBWirLx6j08_","executionInfo":{"status":"ok","timestamp":1681304567409,"user_tz":-180,"elapsed":1792,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}},"outputId":"384efabd-8972-4d86-d579-07060265f712"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["71/71 [==============================] - 1s 3ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["0.8875055580257892"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["pd.DataFrame(gs.cv_results_)[['params','mean_test_score']]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1068},"executionInfo":{"status":"ok","timestamp":1681304314976,"user_tz":-180,"elapsed":583,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}},"outputId":"a61b952f-7f67-4503-e774-ea903534754a","id":"tjL93StDi7qo"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               params  mean_test_score\n","0   {'loss': 'categorical_crossentropy', 'optimize...         0.852287\n","1   {'loss': 'categorical_crossentropy', 'optimize...         0.726811\n","2   {'loss': 'categorical_crossentropy', 'optimize...         0.879606\n","3   {'loss': 'categorical_crossentropy', 'optimize...         0.824651\n","4   {'loss': 'categorical_crossentropy', 'optimize...         0.741741\n","5   {'loss': 'categorical_crossentropy', 'optimize...         0.858323\n","6   {'loss': 'categorical_crossentropy', 'optimize...         0.817662\n","7   {'loss': 'categorical_crossentropy', 'optimize...         0.654384\n","8   {'loss': 'categorical_crossentropy', 'optimize...         0.807814\n","9   {'loss': 'categorical_crossentropy', 'optimize...         0.827510\n","10  {'loss': 'categorical_crossentropy', 'optimize...         0.283037\n","11  {'loss': 'categorical_crossentropy', 'optimize...         0.736023\n","12  {'loss': 'categorical_crossentropy', 'optimize...         0.860864\n","13  {'loss': 'categorical_crossentropy', 'optimize...         0.664867\n","14  {'loss': 'categorical_crossentropy', 'optimize...         0.833863\n","15  {'loss': 'categorical_crossentropy', 'optimize...         0.774460\n","16  {'loss': 'categorical_crossentropy', 'optimize...         0.721728\n","17  {'loss': 'categorical_crossentropy', 'optimize...         0.804320\n","18  {'loss': 'categorical_crossentropy', 'optimize...         0.518424\n","19  {'loss': 'categorical_crossentropy', 'optimize...         0.183609\n","20  {'loss': 'categorical_crossentropy', 'optimize...         0.418679\n","21  {'loss': 'categorical_crossentropy', 'optimize...         0.713787\n","22  {'loss': 'categorical_crossentropy', 'optimize...         0.320203\n","23  {'loss': 'categorical_crossentropy', 'optimize...         0.575604\n","24  {'loss': 'categorical_crossentropy', 'optimize...         0.776684\n","25  {'loss': 'categorical_crossentropy', 'optimize...         0.613405\n","26  {'loss': 'categorical_crossentropy', 'optimize...         0.713469"],"text/html":["\n","  <div id=\"df-1dda8bf8-0818-44ce-a3f3-3b31d38911a6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>params</th>\n","      <th>mean_test_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.852287</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.726811</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.879606</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.824651</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.741741</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.858323</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.817662</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.654384</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.807814</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.827510</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.283037</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.736023</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.860864</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.664867</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.833863</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.774460</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.721728</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.804320</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.518424</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.183609</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.418679</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.713787</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.320203</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.575604</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.776684</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.613405</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>{'loss': 'categorical_crossentropy', 'optimize...</td>\n","      <td>0.713469</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1dda8bf8-0818-44ce-a3f3-3b31d38911a6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1dda8bf8-0818-44ce-a3f3-3b31d38911a6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1dda8bf8-0818-44ce-a3f3-3b31d38911a6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"FpObLJoRAfKY","executionInfo":{"status":"error","timestamp":1681061592314,"user_tz":-180,"elapsed":380,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}},"outputId":"4c6f2148-f66d-472d-9309-33bd7f379967"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-94ca52e6cd74>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \"\"\"\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0m_check_refit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_check_refit\u001b[0;34m(search_cv, attr)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_refit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msearch_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0;34mf\"This {type(search_cv).__name__} instance was initialized with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0;34mf\"`refit=False`. {attr} is available only after refitting on the best \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: This GridSearchCV instance was initialized with `refit=False`. score is available only after refitting on the best parameters. You can refit an estimator manually using the `best_params_` attribute"]}]},{"cell_type":"code","source":["for fname in get_csv_filenames():\n","  train_csv(fname)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eTbV9bf1SdTl","outputId":"c59d5ee3-fd2c-45dc-ce43-5180b145421f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["less_pendigitssummary\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 681ms/step\n","... quantizing model\n","71/71 [==============================] - 1s 3ms/step - loss: 0.5281 - accuracy: 0.8395\n","less_cardiosummary\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 683ms/step\n","... quantizing model\n","20/20 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8824\n","less_Harsummary\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 682ms/step\n","... quantizing model\n","28/28 [==============================] - 0s 4ms/step - loss: 1.1668 - accuracy: 0.5333\n","less_winequality_redsummary\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 663ms/step\n","... quantizing model\n","15/15 [==============================] - 0s 3ms/step - loss: 1.2332 - accuracy: 0.5708\n","less_gasIdsummary\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 669ms/step\n","... quantizing model\n","131/131 [==============================] - 1s 3ms/step - loss: 0.5700 - accuracy: 0.8212\n","less_winequality_whitesummary\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n","WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 664ms/step\n","... quantizing model\n","46/46 [==============================] - 0s 3ms/step - loss: 1.6193 - accuracy: 0.5048\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('winequality_white.csv', header=None)\n","Xx = df.iloc[:, :-1]\n","y = df.iloc[:, -1]\n","X = pd.DataFrame(Xx.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))))"],"metadata":{"id":"6PmoZA1QvPZy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pip install h5py\n"],"metadata":{"id":"f5iODGC7ZaP5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d6978bc5-eba8-4566-b3e7-2729c1434706"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (3.1.0)\n","Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.8/dist-packages (from h5py) (1.22.4)\n"]}]},{"cell_type":"code","source":["from keras.models import load_model\n","\n","# Load the model from the HDF5 file\n","model = load_model('best_tmp.h5', custom_objects={'QActivation': QActivation,'QDense':QDense})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348},"id":"SURAbh5-mpe0","outputId":"145a5308-ca65-4fcb-83ff-7cf86302ff2b","executionInfo":{"status":"error","timestamp":1681483035055,"user_tz":-180,"elapsed":575,"user":{"displayName":"ΠΑΝΑΓΙΩΤΗΣ ΠΑΠΑΝΙΚΟΛΑΟΥ","userId":"03331666574765439918"}}},"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-d0eec0ed6900>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the model from the HDF5 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_tmp.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'QActivation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mQActivation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'QDense'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mQDense\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    228\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    231\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                             )\n","\u001b[0;31mOSError\u001b[0m: No file or directory found at best_tmp.h5"]}]},{"cell_type":"code","source":["#x_hack = tf.random.normal(shape=(1,16),dtype=tf.float32)\n","#x_hack = tf.abs(x_hack)\n","#output=model.predict(x_hack)\n","#inpux = np.expand_dims(X.iloc[0], axis=0)\n","inpux = X.iloc[0:1]\n","lo=get_layer_outputs(model,inpux)\n","yoyo = lo[2]\n","gol = lo[4]\n","lo"],"metadata":{"id":"XlKZSNDWobPr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d4e065d4-4709-403b-c300-da957a1e2551"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([[0.3125, 0.1875, 0.1875, 0.3125, 0.125 , 0.125 , 0.375 , 0.25  ,\n","         0.25  , 0.25  , 0.125 ]], dtype=float32),\n"," array([[-0.15625 ,  1.625   , -0.03125 , -0.25    ,  0.09375 , -0.1875  ,\n","          0.59375 , -0.25    , -0.09375 ,  0.      ,  0.28125 ,  0.15625 ,\n","          0.1875  ,  0.15625 ,  0.03125 , -0.21875 ,  1.9375  , -0.1875  ,\n","          0.234375, -0.21875 ,  0.      ,  0.15625 ,  0.125   ,  1.625   ,\n","          0.0625  , -0.0625  , -0.3125  ,  0.4375  , -0.0625  , -0.4375  ,\n","          0.4375  ,  0.      ,  0.53125 ,  0.28125 , -0.09375 ,  0.21875 ,\n","         -0.25    , -0.125   ,  0.125   , -0.078125]], dtype=float32),\n"," array([[-1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n","          1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n","         -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,\n","         -1.]], dtype=float32),\n"," array([[-6., -3.,  0.,  2., -3., -4., -5.]], dtype=float32),\n"," array([[2.9106444e-04, 5.8461856e-03, 1.1742377e-01, 8.6765087e-01,\n","         5.8461856e-03, 2.1506916e-03, 7.9119514e-04]], dtype=float32)]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["xrisos = np.argmax(gol,axis=1)\n","qinp = lo[0]"],"metadata":{"id":"W21T375ey6Fc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import h5py\n","\n","filename = \"weightnnwinequality_white.h5\"\n","\n","h5 = h5py.File(filename,'r')\n","\n","h5.visit(print)\n","#print(h5['q_dense/q_dense/kernel:0'][:,:])\n","#print(h5['q_batch_normalization/q_batch_normalization/beta:0'][:])\n","sw0 = h5['q_dense/q_dense/kernel:0'][:,:]\n","sw1 = h5['q_dense_1/q_dense_1/kernel:0'][:,:]\n","\n","h5.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nhtkb7dKLxPq","outputId":"28d501d1-d0f9-4ed8-ca12-e703c10d4ebe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["activation\n","q_activation\n","q_activation_1\n","q_dense\n","q_dense/q_dense\n","q_dense/q_dense/kernel:0\n","q_dense_1\n","q_dense_1/q_dense_1\n","q_dense_1/q_dense_1/kernel:0\n","top_level_model_weights\n"]}]},{"cell_type":"code","source":["matz=np.sign(sw0)\n","abz=np.abs(matz)\n","sinz=np.maximum(matz,0)\n","binst(abz.flatten())[::-1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"id":"Gn0OVXwMtwVD","outputId":"476fbadb-ea53-4602-9cc4-824062fd1a29"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'10011001110000000100111010000101000100011001101110011010111111111100011111111110011001101001111010110011101101001011101001001110011000111011011011110110101101001111101101010110110110010101001010110101001110011011110011011011100001110110110101110111111100111011101110010000001111011111011101101011111011011100011111011001101000001101010101100111000001000001000111101010100110101001010000010110000111000110100101011110101011111110110100000011'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["cnz=np.count_nonzero(sw0, axis=0)\n","''.join([f\"0{i}\" for i in cnz])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":39},"id":"75hA3mk4cdJJ","outputId":"5af46201-68e1-4598-fc10-2f412d17dd85"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'06070806070407070707040806050804090607070707080808050305010906050503060906060307'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["hay=binst(yoyo[0])\n","jay = '0100101001111110101011111001001111010010'[::-1]\n","jay"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":39},"id":"felrSlVJedqO","outputId":"e8b10d62-1a5b-45ad-a320-c06e77197a9f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'0100101111001001111101010111111001010010'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["def dbytes(mat):\n","  kay=mat.flatten().astype(np.uint8).tobytes()\n","  return binascii.hexlify(kay).decode()"],"metadata":{"id":"3WN6HY_igOES"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.sparse import csr_matrix\n","spa=csr_matrix(sw1.T)\n","#spa.data,spa.indices,spa.indptr\n","svals=binst(np.maximum(spa.data,0))\n","scols=dbytes(spa.indices[::-1])\n","srows=dbytes(spa.indptr[::-1])\n","svals,scols,srows"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KIEYm3DPhKFm","outputId":"53d686ba-8f91-46aa-ade6-e664e01935d7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('0100000010110010011000100000110000101111111100111011000110111010101011011001010',\n"," '2625232221201e1b1817141211100d0c0605040201211f17100d0b211c1615100c0825211f1817100f0125242119181412092625221f1e1c1817161413100b0a07261c171412100f0b0a0907060401',\n"," '4f3a342d251d0e00')"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["lo[3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vOOG6WG0oQj_","outputId":"c50d4cc2-f92e-4563-aece-662a6fbfc22f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-6., -3.,  0.,  2., -3., -4., -5.]], dtype=float32)"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["sw1.T"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"drqNXCwhj9I6","outputId":"90d674fe-e2af-42fa-a2d1-f5f6e1348e20"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0., -1.,  0.,  0.,  1.,  0., -1.,  1.,  0., -1., -1.,  1.,  0.,\n","         0.,  0.,  1., -1.,  0.,  1.,  0.,  1.,  0.,  0., -1.,  0.,  0.,\n","         0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n","         0.],\n","       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0., -1.,  1.,  0.,\n","         0.,  0.,  0., -1.,  0.,  0.,  1.,  1.,  0.,  1., -1.,  1.,  0.,\n","         0.,  0.,  1.,  0., -1., -1.,  0.,  0., -1.,  0.,  0.,  1.,  1.,\n","         0.],\n","       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n","         0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1., -1.,\n","         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  1.,  1.,  0.,\n","         0.],\n","       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n","         0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,\n","         0.,  0.,  0.,  0.,  0.,  1.,  0., -1.,  0.,  0.,  0.,  1.,  0.,\n","         0.],\n","       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0., -1.,\n","         0.,  0.,  0., -1.,  0.,  0.,  0.,  0., -1.,  1.,  0.,  0.,  0.,\n","         0.,  0.,  1.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n","         0.],\n","       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n","        -1.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n","         0.,  0.,  0.,  0.,  0.,  1.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n","         0.],\n","       [ 0., -1., -1.,  0.,  1.,  1., -1.,  0.,  0.,  0.,  0.,  0., -1.,\n","         1.,  0.,  0., -1., -1.,  1.,  0.,  1.,  0.,  0., -1.,  1.,  0.,\n","         0., -1.,  0.,  0., -1.,  0., -1., -1., -1., -1.,  0.,  1., -1.,\n","         0.]], dtype=float32)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["nn=np.count_nonzero(sw1, axis=0)\n","oh=(lo[3]+nn)/2\n","lo[3],oh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uHFyK_dx5_Np","outputId":"e0b6647a-6d03-468c-ef6c-3578718dbfe6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[-6., -3.,  0.,  2., -3., -4., -5.]], dtype=float32),\n"," array([[4., 6., 4., 5., 2., 1., 8.]]))"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["np.max(np.abs(sw0.T),axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wovagrYV4S9Z","outputId":"56ceb7ec-8cc2-4878-c37b-0eb1ca385966"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.25, 1.  , 0.5 , 0.5 , 0.5 , 0.5 , 0.5 , 0.5 , 0.5 , 0.25, 0.5 ,\n","       0.25, 0.5 , 0.5 , 0.5 , 0.5 , 1.  , 0.5 , 0.25, 0.5 , 0.5 , 0.5 ,\n","       0.5 , 1.  , 0.25, 0.5 , 0.5 , 0.5 , 0.5 , 0.5 , 0.5 , 0.5 , 0.5 ,\n","       0.5 , 0.5 , 0.25, 0.5 , 0.5 , 0.5 , 0.25], dtype=float32)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["def mysign(a):\n","  signs = np.sign(a)\n","\n","  # Replace the sign of the zeroes with 1 (positive) or -1 (negative)\n","  signs_no_zero = np.where(signs == 0, 1, signs)\n","  return signs_no_zero"],"metadata":{"id":"Pm0qdICClLLZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def grup(x):\n","  x1 = x @ sw0\n","  x2 = mysign(x1)\n","  x3 = x2 @ sw1\n","  return (x1,x2,x3)\n","def drut(x):\n","  x1 = x @ np.sign(sw0)\n","  x2 = mysign(x1)\n","  x3 = x2 @ sw1\n","  am = np.argmax(x3,axis=1)\n","  return am"],"metadata":{"id":"z1uLXHm762op"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xrisos[0:20]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UoZUBU02rtoC","outputId":"37b6ab6d-9e9a-43bc-ae45-471c7eb54757"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3, 3, 2, 3, 3])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["drut(qinp)[0:20]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oUrpcFmBbP8z","outputId":"5935e192-57fc-41f1-b63e-06cbe8f840d6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3, 3, 2, 3, 3])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["np.where(np.not_equal(yoyo, grup(qinp)[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VgcQ5sQxptPs","outputId":"161806bd-4e6c-4ac5-db22-ddafb2b5cc29"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([], dtype=int64), array([], dtype=int64))"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["import binascii\n","def binst(yy):\n","  yozo = np.maximum(yy,0)\n","  asbin=yozo.astype(np.uint8).tobytes()\n","  bs=binascii.hexlify(asbin).decode()[1::2]\n","  return bs[::-1]\n","\n","[print(binst(yy)) for yy in yoyo]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_s5UYjJXsIFZ","outputId":"d91f414d-dde4-4259-e679-692116657536"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0100101111001001111101010111111001010010\n"]},{"output_type":"execute_result","data":{"text/plain":["[None]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["y[0:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EG19gGCVcG76","outputId":"d4de481b-9277-47c7-966c-034b9b5beacc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    3\n","1    3\n","2    3\n","3    3\n","4    3\n","5    3\n","6    3\n","7    3\n","8    3\n","9    3\n","Name: 11, dtype: int64"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["glo = lo[2][175]\n","gor = grup(qinp[175])[1]\n","glo, gor, np.where(np.not_equal(glo,gor))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kFyrR6SEd2a6","outputId":"3c113fbc-33df-4e94-98ff-80c10666d1e3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([-1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n","        -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n","         1.,  1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,\n","        -1.], dtype=float32),\n"," array([-1., -1., -1., -1., -1., -1., -1., -1.,  1.,  0.,  0., -1.,  1.,\n","        -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n","         1.,  1., -1., -1., -1.,  1.,  0., -1.,  1., -1., -1., -1., -1.,\n","        -1.], dtype=float32),\n"," (array([ 9, 10, 32]),))"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["#dut = yoyo @ (np.sign(swax))\n","#dd , gg = np.argmax(dut,axis=1),np.argmax(gol,axis=1)\n","hm=np.where(np.not_equal(drut(qinp),y[0:199]))\n","ex=np.where(np.not_equal(xrisos,y[0:199]))\n","#(dd[hm],gg[hm],hm)\n","hm,ex,np.where(np.not_equal(hm,ex))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GW6EbDhJsOvA","outputId":"98d6b8dd-0551-4024-d82b-93eea6fdb291"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((array([ 13,  27,  29,  49,  74,  82,  86,  93, 114, 148, 152, 154, 160,\n","         161, 162, 166, 180]),),\n"," (array([ 13,  27,  29,  49,  74,  82,  86,  93, 114, 148, 152, 154, 160,\n","         161, 162, 166, 180]),),\n"," (array([], dtype=int64), array([], dtype=int64)))"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["h5.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":556},"id":"AZbqv15wNqIu","outputId":"2482cd41-22bb-4873-8c42-10552780ba14"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    400\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/h5py/_hl/base.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mKeysViewHDF5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeysView\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"<KeysViewHDF5 {}>\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0m__repr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/_collections_abc.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;34m\"\"\" Number of members attached to this group \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwith_phil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5g.pyx\u001b[0m in \u001b[0;36mh5py.h5g.GroupID.get_num_objs\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Invalid group (or file) id (invalid group (or file) ID)"]}]},{"cell_type":"code","source":["h5['q_dense_1/q_dense_1/kernel:0'][:,:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":462},"id":"aI0A96aNPZw9","outputId":"f2e59f72-d106-4553-fa1f-85b693b1d197"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-d168f28e0cf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'q_dense_1/q_dense_1/kernel:0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Invalid location identifier (invalid location identifier)"]}]},{"cell_type":"code","source":["list(QBatchNormalization().quantizers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vQAg-y66TSHQ","outputId":"4bfd20e9-2560-47b2-9496-185d5010dcb6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<qkeras.quantizers.quantized_relu_po2 at 0x7fb3e48dd4f0>,\n"," <qkeras.quantizers.quantized_po2 at 0x7fb3e3a95610>,\n"," <qkeras.quantizers.quantized_po2 at 0x7fb3e3a95fd0>,\n"," <qkeras.quantizers.quantized_relu_po2 at 0x7fb3e3a955b0>]"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["import keras.backend as K\n","\n","def get_layer_outputs(model, x):\n","    \"\"\"\n","    Returns the output of every layer in a Keras model evaluated at the input x.\n","    \n","    Args:\n","    model: A Keras model object.\n","    x: The input to the model as a Numpy array or a list of Numpy arrays.\n","    \n","    Returns:\n","    A list of Numpy arrays, where the i-th element is the output of the i-th layer\n","    in the model evaluated at the input x.\n","    \"\"\"\n","    # Create a function that computes the output of every layer given the input\n","    layer_outputs = [layer.output for layer in model.layers]\n","    layer_eval_fn = K.function(inputs=[model.input], outputs=layer_outputs)\n","    \n","    # Evaluate the function at the input\n","    output_values = layer_eval_fn([x])\n","    \n","    return output_values\n"],"metadata":{"id":"qjpdNkMXUCXh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import load_model\n","def get_results(fname):\n","    df = pd.read_csv(fname+\".csv\", header=None)\n","    X = df.iloc[:, :-1]\n","    \n","    X = pd.DataFrame(X.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))))\n","    \n","    model = load_model(fname+\"tnn.h5\", custom_objects={'QActivation': QActivation,'QDense':QDense})\n","   \n","    output=model.predict(X)\n","    clases = np.argmax(output, axis=1)\n","    return clases"],"metadata":{"id":"WKdtNMBAhe5O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_results(\"pendigits\")[0:14]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Z6PkxAfin56","outputId":"91d1e518-aa07-4e36-e0a6-358ee76814f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n","/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["235/235 [==============================] - 4s 2ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([8, 2, 1, 4, 1, 6, 4, 0, 5, 0, 9, 8, 5, 5])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def write_strings_to_file(strings, file_path):\n","    with open(file_path, 'w') as file:\n","        for string in strings:\n","            file.write(str(string) + '\\n')"],"metadata":{"id":"2rVg94yci8af"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for fname in get_csv_filenames():\n","  gres = get_results(fname).tolist()\n","  write_strings_to_file(gres,'results_'+fname+'.results')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xsBYR8kUjBrb","outputId":"6606c12f-ecf2-4a7b-dfed-9e957f9f404e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["235/235 [==============================] - 1s 3ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["67/67 [==============================] - 0s 2ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["154/154 [==============================] - 1s 2ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["50/50 [==============================] - 0s 2ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["435/435 [==============================] - 1s 2ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["93/93 [==============================] - 0s 2ms/step\n"]}]},{"cell_type":"code","source":["inpux = X.iloc[0:1]\n","#inpux = np.array([[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]])\n","lo=get_layer_outputs(model,inpux)\n","yoyo = lo[2]\n","gol = lo[4]\n","lo"],"metadata":{"id":"wW9q0LtTn5Fd"},"execution_count":null,"outputs":[]}]}
