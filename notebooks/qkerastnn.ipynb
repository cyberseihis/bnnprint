{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yk_oLILjcdDrjCe6KQ9nhWHcGbQys55V",
      "authorship_tag": "ABX9TyP/+0AsV3zSCE84XS4gG+0N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyberseihis/bnnprint/blob/main/notebooks/qkerastnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install keras-tuner QKeras"
      ],
      "metadata": {
        "id": "inCvvA6Y12bn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "010536b9-e1b0-4701-c076-a55bfb5321ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.3-py3-none-any.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.1/172.1 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting QKeras\n",
            "  Downloading QKeras-0.9.0-py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.3 in /usr/local/lib/python3.9/dist-packages (from keras-tuner) (3.20.3)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from keras-tuner) (2.27.1)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.9/dist-packages (from keras-tuner) (2.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from keras-tuner) (23.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from QKeras) (1.22.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.9/dist-packages (from QKeras) (3.0)\n",
            "Collecting pyparser\n",
            "  Downloading pyparser-1.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from QKeras) (1.2.2)\n",
            "Collecting tensorflow-model-optimization>=0.2.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from QKeras) (1.10.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from QKeras) (67.6.1)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.9/dist-packages (from QKeras) (4.65.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.23.1->QKeras) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.23.1->QKeras) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (16.0.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (0.32.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.7)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (2.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (4.5.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (23.3.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (1.53.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (2.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (2.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (3.3.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization>=0.2.1->QKeras) (0.1.8)\n",
            "Collecting parse==1.6.5\n",
            "  Downloading parse-1.6.5.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (2.0.12)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->keras-tuner) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow>=2.0->keras-tuner) (0.0.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (2.17.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (3.4.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (6.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (3.2.2)\n",
            "Building wheels for collected packages: pyparser, parse\n",
            "  Building wheel for pyparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyparser: filename=pyparser-1.0-py3-none-any.whl size=4941 sha256=03eda82a9c2d1f68875d22283bf7284879789c6ce6938867333b4e6ebbbe9519\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/a4/1a/fdbe78211760c69a9c7635d224d3683c8ed2519e01f53a81e0\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.6.5-py3-none-any.whl size=18174 sha256=a508d9c3bf3f33912886f7f06d47bb3a0fd8ccfaef7302031ceb664d7c93d423\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/ef/ff/5004e21f680c6489785b14199d1716e5db6eb05ca497068b1f\n",
            "Successfully built pyparser parse\n",
            "Installing collected packages: parse, kt-legacy, tensorflow-model-optimization, pyparser, keras-tuner, QKeras\n",
            "Successfully installed QKeras-0.9.0 keras-tuner-1.3.3 kt-legacy-1.0.4 parse-1.6.5 pyparser-1.0 tensorflow-model-optimization-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_csv_filenames():\n",
        "    filenames = os.listdir()\n",
        "    csv_filenames = [os.path.splitext(filename)[0] for filename in filenames if filename.endswith(\".csv\")]\n",
        "    return csv_filenames"
      ],
      "metadata": {
        "id": "oHc51wQaItjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras_tuner import HyperParameters\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# data and metric imports\n",
        "import sklearn.model_selection\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "\n",
        "from qkeras import *\n",
        "import qkeras.utils as qutils\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build_model(input_shape, output_shape, hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(QActivation(\"quantized_bits(4, keep_negative=0)\"))\n",
        "    model.add(QDense(units=40,kernel_quantizer=\"ternary\", use_bias=False, input_shape=(input_shape,)))\n",
        "    #model.add(layers.BatchNormalization(scale=False))\n",
        "    #model.add(layers.Activation('relu'))\n",
        "    model.add(QActivation(\"binary\"))\n",
        "    #model.add(layers.Dense(units=output_shape))\n",
        "    #model.add(layers.Dropout(rate=hp.Float(\"dropout\", min_value=0, max_value=0.4)))\n",
        "    model.add(QDense(units=output_shape, kernel_quantizer=\"ternary(alpha=1)\", use_bias=False))\n",
        "    model.add(layers.Activation('softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        #maybe I could add more hyperparameters\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Float(\"learning_rate\", min_value=0.001, max_value=0.02)),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_csv(fname,tri=20,ep=50):\n",
        "    df = pd.read_csv(fname+'.csv', header=None)\n",
        "    X = df.iloc[:, :-1]\n",
        "    y = df.iloc[:, -1]\n",
        "    X = pd.DataFrame(X.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))))\n",
        "    X_train, X_test, y_train, y_test = \\\n",
        "        sklearn.model_selection.train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    (_, input_shape) = X.shape\n",
        "    output_shape = y.nunique()\n",
        "    y_train = to_categorical(y_train, num_classes=output_shape)\n",
        "    y_test = to_categorical(y_test, num_classes=output_shape)\n",
        "\n",
        "    def my_builder(hp):\n",
        "        return build_model(input_shape, output_shape, hp)\n",
        "\n",
        "    tuna = kt.BayesianOptimization(\n",
        "        hypermodel=my_builder,\n",
        "        objective=\"val_accuracy\",\n",
        "        max_trials=tri,\n",
        "        project_name=\"proj\"+fname\n",
        "    )\n",
        "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "    tuna.search(X_train, y_train, epochs=ep, validation_data=(X_test, y_test), callbacks=[early_stop])\n",
        "    print(fname+\"summary\")\n",
        "    #tuna.results_summary()\n",
        "    model = tuna.get_best_models(num_models=1)[0]\n",
        "    x_hack = tf.random.normal(shape=(1,input_shape),dtype=tf.float32)\n",
        "    output=model.predict(x_hack)\n",
        "    qutils.model_save_quantized_weights(model,'weightnn'+fname+'.h5')\n",
        "    model.save(fname+\"tnn.h5\")\n",
        "    model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "neAuGGgWFl2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/os.chdir('drive/MyDrive/colab notebooks/dataset')"
      ],
      "metadata": {
        "id": "S4a0bOUTQXLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv(\"less_winered\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4845ddf-67c5-4abf-fda7-8a1a2d5e0d65",
        "id": "hcdq7H_gQb1w"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 00m 09s]\n",
            "val_accuracy: 0.5666666626930237\n",
            "\n",
            "Best val_accuracy So Far: 0.5708333253860474\n",
            "Total elapsed time: 00h 02m 17s\n",
            "less_wineredsummary\n",
            "1/1 [==============================] - 1s 717ms/step\n",
            "... quantizing model\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.2332 - accuracy: 0.5708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for fname in get_csv_filenames():\n",
        "  train_csv(fname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTbV9bf1SdTl",
        "outputId": "c59d5ee3-fd2c-45dc-ce43-5180b145421f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "less_pendigitssummary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 681ms/step\n",
            "... quantizing model\n",
            "71/71 [==============================] - 1s 3ms/step - loss: 0.5281 - accuracy: 0.8395\n",
            "less_cardiosummary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 683ms/step\n",
            "... quantizing model\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8824\n",
            "less_Harsummary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 682ms/step\n",
            "... quantizing model\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1.1668 - accuracy: 0.5333\n",
            "less_wineredsummary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 663ms/step\n",
            "... quantizing model\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.2332 - accuracy: 0.5708\n",
            "less_gasIdsummary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 669ms/step\n",
            "... quantizing model\n",
            "131/131 [==============================] - 1s 3ms/step - loss: 0.5700 - accuracy: 0.8212\n",
            "less_winequality_whitesummary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 664ms/step\n",
            "... quantizing model\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 1.6193 - accuracy: 0.5048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('winequality_white.csv', header=None)\n",
        "Xx = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "X = pd.DataFrame(Xx.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))))"
      ],
      "metadata": {
        "id": "6PmoZA1QvPZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install h5py\n"
      ],
      "metadata": {
        "id": "f5iODGC7ZaP5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6978bc5-eba8-4566-b3e7-2729c1434706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.8/dist-packages (from h5py) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the model from the HDF5 file\n",
        "model = load_model('winequality_whitetnn.h5', custom_objects={'QActivation': QActivation,'QDense':QDense})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SURAbh5-mpe0",
        "outputId": "7ac970cb-eb73-4434-e955-f17598ae5dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x_hack = tf.random.normal(shape=(1,16),dtype=tf.float32)\n",
        "#x_hack = tf.abs(x_hack)\n",
        "#output=model.predict(x_hack)\n",
        "#inpux = np.expand_dims(X.iloc[0], axis=0)\n",
        "inpux = X.iloc[0:1]\n",
        "lo=get_layer_outputs(model,inpux)\n",
        "yoyo = lo[2]\n",
        "gol = lo[4]\n",
        "lo"
      ],
      "metadata": {
        "id": "XlKZSNDWobPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e065d4-4709-403b-c300-da957a1e2551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.3125, 0.1875, 0.1875, 0.3125, 0.125 , 0.125 , 0.375 , 0.25  ,\n",
              "         0.25  , 0.25  , 0.125 ]], dtype=float32),\n",
              " array([[-0.15625 ,  1.625   , -0.03125 , -0.25    ,  0.09375 , -0.1875  ,\n",
              "          0.59375 , -0.25    , -0.09375 ,  0.      ,  0.28125 ,  0.15625 ,\n",
              "          0.1875  ,  0.15625 ,  0.03125 , -0.21875 ,  1.9375  , -0.1875  ,\n",
              "          0.234375, -0.21875 ,  0.      ,  0.15625 ,  0.125   ,  1.625   ,\n",
              "          0.0625  , -0.0625  , -0.3125  ,  0.4375  , -0.0625  , -0.4375  ,\n",
              "          0.4375  ,  0.      ,  0.53125 ,  0.28125 , -0.09375 ,  0.21875 ,\n",
              "         -0.25    , -0.125   ,  0.125   , -0.078125]], dtype=float32),\n",
              " array([[-1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n",
              "          1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
              "         -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,\n",
              "         -1.]], dtype=float32),\n",
              " array([[-6., -3.,  0.,  2., -3., -4., -5.]], dtype=float32),\n",
              " array([[2.9106444e-04, 5.8461856e-03, 1.1742377e-01, 8.6765087e-01,\n",
              "         5.8461856e-03, 2.1506916e-03, 7.9119514e-04]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xrisos = np.argmax(gol,axis=1)\n",
        "qinp = lo[0]"
      ],
      "metadata": {
        "id": "W21T375ey6Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "filename = \"weightnnwinequality_white.h5\"\n",
        "\n",
        "h5 = h5py.File(filename,'r')\n",
        "\n",
        "h5.visit(print)\n",
        "#print(h5['q_dense/q_dense/kernel:0'][:,:])\n",
        "#print(h5['q_batch_normalization/q_batch_normalization/beta:0'][:])\n",
        "sw0 = h5['q_dense/q_dense/kernel:0'][:,:]\n",
        "sw1 = h5['q_dense_1/q_dense_1/kernel:0'][:,:]\n",
        "\n",
        "h5.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhtkb7dKLxPq",
        "outputId": "28d501d1-d0f9-4ed8-ca12-e703c10d4ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activation\n",
            "q_activation\n",
            "q_activation_1\n",
            "q_dense\n",
            "q_dense/q_dense\n",
            "q_dense/q_dense/kernel:0\n",
            "q_dense_1\n",
            "q_dense_1/q_dense_1\n",
            "q_dense_1/q_dense_1/kernel:0\n",
            "top_level_model_weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matz=np.sign(sw0)\n",
        "abz=np.abs(matz)\n",
        "sinz=np.maximum(matz,0)\n",
        "binst(abz.flatten())[::-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Gn0OVXwMtwVD",
        "outputId": "476fbadb-ea53-4602-9cc4-824062fd1a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10011001110000000100111010000101000100011001101110011010111111111100011111111110011001101001111010110011101101001011101001001110011000111011011011110110101101001111101101010110110110010101001010110101001110011011110011011011100001110110110101110111111100111011101110010000001111011111011101101011111011011100011111011001101000001101010101100111000001000001000111101010100110101001010000010110000111000110100101011110101011111110110100000011'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnz=np.count_nonzero(sw0, axis=0)\n",
        "''.join([f\"0{i}\" for i in cnz])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "75hA3mk4cdJJ",
        "outputId": "5af46201-68e1-4598-fc10-2f412d17dd85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'06070806070407070707040806050804090607070707080808050305010906050503060906060307'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hay=binst(yoyo[0])\n",
        "jay = '0100101001111110101011111001001111010010'[::-1]\n",
        "jay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "felrSlVJedqO",
        "outputId": "e8b10d62-1a5b-45ad-a320-c06e77197a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0100101111001001111101010111111001010010'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dbytes(mat):\n",
        "  kay=mat.flatten().astype(np.uint8).tobytes()\n",
        "  return binascii.hexlify(kay).decode()"
      ],
      "metadata": {
        "id": "3WN6HY_igOES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "spa=csr_matrix(sw1.T)\n",
        "#spa.data,spa.indices,spa.indptr\n",
        "svals=binst(np.maximum(spa.data,0))\n",
        "scols=dbytes(spa.indices[::-1])\n",
        "srows=dbytes(spa.indptr[::-1])\n",
        "svals,scols,srows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIEYm3DPhKFm",
        "outputId": "53d686ba-8f91-46aa-ade6-e664e01935d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('0100000010110010011000100000110000101111111100111011000110111010101011011001010',\n",
              " '2625232221201e1b1817141211100d0c0605040201211f17100d0b211c1615100c0825211f1817100f0125242119181412092625221f1e1c1817161413100b0a07261c171412100f0b0a0907060401',\n",
              " '4f3a342d251d0e00')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lo[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOOG6WG0oQj_",
        "outputId": "c50d4cc2-f92e-4563-aece-662a6fbfc22f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-6., -3.,  0.,  2., -3., -4., -5.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sw1.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drqNXCwhj9I6",
        "outputId": "90d674fe-e2af-42fa-a2d1-f5f6e1348e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0., -1.,  0.,  0.,  1.,  0., -1.,  1.,  0., -1., -1.,  1.,  0.,\n",
              "         0.,  0.,  1., -1.,  0.,  1.,  0.,  1.,  0.,  0., -1.,  0.,  0.,\n",
              "         0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
              "         0.],\n",
              "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0., -1.,  1.,  0.,\n",
              "         0.,  0.,  0., -1.,  0.,  0.,  1.,  1.,  0.,  1., -1.,  1.,  0.,\n",
              "         0.,  0.,  1.,  0., -1., -1.,  0.,  0., -1.,  0.,  0.,  1.,  1.,\n",
              "         0.],\n",
              "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1., -1.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  1.,  1.,  0.,\n",
              "         0.],\n",
              "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  1.,  0., -1.,  0.,  0.,  0.,  1.,  0.,\n",
              "         0.],\n",
              "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0., -1.,\n",
              "         0.,  0.,  0., -1.,  0.,  0.,  0.,  0., -1.,  1.,  0.,  0.,  0.,\n",
              "         0.,  0.,  1.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.],\n",
              "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
              "        -1.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  1.,  0., -1.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.],\n",
              "       [ 0., -1., -1.,  0.,  1.,  1., -1.,  0.,  0.,  0.,  0.,  0., -1.,\n",
              "         1.,  0.,  0., -1., -1.,  1.,  0.,  1.,  0.,  0., -1.,  1.,  0.,\n",
              "         0., -1.,  0.,  0., -1.,  0., -1., -1., -1., -1.,  0.,  1., -1.,\n",
              "         0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn=np.count_nonzero(sw1, axis=0)\n",
        "oh=(lo[3]+nn)/2\n",
        "lo[3],oh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHFyK_dx5_Np",
        "outputId": "e0b6647a-6d03-468c-ef6c-3578718dbfe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-6., -3.,  0.,  2., -3., -4., -5.]], dtype=float32),\n",
              " array([[4., 6., 4., 5., 2., 1., 8.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.max(np.abs(sw0.T),axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wovagrYV4S9Z",
        "outputId": "56ceb7ec-8cc2-4878-c37b-0eb1ca385966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.25, 1.  , 0.5 , 0.5 , 0.5 , 0.5 , 0.5 , 0.5 , 0.5 , 0.25, 0.5 ,\n",
              "       0.25, 0.5 , 0.5 , 0.5 , 0.5 , 1.  , 0.5 , 0.25, 0.5 , 0.5 , 0.5 ,\n",
              "       0.5 , 1.  , 0.25, 0.5 , 0.5 , 0.5 , 0.5 , 0.5 , 0.5 , 0.5 , 0.5 ,\n",
              "       0.5 , 0.5 , 0.25, 0.5 , 0.5 , 0.5 , 0.25], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mysign(a):\n",
        "  signs = np.sign(a)\n",
        "\n",
        "  # Replace the sign of the zeroes with 1 (positive) or -1 (negative)\n",
        "  signs_no_zero = np.where(signs == 0, 1, signs)\n",
        "  return signs_no_zero"
      ],
      "metadata": {
        "id": "Pm0qdICClLLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grup(x):\n",
        "  x1 = x @ sw0\n",
        "  x2 = mysign(x1)\n",
        "  x3 = x2 @ sw1\n",
        "  return (x1,x2,x3)\n",
        "def drut(x):\n",
        "  x1 = x @ np.sign(sw0)\n",
        "  x2 = mysign(x1)\n",
        "  x3 = x2 @ sw1\n",
        "  am = np.argmax(x3,axis=1)\n",
        "  return am"
      ],
      "metadata": {
        "id": "z1uLXHm762op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xrisos[0:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoZUBU02rtoC",
        "outputId": "37b6ab6d-9e9a-43bc-ae45-471c7eb54757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 2, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drut(qinp)[0:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUrpcFmBbP8z",
        "outputId": "5935e192-57fc-41f1-b63e-06cbe8f840d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 2, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(np.not_equal(yoyo, grup(qinp)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgcQ5sQxptPs",
        "outputId": "161806bd-4e6c-4ac5-db22-ddafb2b5cc29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([], dtype=int64), array([], dtype=int64))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import binascii\n",
        "def binst(yy):\n",
        "  yozo = np.maximum(yy,0)\n",
        "  asbin=yozo.astype(np.uint8).tobytes()\n",
        "  bs=binascii.hexlify(asbin).decode()[1::2]\n",
        "  return bs[::-1]\n",
        "\n",
        "[print(binst(yy)) for yy in yoyo]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s5UYjJXsIFZ",
        "outputId": "d91f414d-dde4-4259-e679-692116657536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0100101111001001111101010111111001010010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG19gGCVcG76",
        "outputId": "d4de481b-9277-47c7-966c-034b9b5beacc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    3\n",
              "1    3\n",
              "2    3\n",
              "3    3\n",
              "4    3\n",
              "5    3\n",
              "6    3\n",
              "7    3\n",
              "8    3\n",
              "9    3\n",
              "Name: 11, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glo = lo[2][175]\n",
        "gor = grup(qinp[175])[1]\n",
        "glo, gor, np.where(np.not_equal(glo,gor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFyrR6SEd2a6",
        "outputId": "3c113fbc-33df-4e94-98ff-80c10666d1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n",
              "        -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
              "         1.,  1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,\n",
              "        -1.], dtype=float32),\n",
              " array([-1., -1., -1., -1., -1., -1., -1., -1.,  1.,  0.,  0., -1.,  1.,\n",
              "        -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
              "         1.,  1., -1., -1., -1.,  1.,  0., -1.,  1., -1., -1., -1., -1.,\n",
              "        -1.], dtype=float32),\n",
              " (array([ 9, 10, 32]),))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dut = yoyo @ (np.sign(swax))\n",
        "#dd , gg = np.argmax(dut,axis=1),np.argmax(gol,axis=1)\n",
        "hm=np.where(np.not_equal(drut(qinp),y[0:199]))\n",
        "ex=np.where(np.not_equal(xrisos,y[0:199]))\n",
        "#(dd[hm],gg[hm],hm)\n",
        "hm,ex,np.where(np.not_equal(hm,ex))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW6EbDhJsOvA",
        "outputId": "98d6b8dd-0551-4024-d82b-93eea6fdb291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([ 13,  27,  29,  49,  74,  82,  86,  93, 114, 148, 152, 154, 160,\n",
              "         161, 162, 166, 180]),),\n",
              " (array([ 13,  27,  29,  49,  74,  82,  86,  93, 114, 148, 152, 154, 160,\n",
              "         161, 162, 166, 180]),),\n",
              " (array([], dtype=int64), array([], dtype=int64)))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h5.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "AZbqv15wNqIu",
        "outputId": "2482cd41-22bb-4873-8c42-10552780ba14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    400\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/h5py/_hl/base.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mKeysViewHDF5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeysView\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"<KeysViewHDF5 {}>\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0m__repr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/_collections_abc.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;34m\"\"\" Number of members attached to this group \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwith_phil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5g.pyx\u001b[0m in \u001b[0;36mh5py.h5g.GroupID.get_num_objs\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid group (or file) id (invalid group (or file) ID)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h5['q_dense_1/q_dense_1/kernel:0'][:,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "aI0A96aNPZw9",
        "outputId": "f2e59f72-d106-4553-fa1f-85b693b1d197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d168f28e0cf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'q_dense_1/q_dense_1/kernel:0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid location identifier (invalid location identifier)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(QBatchNormalization().quantizers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQAg-y66TSHQ",
        "outputId": "4bfd20e9-2560-47b2-9496-185d5010dcb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<qkeras.quantizers.quantized_relu_po2 at 0x7fb3e48dd4f0>,\n",
              " <qkeras.quantizers.quantized_po2 at 0x7fb3e3a95610>,\n",
              " <qkeras.quantizers.quantized_po2 at 0x7fb3e3a95fd0>,\n",
              " <qkeras.quantizers.quantized_relu_po2 at 0x7fb3e3a955b0>]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def get_layer_outputs(model, x):\n",
        "    \"\"\"\n",
        "    Returns the output of every layer in a Keras model evaluated at the input x.\n",
        "    \n",
        "    Args:\n",
        "    model: A Keras model object.\n",
        "    x: The input to the model as a Numpy array or a list of Numpy arrays.\n",
        "    \n",
        "    Returns:\n",
        "    A list of Numpy arrays, where the i-th element is the output of the i-th layer\n",
        "    in the model evaluated at the input x.\n",
        "    \"\"\"\n",
        "    # Create a function that computes the output of every layer given the input\n",
        "    layer_outputs = [layer.output for layer in model.layers]\n",
        "    layer_eval_fn = K.function(inputs=[model.input], outputs=layer_outputs)\n",
        "    \n",
        "    # Evaluate the function at the input\n",
        "    output_values = layer_eval_fn([x])\n",
        "    \n",
        "    return output_values\n"
      ],
      "metadata": {
        "id": "qjpdNkMXUCXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "def get_results(fname):\n",
        "    df = pd.read_csv(fname+\".csv\", header=None)\n",
        "    X = df.iloc[:, :-1]\n",
        "    \n",
        "    X = pd.DataFrame(X.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))))\n",
        "    \n",
        "    model = load_model(fname+\"tnn.h5\", custom_objects={'QActivation': QActivation,'QDense':QDense})\n",
        "   \n",
        "    output=model.predict(X)\n",
        "    clases = np.argmax(output, axis=1)\n",
        "    return clases"
      ],
      "metadata": {
        "id": "WKdtNMBAhe5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_results(\"pendigits\")[0:14]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z6PkxAfin56",
        "outputId": "91d1e518-aa07-4e36-e0a6-358ee76814f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235/235 [==============================] - 4s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8, 2, 1, 4, 1, 6, 4, 0, 5, 0, 9, 8, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def write_strings_to_file(strings, file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        for string in strings:\n",
        "            file.write(str(string) + '\\n')"
      ],
      "metadata": {
        "id": "2rVg94yci8af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fname in get_csv_filenames():\n",
        "  gres = get_results(fname).tolist()\n",
        "  write_strings_to_file(gres,'results_'+fname+'.results')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsBYR8kUjBrb",
        "outputId": "6606c12f-ecf2-4a7b-dfed-9e957f9f404e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235/235 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67/67 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "154/154 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "435/435 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93/93 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inpux = X.iloc[0:1]\n",
        "#inpux = np.array([[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]])\n",
        "lo=get_layer_outputs(model,inpux)\n",
        "yoyo = lo[2]\n",
        "gol = lo[4]\n",
        "lo"
      ],
      "metadata": {
        "id": "wW9q0LtTn5Fd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}